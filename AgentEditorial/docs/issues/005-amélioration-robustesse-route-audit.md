# Issue #005 : Am√©lioration de la robustesse et performance de la route /audit

**Date de cr√©ation** : 2025-12-29
**Date d'impl√©mentation** : _√Ä d√©finir_
**Statut** : En attente
**Priorit√©** : Haute
**Type** : Am√©lioration / Bugfix / Performance
**Labels** : `api`, `audit`, `performance`, `reliability`, `race-condition`, `caching`

---

## Contexte

La route `GET /api/v1/sites/{domain}/audit` est un endpoint critique qui orchestre plusieurs workflows (analyse √©ditoriale, recherche de concurrents, scraping, trend pipeline) pour fournir un audit complet d'un site. Bien que fonctionnelle, cette route pr√©sente plusieurs probl√®mes de robustesse, performance et gestion d'erreurs.

### Probl√®mes identifi√©s

**Critique (P0)** :
1. **Race condition** : Appels simultan√©s cr√©ent plusieurs orchestrators pour le m√™me domaine
2. **Absence de timeout global** : Orchestrators peuvent rester "running" ind√©finiment
3. **Gestion d'erreur en cha√Æne** : Une √©tape √©chou√©e bloque toutes les suivantes

**Performance (P1)** :
4. **Requ√™tes s√©quentielles** : Les 5 v√©rifications s'ex√©cutent s√©quentiellement
5. **build_complete_audit_from_database co√ªteuse** : Charge 1000 articles √† chaque appel
6. **Absence de cache** : Recalcule l'audit complet m√™me si donn√©es inchang√©es

**Robustesse (P2)** :
7. **Seuils hardcod√©s** : 10 et 5 articles en dur dans le code
8. **Pas de validation du domaine** : Aucune validation avant de lancer des workflows co√ªteux
9. **Timeout trend pipeline silencieux** : Peut timeout sans notification

**UX/API (P2)** :
10. **Pas de progression granulaire** : Seulement "pending" ‚Üí "completed"
11. **Messages d'erreur g√©n√©riques** : Pas de contexte actionnable
12. **Pas de retry automatique** : Erreurs transitoires font tout √©chouer

**Monitoring (P2)** :
13. **M√©triques manquantes** : Pas de m√©triques Prometheus
14. **Pas de distinction first run vs refresh** : Impossible de savoir si c'est un nouvel audit

---

## Impact

### Impact utilisateur
- **Gaspillage de ressources** : Workflows dupliqu√©s, co√ªts API
- **Latence √©lev√©e** : Pas de cache, requ√™tes s√©quentielles
- **Exp√©rience d√©grad√©e** : Pas de progression d√©taill√©e, messages d'erreur peu clairs

### Impact technique
- **Risque de conflits** : √âcritures simultan√©es en base
- **Orchestrators zombies** : Workflows bloqu√©s sans nettoyage
- **Difficile √† d√©boguer** : Manque de logs et m√©triques

---

## Analyse technique d√©taill√©e

### Localisation du code

**Fichier principal** : `python_scripts/api/routers/sites.py`

**Fonctions cl√©s** :
- `get_site_audit()` : Ligne 2631-2835
- `run_missing_workflows_chain()` : Ligne 2109-2404
- `build_complete_audit_from_database()` : Ligne 843-980
- `_get_audit_status()` : Ligne 2406-2605
- Fonctions de v√©rification : Lignes 712-840

---

## Solutions propos√©es

### üî¥ P0-1 : Race condition - Duplication des orchestrators

**Probl√®me** :
```python
# Ligne 2730-2742
orchestrator_execution = await create_workflow_execution(
    db,
    workflow_type="audit_orchestrator",
    input_data={"domain": domain, ...},
    status="running",
)
```

Si deux requ√™tes arrivent simultan√©ment, deux orchestrators sont cr√©√©s.

**Solution recommand√©e** : V√©rifier l'existence d'un orchestrator en cours

```python
# AVANT de cr√©er l'orchestrator
existing_orchestrator = await db.execute(
    select(WorkflowExecution)
    .where(
        WorkflowExecution.workflow_type == "audit_orchestrator",
        WorkflowExecution.status.in_(["pending", "running"]),
        WorkflowExecution.input_data["domain"].astext == domain,
    )
    .order_by(desc(WorkflowExecution.start_time))
    .limit(1)
)

existing = existing_orchestrator.scalar_one_or_none()

if existing:
    # Retourner l'orchestrator existant
    logger.info("Existing orchestrator found, reusing", execution_id=existing.execution_id)

    # Construire workflow_steps depuis input_data
    workflow_steps = _build_workflow_steps_from_input_data(existing.input_data)

    return PendingAuditResponse(
        status="pending",
        execution_id=str(existing.execution_id),
        message="Audit already in progress. Use the execution_id to check status.",
        workflow_steps=workflow_steps,
        data_status=_get_current_data_status(...),
    )

# SINON cr√©er un nouveau orchestrator
orchestrator_execution = await create_workflow_execution(...)
```

**Localisation** : `sites.py:2720-2742`

**B√©n√©fices** :
- √âlimine la duplication
- √âconomise des ressources
- √âvite les conflits en base

---

### üî¥ P0-2 : Absence de timeout global pour orchestrator

**Probl√®me** : Orchestrator peut rester "running" ind√©finiment si un workflow se bloque.

**Solution recommand√©e** : Ajouter v√©rification de timeout dans `_get_audit_status()`

```python
# Dans _get_audit_status()
from datetime import timezone

MAX_ORCHESTRATOR_DURATION = 3600  # 1 heure

# Apr√®s avoir r√©cup√©r√© l'orchestrator
if orchestrator.start_time and orchestrator.status == "running":
    elapsed = (datetime.now(timezone.utc) - orchestrator.start_time).total_seconds()

    if elapsed > MAX_ORCHESTRATOR_DURATION:
        logger.error(
            "Orchestrator timeout exceeded",
            execution_id=orchestrator_execution_id,
            elapsed_seconds=elapsed,
        )

        # Marquer comme failed avec timeout
        await update_workflow_execution(
            db,
            orchestrator,
            status="failed",
            error_message=f"Orchestrator timeout exceeded ({elapsed:.0f}s > {MAX_ORCHESTRATOR_DURATION}s)",
        )

        # Marquer aussi les workflows enfants en running comme failed
        child_workflows_running = [w for w in child_workflows if w.status == "running"]
        for child in child_workflows_running:
            await update_workflow_execution(
                db,
                child,
                status="failed",
                error_message="Parent orchestrator timed out",
            )
```

**Localisation** : `sites.py:2406` (dans `_get_audit_status`)

**Configuration** :
```python
# Ajouter dans config ou env
MAX_ORCHESTRATOR_DURATION = int(os.getenv("MAX_AUDIT_ORCHESTRATOR_DURATION", "3600"))
```

**B√©n√©fices** :
- Nettoyage automatique des workflows zombies
- Permet retry apr√®s timeout
- Am√©liore l'observabilit√©

---

### üî¥ P0-3 : Gestion d'erreur en cha√Æne

**Probl√®me** : Si Competitor Search √©choue, Client Scraping (ind√©pendant) n'est jamais lanc√©.

**Solution recommand√©e** : Rendre les workflows r√©silients avec try/except individuels

```python
async def run_missing_workflows_chain(...):
    """Execute workflows with individual error handling."""

    async with AsyncSessionLocal() as db:
        failed_workflows = []
        orchestrator = EditorialAnalysisOrchestrator(db)
        current_profile_id = profile_id

        try:
            # √âtape 1: Editorial Analysis (CRITIQUE - doit r√©ussir)
            if needs_analysis:
                try:
                    logger.info("Step 1: Starting editorial analysis", domain=domain)
                    # ... code existant ...
                except Exception as e:
                    logger.error("Editorial analysis failed", error=str(e), exc_info=True)
                    failed_workflows.append(("editorial_analysis", str(e)))
                    # Ne pas continuer si l'analyse √©choue (critique)
                    raise

            # √âtape 2: Competitor Search (NON-CRITIQUE)
            if needs_competitors:
                try:
                    logger.info("Step 2: Starting competitor search", domain=domain)
                    # ... code existant ...
                except Exception as e:
                    logger.error("Competitor search failed, continuing...", error=str(e), exc_info=True)
                    failed_workflows.append(("competitor_search", str(e)))
                    # Ne pas raise, continuer avec les autres workflows

            # √âtape 3: Client Scraping (SEMI-CRITIQUE)
            if needs_client_scraping and current_profile_id:
                try:
                    logger.info("Step 3: Starting client site scraping", domain=domain)
                    # ... code existant ...
                except Exception as e:
                    logger.error("Client scraping failed", error=str(e), exc_info=True)
                    failed_workflows.append(("client_scraping", str(e)))
                    # Continuer quand m√™me (peut avoir des donn√©es partielles)

            # √âtape 4: Competitor Scraping (NON-CRITIQUE)
            if needs_scraping:
                try:
                    logger.info("Step 4: Starting competitor scraping", domain=domain)
                    # ... code existant ...
                except Exception as e:
                    logger.error("Competitor scraping failed, continuing...", error=str(e), exc_info=True)
                    failed_workflows.append(("enhanced_scraping", str(e)))

            # √âtape 5: Trend Pipeline (NON-CRITIQUE)
            if needs_trend_pipeline:
                try:
                    logger.info("Step 5: Starting trend pipeline", domain=domain)
                    # ... code existant ...
                except Exception as e:
                    logger.error("Trend pipeline failed", error=str(e), exc_info=True)
                    failed_workflows.append(("trend_pipeline", str(e)))

            # D√©terminer le statut final
            orchestrator_exec = await get_workflow_execution(db, orchestrator_execution_id)
            if orchestrator_exec:
                if failed_workflows:
                    # Succ√®s partiel
                    status = "partial"
                    error_message = f"Some workflows failed: {', '.join(w[0] for w in failed_workflows)}"
                else:
                    # Succ√®s complet
                    status = "completed"
                    error_message = None

                await update_workflow_execution(
                    db,
                    orchestrator_exec,
                    status=status,
                    error_message=error_message,
                    output_data={"failed_workflows": failed_workflows} if failed_workflows else None,
                )

            logger.info(
                "Missing workflows completed",
                domain=domain,
                status=status,
                failed_count=len(failed_workflows),
            )

        except Exception as e:
            # Erreur critique (editorial_analysis ou autre erreur non g√©r√©e)
            logger.error("Critical error in workflows chain", domain=domain, error=str(e), exc_info=True)
            orchestrator_exec = await get_workflow_execution(db, orchestrator_execution_id)
            if orchestrator_exec:
                await update_workflow_execution(
                    db,
                    orchestrator_exec,
                    status="failed",
                    error_message=str(e),
                )
```

**Localisation** : `sites.py:2109-2404`

**B√©n√©fices** :
- Workflows ind√©pendants peuvent continuer malgr√© les √©checs
- Statut "partial" indique succ√®s partiel
- Meilleure utilisation des ressources

---

### üü° P1-4 : Parall√©lisation des v√©rifications

**Probl√®me** : Les 5 v√©rifications sont s√©quentielles (lignes 2654-2715).

**Solution recommand√©e** : Utiliser `asyncio.gather()`

```python
import asyncio

async def get_site_audit(...):
    # AVANT : S√©quentiel
    # profile = await _check_site_profile(db, domain)
    # competitors_execution = await _check_competitors(db, domain)
    # trend_execution = await _check_trend_pipeline(db, domain)

    # APR√àS : Parall√®le
    profile, competitors_execution, trend_execution = await asyncio.gather(
        _check_site_profile(db, domain),
        _check_competitors(db, domain),
        _check_trend_pipeline(db, domain),
        return_exceptions=False,  # Propager les exceptions
    )

    needs_analysis = not profile
    needs_competitors = not competitors_execution
    needs_trend_pipeline = not trend_execution

    # Les v√©rifications d'articles d√©pendent du profil, donc s√©quentielles
    if profile:
        (client_count, client_sufficient), (competitor_count, competitor_sufficient) = await asyncio.gather(
            _check_client_articles(db, profile.id),
            _check_competitor_articles(db, competitor_domains) if competitors_execution else (0, False),
        )
        needs_client_scraping = not client_sufficient
        needs_scraping = not competitor_sufficient
    else:
        needs_client_scraping = True
        needs_scraping = True
```

**Localisation** : `sites.py:2654-2715`

**Gain estim√©** : 50-200ms

---

### üü° P1-6 : Cache pour les audits r√©cents

**Probl√®me** : Recalcule l'audit complet m√™me si donn√©es inchang√©es.

**Solution recommand√©e** : Cache Redis avec invalidation intelligente

```python
import json
from typing import Optional
import hashlib

async def get_site_audit(...):
    # V√©rifier le cache avant tout
    cache_enabled = os.getenv("AUDIT_CACHE_ENABLED", "true").lower() == "true"

    if cache_enabled and redis_client:
        cache_key = f"audit:complete:{domain}"

        # R√©cup√©rer depuis le cache
        cached_data = await redis_client.get(cache_key)

        if cached_data:
            # V√©rifier si les donn√©es sources ont chang√©
            last_modified = await _get_last_data_modification_timestamp(db, domain)
            cache_timestamp_key = f"{cache_key}:timestamp"
            cache_timestamp_str = await redis_client.get(cache_timestamp_key)

            if cache_timestamp_str:
                cache_timestamp = datetime.fromisoformat(cache_timestamp_str)

                if last_modified and last_modified <= cache_timestamp:
                    logger.info("Returning cached audit", domain=domain, age_seconds=(datetime.now() - cache_timestamp).total_seconds())
                    return SiteAuditResponse(**json.loads(cached_data))

    # Pas de cache ou donn√©es modifi√©es : calculer
    # ... logique existante ...

    # Si toutes les donn√©es disponibles, construire et cacher
    if all_data_available:
        audit_response = await build_complete_audit_from_database(...)

        # Mettre en cache
        if cache_enabled and redis_client:
            cache_ttl = int(os.getenv("AUDIT_CACHE_TTL", "3600"))  # 1 heure
            await redis_client.setex(
                cache_key,
                cache_ttl,
                json.dumps(audit_response.model_dump(), default=str)
            )
            await redis_client.setex(
                f"{cache_key}:timestamp",
                cache_ttl,
                datetime.now(timezone.utc).isoformat()
            )

        return audit_response


async def _get_last_data_modification_timestamp(
    db: AsyncSession,
    domain: str,
) -> Optional[datetime]:
    """
    R√©cup√®re le timestamp de derni√®re modification des donn√©es sources.

    V√©rifie :
    - site_profiles.updated_at
    - workflow_executions (competitor_search, enhanced_scraping, trend_pipeline)
    - client_articles.created_at (max)
    """
    from sqlalchemy import select, func

    # Profile
    profile = await get_site_profile_by_domain(db, domain)
    timestamps = []

    if profile and profile.updated_at:
        timestamps.append(profile.updated_at)

    # Workflows
    workflow_types = ["competitor_search", "enhanced_scraping", "trend_pipeline"]
    stmt = (
        select(func.max(WorkflowExecution.end_time))
        .where(
            WorkflowExecution.workflow_type.in_(workflow_types),
            WorkflowExecution.input_data["domain"].astext == domain,
            WorkflowExecution.status == "completed",
        )
    )
    result = await db.execute(stmt)
    max_workflow_time = result.scalar_one_or_none()
    if max_workflow_time:
        timestamps.append(max_workflow_time)

    # Client articles
    if profile:
        stmt = (
            select(func.max(ClientArticle.created_at))
            .where(ClientArticle.site_profile_id == profile.id)
        )
        result = await db.execute(stmt)
        max_article_time = result.scalar_one_or_none()
        if max_article_time:
            timestamps.append(max_article_time)

    return max(timestamps) if timestamps else None
```

**Configuration** :
```bash
AUDIT_CACHE_ENABLED=true
AUDIT_CACHE_TTL=3600  # 1 heure
REDIS_URL=redis://localhost:6379/0
```

**Invalidation** :
- TTL automatique (1 heure)
- V√©rification de timestamp de modification
- Endpoint manuel : `DELETE /api/v1/sites/{domain}/audit/cache`

**B√©n√©fices** :
- R√©duction latence de 80-95%
- √âconomie ressources DB
- Meilleure scalabilit√©

---

### üü° P1-9 : Timeout trend pipeline silencieux

**Probl√®me** : Boucle while peut sortir par timeout sans lever d'exception (ligne 2336-2355).

**Solution recommand√©e** :

```python
# Dans run_missing_workflows_chain, √©tape 5
max_wait = 1200  # 20 minutes
start_wait = datetime.now()
trend_exec = None

while (datetime.now() - start_wait).total_seconds() < max_wait:
    stmt = (
        select(TrendPipelineExecution)
        .where(
            TrendPipelineExecution.execution_id == UUIDType(execution_id),
            TrendPipelineExecution.stage_1_clustering_status == "completed",
            TrendPipelineExecution.stage_2_temporal_status == "completed",
            TrendPipelineExecution.stage_3_llm_status == "completed",
        )
    )
    result = await db.execute(stmt)
    trend_exec = result.scalar_one_or_none()

    if trend_exec:
        break

    await asyncio.sleep(10)

# ‚úÖ AJOUTER : V√©rifier si timeout
if not trend_exec:
    elapsed = (datetime.now() - start_wait).total_seconds()
    error_msg = f"Trend pipeline did not complete within {max_wait}s (elapsed: {elapsed:.0f}s)"
    logger.error("Trend pipeline timeout", execution_id=execution_id, elapsed=elapsed)

    await update_workflow_execution(
        db,
        trend_execution,
        status="failed",
        error_message=error_msg,
    )
    raise TimeoutError(error_msg)

# Le reste du code continue normalement
await update_workflow_execution(
    db,
    trend_execution,
    status="completed",
)
```

**Localisation** : `sites.py:2336-2360`

---

### üü¢ P2-7 : Seuils configurables

**Probl√®me** : Seuils hardcod√©s (10 et 5 articles).

**Solution recommand√©e** :

```python
# Configuration
MIN_COMPETITOR_ARTICLES = int(os.getenv("MIN_COMPETITOR_ARTICLES_FOR_AUDIT", "10"))
MIN_CLIENT_ARTICLES = int(os.getenv("MIN_CLIENT_ARTICLES_FOR_AUDIT", "5"))

# Ou via query params
async def get_site_audit(
    domain: str,
    min_competitor_articles: int = Query(10, ge=1, le=100, description="Minimum competitor articles required"),
    min_client_articles: int = Query(5, ge=1, le=100, description="Minimum client articles required"),
    db: AsyncSession = Depends(get_db),
    background_tasks: BackgroundTasks = BackgroundTasks(),
):
    # Utiliser les param√®tres
    count, is_sufficient = await _check_competitor_articles(db, competitor_domains)
    needs_scraping = count < min_competitor_articles

    count, is_sufficient = await _check_client_articles(db, profile.id)
    needs_client_scraping = count < min_client_articles
```

**Localisation** : `sites.py:789, 808`

---

### üü¢ P2-8 : Validation du domaine

**Probl√®me** : Pas de validation avant de lancer workflows co√ªteux.

**Solution recommand√©e** :

```python
import re
from fastapi import Path

# Regex domaine valide
DOMAIN_REGEX = re.compile(
    r'^(?:[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}$'
)

async def get_site_audit(
    domain: str = Path(
        ...,
        regex=DOMAIN_REGEX.pattern,
        description="Valid domain name (e.g., example.com)",
        examples=["innosys.fr", "example.com"],
    ),
    db: AsyncSession = Depends(get_db),
    background_tasks: BackgroundTasks = BackgroundTasks(),
):
    # FastAPI validera automatiquement le domaine
    # Si invalide, retourne 422 Unprocessable Entity
    ...
```

**Validation suppl√©mentaire** :

```python
# Validation DNS optionnelle (peut √™tre co√ªteuse)
import socket

async def validate_domain_exists(domain: str) -> bool:
    """V√©rifie que le domaine existe via DNS."""
    try:
        socket.gethostbyname(domain)
        return True
    except socket.gaierror:
        return False

# Dans get_site_audit (optionnel)
if os.getenv("VALIDATE_DOMAIN_DNS", "false").lower() == "true":
    if not await validate_domain_exists(domain):
        raise HTTPException(
            status_code=400,
            detail=f"Domain {domain} does not exist or is unreachable"
        )
```

---

### üü¢ P2-11 : Messages d'erreur riches

**Probl√®me** : Messages d'erreur g√©n√©riques sans contexte actionnable.

**Solution recommand√©e** : Enrichir `AuditStatusResponse`

```python
class FailedWorkflowDetail(BaseModel):
    """D√©tails d'un workflow √©chou√©."""

    workflow: str = Field(..., description="Type de workflow")
    error: str = Field(..., description="Message d'erreur")
    error_code: Optional[str] = Field(None, description="Code d'erreur")
    retry_possible: bool = Field(..., description="Peut √™tre retry")
    suggested_action: Optional[str] = Field(None, description="Action sugg√©r√©e")
    timestamp: datetime = Field(..., description="Timestamp de l'erreur")


class AuditStatusResponse(BaseModel):
    # ... champs existants ...

    failed_workflow_details: Optional[List[FailedWorkflowDetail]] = Field(
        None,
        description="D√©tails des workflows √©chou√©s avec actions sugg√©r√©es"
    )
```

**Exemple** :

```json
{
  "overall_status": "partial",
  "failed_workflow_details": [
    {
      "workflow": "competitor_search",
      "error": "API rate limit exceeded: 429 Too Many Requests",
      "error_code": "RATE_LIMIT_EXCEEDED",
      "retry_possible": true,
      "suggested_action": "Wait 5 minutes and retry the audit",
      "timestamp": "2025-12-29T10:30:00Z"
    }
  ]
}
```

---

### üü¢ P2-12 : Retry automatique pour erreurs transitoires

**Probl√®me** : Erreurs r√©seau temporaires font tout √©chouer.

**Solution recommand√©e** : Utiliser `tenacity`

```python
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
)

# Wrapper pour scraping avec retry
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10),
    retry=retry_if_exception_type((ConnectionError, TimeoutError, asyncio.TimeoutError)),
    reraise=True,
)
async def scrape_with_retry(
    scraping_agent: EnhancedScrapingAgent,
    db: AsyncSession,
    domain: str,
    **kwargs,
):
    """Scraping avec retry automatique pour erreurs transitoires."""
    return await scraping_agent.discover_and_scrape_articles(
        db,
        domain,
        **kwargs,
    )

# Utilisation dans run_missing_workflows_chain
if needs_client_scraping and current_profile_id:
    scraping_agent = EnhancedScrapingAgent(min_word_count=150)
    try:
        await scrape_with_retry(
            scraping_agent,
            db,
            domain,
            max_articles=100,
            is_client_site=True,
            site_profile_id=current_profile_id,
            force_reprofile=False,
        )
    except Exception as e:
        # Apr√®s 3 tentatives, √©choue
        logger.error("Client scraping failed after retries", error=str(e))
        failed_workflows.append(("client_scraping", str(e)))
```

**D√©pendance** :
```bash
pip install tenacity
```

---

### üü¢ P2-13 : M√©triques Prometheus

**Probl√®me** : Pas de m√©triques pour monitoring.

**Solution recommand√©e** :

```python
from prometheus_client import Counter, Histogram, Gauge

# D√©finir les m√©triques
audit_requests_total = Counter(
    'audit_requests_total',
    'Total audit requests',
    ['domain', 'status']  # labels
)

audit_duration_seconds = Histogram(
    'audit_duration_seconds',
    'Audit duration in seconds',
    ['domain', 'has_cache']
)

workflow_failures_total = Counter(
    'workflow_failures_total',
    'Workflow failures',
    ['workflow_type', 'error_type']
)

orchestrator_active_count = Gauge(
    'orchestrator_active_count',
    'Number of active orchestrators'
)

# Dans get_site_audit
import time

start_time = time.time()
has_cache = False

try:
    # ... logique ...

    if cached_audit:
        has_cache = True
        audit_requests_total.labels(domain=domain, status='cache_hit').inc()
    else:
        audit_requests_total.labels(domain=domain, status='success').inc()

    return audit_response

except Exception as e:
    audit_requests_total.labels(domain=domain, status='error').inc()
    raise

finally:
    duration = time.time() - start_time
    audit_duration_seconds.labels(domain=domain, has_cache=has_cache).observe(duration)

# Dans run_missing_workflows_chain
try:
    orchestrator_active_count.inc()
    # ... workflows ...
except Exception as e:
    workflow_failures_total.labels(
        workflow_type=current_workflow_type,
        error_type=type(e).__name__
    ).inc()
finally:
    orchestrator_active_count.dec()
```

**Endpoint m√©triques** :
```python
from prometheus_client import make_asgi_app

# Dans main.py
metrics_app = make_asgi_app()
app.mount("/metrics", metrics_app)
```

---

### üü¢ P2-14 : Distinction first run vs refresh

**Probl√®me** : Impossible de savoir si c'est un nouvel audit.

**Solution recommand√©e** : Enrichir `SiteAuditResponse`

```python
class SiteAuditResponse(BaseModel):
    # ... existing fields ...

    is_fresh_analysis: bool = Field(
        ...,
        description="True if this is a fresh analysis (just completed)"
    )
    last_updated: datetime = Field(
        ...,
        description="Timestamp of last audit update"
    )
    data_age_hours: float = Field(
        ...,
        description="Age of the audit data in hours",
        ge=0
    )
    cache_hit: bool = Field(
        default=False,
        description="True if returned from cache"
    )


# Dans build_complete_audit_from_database
def build_complete_audit_from_database(..., is_fresh: bool = False):
    # Calculer last_updated
    last_updated = orchestrator.end_time if orchestrator else profile.updated_at

    # Calculer data_age_hours
    if last_updated:
        data_age = (datetime.now(timezone.utc) - last_updated).total_seconds() / 3600
    else:
        data_age = 0.0

    return SiteAuditResponse(
        # ... existing fields ...
        is_fresh_analysis=is_fresh,
        last_updated=last_updated,
        data_age_hours=round(data_age, 2),
        cache_hit=False,  # Sera True si retourn√© depuis cache
    )
```

---

## Plan d'impl√©mentation

### Phase 1 : Corrections critiques (P0) - 2-3 jours

**Objectif** : √âliminer les bugs et race conditions

1. **P0-1 : Race condition**
   - Ajouter v√©rification orchestrator existant
   - Tests : 2 requ√™tes simultan√©es ne cr√©ent qu'un orchestrator

2. **P0-2 : Timeout global**
   - Ajouter v√©rification timeout dans `_get_audit_status`
   - Nettoyage orchestrators zombies
   - Tests : Orchestrator timeout apr√®s MAX_DURATION

3. **P0-3 : Gestion d'erreur cha√Æne**
   - Refactorer `run_missing_workflows_chain` avec try/except individuels
   - Ajouter statut "partial"
   - Tests : Workflow 2 √©choue, workflow 3 continue

**Livrable** : Route /audit robuste et fiable

---

### Phase 2 : Optimisations performance (P1) - 2-3 jours

**Objectif** : R√©duire latence et consommation ressources

4. **P1-4 : Parall√©lisation checks**
   - Utiliser `asyncio.gather()` pour v√©rifications
   - Tests : Temps r√©duit de 50-200ms

5. **P1-6 : Cache Redis**
   - Impl√©menter cache avec invalidation
   - Ajouter endpoint de nettoyage cache
   - Tests : Cache hit r√©duit latence de 80%+

6. **P1-9 : Timeout trend pipeline**
   - Lever exception si timeout
   - Tests : Timeout d√©tect√© et logg√©

**Livrable** : Route /audit rapide et scalable

---

### Phase 3 : Am√©liorations UX (P2) - 3-4 jours

**Objectif** : Meilleure exp√©rience d√©veloppeur et utilisateur

7. **P2-7 : Seuils configurables**
8. **P2-8 : Validation domaine**
9. **P2-11 : Messages d'erreur riches**
10. **P2-12 : Retry automatique**
11. **P2-13 : M√©triques Prometheus**
12. **P2-14 : First run vs refresh**

**Livrable** : API claire, observable et configurable

---

## Tests √† effectuer

### Tests unitaires

1. **Race condition** :
   - 2 appels simultan√©s ‚Üí 1 seul orchestrator cr√©√©
   - Deuxi√®me appel retourne l'execution_id existant

2. **Timeout orchestrator** :
   - Orchestrator running > MAX_DURATION ‚Üí marqu√© failed
   - Workflows enfants en running ‚Üí marqu√©s failed

3. **Gestion erreurs** :
   - Workflow 2 √©choue ‚Üí Workflows 3, 4, 5 continuent
   - Orchestrator marqu√© "partial" si √©checs non-critiques
   - Orchestrator marqu√© "failed" si √©chec critique (editorial_analysis)

4. **Cache** :
   - Cache hit retourne donn√©es sans requ√™tes DB
   - Donn√©es modifi√©es ‚Üí cache invalid√©
   - TTL expir√© ‚Üí recalcul

### Tests d'int√©gration

1. **Workflow complet** :
   - Audit complet d'un nouveau domaine
   - V√©rifier progression via `/audit/status`
   - V√©rifier cache apr√®s completion

2. **Sc√©narios d'erreur** :
   - API externe timeout ‚Üí retry automatique
   - Scraping √©choue ‚Üí statut partial
   - Trend pipeline timeout ‚Üí erreur claire

3. **Performance** :
   - Temps r√©ponse avec cache < 100ms
   - Temps r√©ponse sans cache < 2s (v√©rifications)
   - Pas de requ√™tes N+1

### Tests de charge

1. **Concurrence** :
   - 10 appels simultan√©s m√™me domaine ‚Üí 1 orchestrator
   - 10 appels domaines diff√©rents ‚Üí 10 orchestrators

2. **Cache** :
   - 100 req/s avec cache ‚Üí latence p95 < 200ms
   - Pas de d√©gradation m√©moire Redis

---

## M√©triques de validation

### Performance
- ‚úÖ Cache hit ratio > 70% en production
- ‚úÖ Latence p95 avec cache < 200ms
- ‚úÖ Latence p95 sans cache < 3s
- ‚úÖ R√©duction requ√™tes DB de 80%+ avec cache

### Robustesse
- ‚úÖ 0 orchestrators dupliqu√©s sur 1000 requ√™tes simultan√©es
- ‚úÖ 100% orchestrators nettoy√©s apr√®s timeout
- ‚úÖ Workflows ind√©pendants continuent malgr√© √©checs non-critiques

### Observabilit√©
- ‚úÖ Toutes les m√©triques expos√©es sur `/metrics`
- ‚úÖ Logs structur√©s avec contexte (domain, execution_id)
- ‚úÖ Messages d'erreur actionnables

---

## Configuration requise

### Variables d'environnement

```bash
# Race condition
MAX_AUDIT_ORCHESTRATOR_DURATION=3600  # 1 heure

# Cache
AUDIT_CACHE_ENABLED=true
AUDIT_CACHE_TTL=3600
REDIS_URL=redis://localhost:6379/0

# Seuils
MIN_COMPETITOR_ARTICLES_FOR_AUDIT=10
MIN_CLIENT_ARTICLES_FOR_AUDIT=5

# Validation
VALIDATE_DOMAIN_DNS=false  # false pour √©viter latence

# Retry
MAX_SCRAPING_RETRIES=3
SCRAPING_RETRY_WAIT_MIN=4
SCRAPING_RETRY_WAIT_MAX=10
```

### D√©pendances

```bash
pip install tenacity prometheus-client redis
```

---

## Points d'attention

### Compatibilit√© backward

- ‚úÖ API existante reste compatible (pas de breaking changes)
- ‚úÖ Nouveaux champs optionnels dans responses
- ‚úÖ Comportement par d√©faut inchang√© si pas de config

### Performance

- ‚ö†Ô∏è Cache Redis n√©cessite infrastructure suppl√©mentaire
- ‚ö†Ô∏è M√©triques Prometheus augmentent l√©g√®rement la latence (<5ms)
- ‚úÖ Parall√©lisation r√©duit significativement latence globale

### S√©curit√©

- ‚ö†Ô∏è Validation DNS peut √™tre contourn√©e si d√©sactiv√©e
- ‚ö†Ô∏è Cache peut contenir donn√©es sensibles (configurer TTL court)
- ‚úÖ Regex validation domaine pr√©vient injection

---

## Prochaines √©tapes

1. **Validation** : Approuver le plan d'impl√©mentation par phases
2. **Phase 1** : Impl√©menter corrections critiques (P0)
3. **Tests** : Valider chaque phase avant de passer √† la suivante
4. **Phase 2** : Optimisations performance
5. **Phase 3** : Am√©liorations UX
6. **Documentation** : Mettre √† jour docs API
7. **Monitoring** : Configurer alertes Prometheus

---

## Historique

- **2025-12-29** : Cr√©ation de l'issue apr√®s analyse approfondie de la route /audit
- **2025-12-29** : Identification de 14 am√©liorations (P0-P2)
- **2025-12-29** : Plan d'impl√©mentation en 3 phases

---

## R√©f√©rences

- Route `/audit` : `python_scripts/api/routers/sites.py:2608-2835`
- Fonction `run_missing_workflows_chain` : `python_scripts/api/routers/sites.py:2109-2404`
- Fonction `build_complete_audit_from_database` : `python_scripts/api/routers/sites.py:843-980`
- Issue #004 : Gestion WorkflowExecution (partiellement adress√© dans cette issue)
- Mod√®le `WorkflowExecution` : `python_scripts/database/models.py`

---

## Diagrammes

### Flux actuel (avec probl√®mes)

```mermaid
flowchart TD
    A[GET /audit] --> B{Donn√©es OK?}
    B -->|Oui| C[build_complete_audit<br/>‚ùå Pas de cache<br/>‚ùå Charge 1000 articles]
    B -->|Non| D{Orchestrator existant?<br/>‚ùå Pas v√©rifi√©}
    D -->|Cr√©er| E[Cr√©er orchestrator]
    D -->|R√©utiliser| F[‚ùå Cr√©e quand m√™me]

    E --> G[run_missing_workflows_chain]
    G --> H[Workflow 1]
    H -->|Succ√®s| I[Workflow 2]
    I -->|‚ùå √âchec| J[‚ùå Arr√™t complet]

    G -.->|Timeout| K[‚ùå Zombie]

    style C fill:#ffcccc
    style D fill:#ffcccc
    style F fill:#ffcccc
    style J fill:#ffcccc
    style K fill:#ffcccc
```

### Flux am√©lior√© (apr√®s impl√©mentation)

```mermaid
flowchart TD
    A[GET /audit] --> V{Validation domaine<br/>‚úÖ Regex}
    V -->|Valide| B{Cache Redis?<br/>‚úÖ TTL 1h}
    V -->|Invalide| Z[422 Error]

    B -->|Hit| C1[‚úÖ Cache hit<br/>Latence < 100ms]
    B -->|Miss| C2{Donn√©es OK?}

    C2 -->|Oui| D[build_complete_audit<br/>‚úÖ Optimis√©<br/>‚úÖ Cache result]
    C2 -->|Non| E{‚úÖ Orchestrator existant?}

    E -->|Oui| F[‚úÖ Retourner existant]
    E -->|Non| G[Cr√©er orchestrator]

    G --> H[run_missing_workflows_chain<br/>‚úÖ Try/catch individuels]
    H --> I[Workflow 1]
    I -->|Succ√®s| J[Workflow 2]
    J -->|√âchec| K[‚úÖ Log + Continue]
    K --> L[Workflow 3]
    L --> M[‚úÖ Statut partial]

    H -.->|> MAX_DURATION| N[‚úÖ Cleanup timeout]

    D --> O[‚úÖ M√©triques Prometheus]
    M --> O

    style C1 fill:#ccffcc
    style D fill:#ccffcc
    style F fill:#ccffcc
    style K fill:#ccffcc
    style M fill:#ccffcc
    style N fill:#ccffcc
    style O fill:#ccffcc
```

---

## Impact estim√©

### Avant am√©liorations

- Latence moyenne : **5-15s** (sans cache)
- Taux d'√©chec : **15-20%** (erreurs transitoires)
- Duplications : **5-10%** (race conditions)
- Orchestrators zombies : **2-5%**

### Apr√®s am√©liorations

- Latence moyenne : **<100ms** (cache hit) / **2-3s** (cache miss)
- Taux d'√©chec : **<5%** (retry automatique)
- Duplications : **0%** (v√©rification existant)
- Orchestrators zombies : **0%** (timeout + cleanup)

**ROI** :
- üöÄ Latence r√©duite de **80-95%**
- üõ°Ô∏è Fiabilit√© augment√©e de **75%**
- üí∞ Co√ªts r√©duits de **50%** (moins de workflows dupliqu√©s)
- üìä Observabilit√© compl√®te (m√©triques + logs)

---
