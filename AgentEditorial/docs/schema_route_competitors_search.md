# Sch√©ma de Base de Donn√©es et Fonctionnalit√©s - Route POST /api/v1/competitors/search

## Vue d'ensemble

La route `POST /api/v1/competitors/search` lance une recherche de concurrents pour un domaine donn√©. Elle utilise un pipeline de validation en 12 √©tapes avec recherche multi-sources et classification LLM.

## Flux d'ex√©cution

1. **Cr√©ation de l'ex√©cution** ‚Üí `workflow_executions`
2. **Recherche du profil client** ‚Üí `site_profiles` (READ)
3. **Pipeline de recherche concurrents** (12 √©tapes) :
   - Recherche multi-sources (Tavily, DuckDuckGo)
   - Filtrage et classification
   - Enrichissement des candidats
   - Scoring et ranking
4. **Sauvegarde des r√©sultats** ‚Üí `workflow_executions` (UPDATE)

## Tables impact√©es

### 1. `workflow_executions` ‚≠ê **CRITIQUE**
- **Op√©ration** : CREATE, UPDATE, READ
- **Description** : Enregistre l'ex√©cution du workflow de recherche de concurrents
- **Champs impact√©s** :
  - `execution_id` (UUID, unique)
  - `workflow_type` = "competitor_search"
  - `status` : "pending" ‚Üí "running" ‚Üí "completed" ou "failed"
  - `input_data` : `{"domain": "...", "max_competitors": ...}`
  - `output_data` : R√©sultats de la recherche avec :
    - `competitors` : Liste des concurrents valid√©s
    - `all_candidates` : Tous les candidats √©valu√©s (inclus + exclus)
    - `excluded_candidates` : Candidats exclus uniquement
    - `total_found` : Nombre de concurrents trouv√©s
    - `total_evaluated` : Nombre total de candidats √©valu√©s
  - `start_time`, `end_time`, `duration_seconds`
  - `was_success` : true/false
  - `error_message` : si √©chec

### 2. `site_profiles` üìñ **LECTURE SEULE**
- **Op√©ration** : READ
- **Description** : Profil √©ditorial du site client (pour enrichir la recherche)
- **Champs lus** :
  - `domain`
  - `activity_domains` (JSONB) : Domaines d'activit√©
  - `keywords` (JSONB) : Mots-cl√©s
  - `target_audience` (JSONB) : Audience cible
  - `editorial_tone` : Ton √©ditorial
  - `language_level` : Niveau de langue

## Diagramme de relations

```
workflow_executions (1)
    ‚îÇ
    ‚îî‚îÄ‚îÄ> output_data.competitors (JSONB) [r√©sultats stock√©s dans JSON]
    ‚îÇ
site_profiles (1) [READ ONLY]
    ‚îÇ
    ‚îî‚îÄ‚îÄ> Utilis√© pour enrichir les requ√™tes de recherche
```

## Fonctionnalit√©s utilis√©es

### 1. **Recherche Multi-Sources** üîç

#### 1.1 Tavily API
- **Type** : API externe (recherche web s√©mantique)
- **Usage** : Recherche de concurrents via requ√™tes s√©mantiques
- **Configuration** : N√©cessite `TAVILY_API_KEY` dans `.env`
- **Limite** : `max_results_tavily` = 20 r√©sultats par requ√™te
- **Fonction** : `_search_tavily(query: str)`

#### 1.2 DuckDuckGo
- **Type** : Biblioth√®que Python (`ddgs`)
- **Usage** : Recherche web alternative/compl√©mentaire
- **Limite** : `max_results_duckduckgo` = 20 r√©sultats par requ√™te
- **Fonction** : `_search_duckduckgo(query: str)`

### 2. **G√©n√©ration de Requ√™tes** üìù

#### 2.1 QueryGenerator
- **Classe** : `QueryGenerator`
- **Fonctionnalit√©** : G√©n√®re des requ√™tes de recherche optimis√©es
- **Strat√©gies** :
  - Requ√™tes bas√©es sur le domaine
  - Requ√™tes bas√©es sur les domaines d'activit√©
  - Requ√™tes bas√©es sur les mots-cl√©s du profil client
  - Requ√™tes combin√©es
- **Limite** : `max_queries` = 50 requ√™tes maximum

### 3. **Pipeline de Validation en 12 √âtapes** üîÑ

#### √âtape 1 : Recherche Multi-Sources
- **Fonction** : Recherche via Tavily et DuckDuckGo
- **R√©sultat** : Liste brute de candidats potentiels

#### √âtape 2 : D√©duplication
- **Fonction** : Suppression des doublons par domaine
- **Crit√®re** : Normalisation du domaine (lowercase, sans www)

#### √âtape 3 : Pre-Filtrage
- **Classe** : `PreFilter`
- **Fonctionnalit√©** : Filtrage basique
  - Exclusion des domaines dans les listes d'exclusion
  - Exclusion des TLDs non autoris√©s
  - Filtrage des domaines invalides

#### √âtape 4 : Filtrage par Domaine
- **Classe** : `DomainFilter`
- **Fonctionnalit√©** : Filtrage avanc√© des domaines
  - Exclusion des domaines du client
  - Exclusion des domaines d√©j√† connus comme non-pertinents

#### √âtape 5 : Enrichissement
- **Classe** : `CandidateEnricher`
- **Fonctionnalit√©** : Enrichissement des candidats
  - R√©cup√©ration des m√©tadonn√©es (titre, description)
  - Validation g√©ographique (via API si disponible)
  - Cross-validation (v√©rification multi-sources)
- **Limite** : `max_candidates_to_enrich` = 50 candidats

#### √âtape 6 : Filtrage LLM
- **Classe** : `RelevanceClassifier`
- **Fonctionnalit√©** : Classification par LLM (phi3:medium)
  - √âvaluation de la pertinence
  - D√©tection des faux positifs
  - Score de pertinence (0-1)

#### √âtape 7 : Filtrage M√©dia
- **Classe** : `MediaFilter`
- **Fonctionnalit√©** : Exclusion des sites m√©dias/presse
  - D√©tection des sites de presse
  - Exclusion automatique

#### √âtape 8 : Validation du Contenu
- **Classe** : `ContentFilter`
- **Fonctionnalit√©** : Validation du contenu
  - V√©rification de la pr√©sence de contenu √©ditorial
  - Exclusion des sites vides ou non-√©ditoriaux

#### √âtape 9 : Classification et Scoring
- **Classes** :
  - `ESNClassifier` : D√©tection des ESN (Entreprises de Services du Num√©rique)
  - `BusinessTypeClassifier` : Classification par type d'entreprise
  - `GeographicClassifier` : Classification g√©ographique
  - `CompetitorScorer` : Calcul des scores
- **Scores calcul√©s** :
  - `relevance_score` : Score de pertinence (LLM)
  - `semantic_similarity` : Similarit√© s√©mantique (si Qdrant utilis√©)
  - `confidence_score` : Score de confiance
  - `combined_score` : Score combin√© (poids configur√©s)
- **Poids** :
  - `weight_llm_score` = 0.50
  - `weight_semantic_similarity` = 0.25
  - `bonus_cross_validation` = 0.15
  - `bonus_geographic` = 0.10

#### √âtape 10 : Assurance de Diversit√©
- **Fonctionnalit√©** : Garantir la diversit√© des r√©sultats
  - Limite par cat√©gorie d'entreprise
  - Distribution √©quilibr√©e
  - Ranking final

#### √âtape 11 : Calcul du Score de Confiance
- **Fonctionnalit√©** : Calcul du score de confiance final
  - Bas√© sur la coh√©rence des signaux
  - Validation multi-sources

#### √âtape 12 : Filtrage Final
- **Classe** : `CompetitorScorer`
- **Fonctionnalit√©** : Filtrage final avec seuils ajust√©s
  - `min_relevance_score` = 0.45
  - `min_confidence_score` = 0.35
  - `min_combined_score` = 0.35
  - Limitation √† `max_competitors`

### 4. **Services Externes** üåê

#### 4.1 Tavily API
- **Endpoint** : `https://api.tavily.com/search`
- **Authentification** : API Key
- **Usage** : Recherche s√©mantique web
- **Configuration** : `TAVILY_API_KEY` dans `.env`

#### 4.2 DuckDuckGo
- **Type** : Biblioth√®que Python (`ddgs`)
- **Usage** : Recherche web gratuite
- **Pas d'authentification requise**

#### 4.3 LLM (Ollama)
- **Mod√®le** : `phi3:medium`
- **Usage** : Classification et filtrage LLM
- **Configuration** : `OLLAMA_BASE_URL` dans `.env`
- **Fonction** : √âvaluation de pertinence des candidats

#### 4.4 Qdrant (Optionnel)
- **Usage** : Recherche s√©mantique pour similarit√©
- **Collection** : `competitor_articles`
- **Fonction** : Calcul de similarit√© s√©mantique si disponible

### 5. **Listes d'Exclusion** üö´

Le syst√®me utilise des listes d'exclusion configur√©es dans `CompetitorSearchConfig` :

- **Domaines exclus** : Liste de domaines √† exclure
- **TLDs exclus** : Extensions de domaine exclues
- **Outils SEO/Analytics** : Exclusion automatique
- **M√©dias et presse** : Exclusion via `MediaFilter`
- **Plateformes de listing** : Exclusion automatique
- **Sites d'emploi** : Exclusion automatique
- **E-commerce** : Exclusion automatique
- **Universit√©s** : Exclusion automatique
- **Services publics** : Exclusion automatique
- **Sites de reprise d'entreprises** : Exclusion automatique
- **Annuaires** : Exclusion automatique

## Ordre d'impact

1. **Phase initiale** :
   - `workflow_executions` (CREATE)
   - `site_profiles` (READ)

2. **Phase recherche** :
   - Appels API externes (Tavily, DuckDuckGo)
   - Pas d'√©criture en base

3. **Phase traitement** :
   - Pipeline de validation (12 √©tapes)
   - Classification LLM
   - Pas d'√©criture en base (traitement en m√©moire)

4. **Phase sauvegarde** :
   - `workflow_executions` (UPDATE avec r√©sultats)

## Structure des donn√©es dans output_data

```json
{
  "competitors": [
    {
      "domain": "example.com",
      "url": "https://example.com",
      "title": "Example Site",
      "reason": "Similar activity domains",
      "source": "tavily",
      "relevance_score": 0.85,
      "confidence_score": 0.78,
      "combined_score": 0.82,
      "business_type": "entreprise",
      "geographic_match": true,
      "cross_validation": true,
      "included": true,
      "status": "included"
    }
  ],
  "all_candidates": [...],  // Tous les candidats √©valu√©s
  "excluded_candidates": [...],  // Candidats exclus uniquement
  "total_found": 15,
  "total_evaluated": 127,
  "domain": "client-domain.com"
}
```

## Notes importantes

- ‚≠ê **CRITIQUE** : Table essentielle pour le fonctionnement de la route
- üìñ **LECTURE SEULE** : Table lue mais non modifi√©e
- üîç **EXTERNE** : Service externe (API, biblioth√®que)
- üîÑ **PIPELINE** : Traitement en m√©moire, pas d'√©criture directe en base

- Les r√©sultats sont stock√©s dans `workflow_executions.output_data` (JSONB)
- Aucune table d√©di√©e aux concurrents n'est cr√©√©e
- Le pipeline peut traiter jusqu'√† 50 requ√™tes √ó 20 r√©sultats = 1000+ candidats initiaux
- Le filtrage r√©duit √† ~10-100 candidats √©valu√©s
- Le r√©sultat final est limit√© √† `max_competitors` (par d√©faut 10-100)

## D√©pendances externes

- **Tavily API** : Requis (avec cl√© API)
- **DuckDuckGo** : Optionnel (biblioth√®que Python)
- **Ollama (phi3:medium)** : Requis pour le filtrage LLM
- **Qdrant** : Optionnel (pour similarit√© s√©mantique)

## Performance

- **Dur√©e typique** : 30-120 secondes selon le nombre de requ√™tes
- **Limites** :
  - `max_queries` = 50
  - `max_results_tavily` = 20
  - `max_results_duckduckgo` = 20
  - `max_candidates_to_enrich` = 50
  - `max_competitors` = 100 (par d√©faut)




