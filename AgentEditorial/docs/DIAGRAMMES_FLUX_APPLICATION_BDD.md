# Diagrammes de Flux - Application et Base de DonnÃ©es

## Vue d'ensemble

Ce document prÃ©sente les diagrammes de flux de l'application **Agent Ã‰ditorial & Concurrentiel** et de sa base de donnÃ©es PostgreSQL.

---

## 1. Diagramme de Flux de l'Application

### 1.1 Architecture GÃ©nÃ©rale

```mermaid
flowchart TB
    Client[ğŸ‘¤ Client/Application<br/>ğŸ“± Frontend/API Client]
    API[ğŸš€ FastAPI API<br/>ğŸŒ Port 8000<br/>ğŸ“¡ REST + WebSocket]
    
    subgraph Routes["ğŸ“‹ Routes API"]
        direction TB
        Health[ğŸ’š Health Check<br/>/health]
        Sites[ğŸ¢ Sites<br/>/sites/analyze]
        Competitors[ğŸ” Competitors<br/>/competitors/search]
        Discovery[ğŸ” Discovery<br/>/discovery/scrape]
        Trend[ğŸ“ˆ Trend Pipeline<br/>/trend-pipeline/analyze]
        Executions[âš™ï¸ Executions<br/>/executions/{id}]
        Errors[âŒ Errors<br/>/errors]
        Articles[ğŸ“ Articles<br/>/articles/enrich]
    end
    
    subgraph Agents["ğŸ¤– Agents Multi-LLM"]
        direction TB
        Editorial[ğŸ“Š Editorial Analysis<br/>Agent]
        Competitor[ğŸ¯ Competitor Search<br/>Agent]
        Scraping[ğŸ•·ï¸ Enhanced Scraping<br/>Agent]
        TrendPipeline[ğŸ“ˆ Trend Pipeline<br/>Agent]
    end
    
    subgraph Services["ğŸŒ Services Externes"]
        direction TB
        LLM[ğŸ§  LLM Models<br/>Llama3 ğŸ¤–<br/>Mistral ğŸŒŠ<br/>Phi3 âš¡]
        Qdrant[ğŸ” Qdrant Vector DB<br/>ğŸ“Š Embeddings]
        Tavily[ğŸ” Tavily Search API<br/>ğŸŒ Web Search]
        DuckDuckGo[ğŸ¦† DuckDuckGo API<br/>ğŸ” Search]
    end
    
    subgraph Database["ğŸ’¾ PostgreSQL Database"]
        direction TB
        Tables[(ğŸ—„ï¸ Tables de donnÃ©es<br/>ğŸ“Š 20+ tables)]
    end
    
    Client -->|HTTP/WebSocket| API
    API -->|Route| Routes
    Routes -->|Execute| Agents
    Agents -->|Query| LLM
    Agents -->|Store/Query| Qdrant
    Agents -->|Search| Tavily
    Agents -->|Search| DuckDuckGo
    Agents -->|CRUD| Database
    Database -->|Persist| Tables
    
    style Client fill:#4a90e2,stroke:#2c5aa0,stroke-width:3px,color:#fff
    style API fill:#50c878,stroke:#2d7a4e,stroke-width:3px,color:#fff
    style Routes fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style Agents fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style Services fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style Database fill:#9370db,stroke:#5e4a9e,stroke-width:3px,color:#fff
    style LLM fill:#ff6b6b,stroke:#c92a2a,stroke-width:2px,color:#fff
    style Qdrant fill:#ffa500,stroke:#cc8500,stroke-width:2px,color:#fff
```

### 1.2 Flux Fonctionnel Principal

```mermaid
flowchart TD
    Start([ğŸš€ DÃ©marrage Application])
    
    subgraph Workflow1["ğŸ“Š 1. Analyse Ã‰ditoriale"]
        direction TB
        A1[ğŸ“¥ POST /sites/analyze<br/>Domain: innosys.fr]
        A2[ğŸ“ CrÃ©er workflow_execution<br/>type: editorial_analysis]
        A3[ğŸ” DÃ©couvrir URLs<br/>via Sitemap]
        A4[ğŸ•·ï¸ Crawler les pages<br/>httpx + robots.txt]
        A5[ğŸ§  Analyse LLM<br/>Multi-modÃ¨les]
        A6[ğŸ’¾ CrÃ©er/Mettre Ã  jour<br/>site_profile]
        A7[ğŸ“Š Sauvegarder<br/>site_analysis_results]
    end
    
    subgraph Workflow2["ğŸ” 2. Recherche Concurrents"]
        direction TB
        B1[ğŸ“¥ POST /competitors/search<br/>Domain: innosys.fr]
        B2[ğŸ“ CrÃ©er workflow_execution<br/>type: competitor_search]
        B3[ğŸŒ Recherche Tavily<br/>+ DuckDuckGo]
        B4[âœ… Validation LLM<br/>des candidats]
        B5[ğŸ’¾ Sauvegarder<br/>concurrents validÃ©s]
    end
    
    subgraph Workflow3["ğŸ•·ï¸ 3. Scraping AmÃ©liorÃ©"]
        direction TB
        C1[ğŸ“¥ POST /discovery/scrape<br/>Domains: concurrents]
        C2[ğŸ“ CrÃ©er workflow_execution<br/>type: enhanced_scraping]
        C3[ğŸ” Phase 0: Profiling<br/>CMS, APIs, RSS]
        C4[ğŸ“¡ Phase 1: Discovery<br/>Multi-sources]
        C5[ğŸ“Š Phase 2: Scoring<br/>ProbabilitÃ© articles]
        C6[âœ‚ï¸ Phase 3: Extraction<br/>Adaptive extractors]
        C7[ğŸ’¾ Sauvegarder<br/>competitor_articles]
    end
    
    subgraph Workflow4["ğŸ“ˆ 4. Trend Pipeline"]
        direction TB
        D1[ğŸ“¥ POST /trend-pipeline/analyze<br/>client_domain: innosys.fr]
        D2[ğŸ“ CrÃ©er workflow_execution<br/>type: trend_pipeline]
        D3[ğŸ¯ Stage 1: Clustering<br/>BERTopic + HDBSCAN]
        D4[â±ï¸ Stage 2: Analyse Temporelle<br/>Volume, Velocity, Freshness]
        D5[ğŸ§  Stage 3: Enrichissement LLM<br/>Trend synthesis]
        D6[ğŸ“Š Stage 4: Gap Analysis<br/>Coverage & Roadmap]
        D7[ğŸ’¾ Sauvegarder rÃ©sultats<br/>Topics, Trends, Gaps]
    end
    
    Start --> A1
    A1 --> A2 --> A3 --> A4 --> A5 --> A6 --> A7
    
    Start --> B1
    B1 --> B2 --> B3 --> B4 --> B5
    
    Start --> C1
    C1 --> C2 --> C3 --> C4 --> C5 --> C6 --> C7
    
    Start --> D1
    D1 --> D2 --> D3 --> D4 --> D5 --> D6 --> D7
    
    A7 -.->|ğŸ”„ Peut dÃ©clencher| C1
    B5 -.->|ğŸ“‹ Fournit domaines| C1
    C7 -.->|ğŸ“š Fournit articles| D1
    
    style Start fill:#4a90e2,stroke:#2c5aa0,stroke-width:3px,color:#fff
    style Workflow1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style Workflow2 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style Workflow3 fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style Workflow4 fill:#fff3e0,stroke:#f57c00,stroke-width:2px
```

### 1.3 Flux DÃ©taillÃ© - Analyse Ã‰ditoriale

```mermaid
sequenceDiagram
    participant Client as ğŸ‘¤ Client
    participant API as ğŸš€ FastAPI Router
    participant DB as ğŸ’¾ PostgreSQL
    participant Orchestrator as ğŸ¯ Orchestrator
    participant Sitemap as ğŸ” Sitemap Discovery
    participant Crawler as ğŸ•·ï¸ Page Crawler
    participant LLM as ğŸ§  Multi-LLM Agent
    participant Scraper as ğŸ” Scraping Agent
    
    Client->>API: ğŸ“¥ POST /api/v1/sites/analyze<br/>{domain: "innosys.fr", max_pages: 10}
    API->>DB: ğŸ“ CREATE workflow_execution<br/>(status: pending, type: editorial_analysis)
    DB-->>API: âœ… execution_id (UUID)
    API-->>Client: âœ… 202 Accepted<br/>{execution_id, status: pending}
    
    rect rgb(200, 220, 255)
        Note over API,Scraper: ğŸ”„ Background Task
    end
    
    API->>Orchestrator: ğŸš€ run_editorial_analysis(domain, execution_id)
    Orchestrator->>DB: ğŸ”„ UPDATE workflow_execution<br/>(status: running)
    
    rect rgb(220, 255, 220)
        Note over Orchestrator,Sitemap: ğŸ“ Phase 1: Discovery
        Orchestrator->>Sitemap: ğŸ” get_sitemap_urls(domain)
        Sitemap-->>Orchestrator: ğŸ“‹ List of URLs
    end
    
    rect rgb(255, 255, 200)
        Note over Orchestrator,Crawler: ğŸ•·ï¸ Phase 2: Crawling
        Orchestrator->>Crawler: ğŸ“¥ crawl_multiple_pages(urls)
        Crawler->>Crawler: ğŸ¤– Check robots.txt
        Crawler->>Crawler: ğŸŒ Fetch pages (httpx)
        Crawler-->>Orchestrator: ğŸ“„ Crawled content
    end
    
    Orchestrator->>Orchestrator: ğŸ”— Combine all pages content
    
    rect rgb(255, 200, 200)
        Note over Orchestrator,LLM: ğŸ§  Phase 3: LLM Analysis
        Orchestrator->>LLM: ğŸš€ execute(combined_content)
        LLM->>LLM: ğŸ¤– Llama3: Editorial style
        LLM->>LLM: ğŸŒŠ Mistral: Content structure
        LLM->>LLM: âš¡ Phi3: Keywords & domains
        LLM-->>Orchestrator: âœ… Analysis results
    end
    
    rect rgb(200, 255, 255)
        Note over Orchestrator,DB: ğŸ’¾ Phase 4: Persistence
        Orchestrator->>DB: ğŸ’¾ CREATE/UPDATE site_profile<br/>(domain, language_level, editorial_tone, etc.)
        Orchestrator->>DB: ğŸ’¾ CREATE site_analysis_results<br/>(site_profile_id, execution_id, phase_results)
        Orchestrator->>DB: âœ… UPDATE workflow_execution<br/>(status: completed, output_data)
    end
    
    rect rgb(255, 220, 220)
        Note over API,Scraper: ğŸ”„ Background Scraping (optional)
        Orchestrator->>Scraper: ğŸ•·ï¸ Auto-scrape client site
        Scraper->>DB: ğŸ’¾ CREATE client_articles
        Scraper->>DB: ğŸ’¾ CREATE site_discovery_profiles
    end
```

### 1.4 Flux DÃ©taillÃ© - Trend Pipeline

```mermaid
flowchart TD
    Start([ğŸ“¥ POST /trend-pipeline/analyze<br/>client_domain: innosys.fr])
    
    CreateExec[ğŸ“ CrÃ©er workflow_execution<br/>type: trend_pipeline<br/>status: running]
    
    subgraph Stage1["ğŸ¯ Stage 1: Clustering"]
        direction TB
        S1A[ğŸ“š RÃ©cupÃ©rer articles<br/>concurrents]
        S1B[ğŸ”¢ GÃ©nÃ©rer embeddings<br/>Vector DB]
        S1C[ğŸ¯ BERTopic clustering<br/>Topic discovery]
        S1D[ğŸ“Š HDBSCAN outliers<br/>Outlier detection]
        S1E[ğŸ’¾ Sauvegarder<br/>topic_clusters]
        S1F[ğŸ’¾ Sauvegarder<br/>topic_outliers]
    end
    
    subgraph Stage2["â±ï¸ Stage 2: Temporal Analysis"]
        direction TB
        S2A[ğŸ“ˆ Calculer mÃ©triques<br/>temporelles]
        S2B[ğŸ“Š Volume, Velocity<br/>Freshness]
        S2C[ğŸ’¾ Sauvegarder<br/>topic_temporal_metrics]
    end
    
    subgraph Stage3["ğŸ§  Stage 3: LLM Enrichment"]
        direction TB
        S3A[âœ¨ Enrichir chaque topic<br/>avec LLM]
        S3B[ğŸ“ GÃ©nÃ©rer recommandations<br/>d'articles]
        S3C[ğŸ’¾ Sauvegarder<br/>trend_analysis]
        S3D[ğŸ’¾ Sauvegarder<br/>article_recommendations]
        S3E[ğŸ’¾ Sauvegarder<br/>weak_signals_analysis]
    end
    
    subgraph Stage4["ğŸ“Š Stage 4: Gap Analysis"]
        direction TB
        S4A[ğŸ” Analyser couverture<br/>client]
        S4B[ğŸ’ª Identifier forces<br/>client]
        S4C[âš ï¸ Identifier gaps<br/>Ã©ditoriaux]
        S4D[ğŸ—ºï¸ GÃ©nÃ©rer roadmap<br/>contenu]
        S4E[ğŸ’¾ Sauvegarder<br/>client_coverage_analysis]
        S4F[ğŸ’¾ Sauvegarder<br/>client_strengths]
        S4G[ğŸ’¾ Sauvegarder<br/>editorial_gaps]
        S4H[ğŸ’¾ Sauvegarder<br/>content_roadmap]
    end
    
    Final[âœ… UPDATE workflow_execution<br/>status: completed<br/>was_success: true]
    
    Start --> CreateExec
    CreateExec --> S1A
    S1A --> S1B --> S1C --> S1D --> S1E --> S1F
    S1F --> S2A
    S2A --> S2B --> S2C
    S2C --> S3A
    S3A --> S3B --> S3C --> S3D --> S3E
    S3E --> S4A
    S4A --> S4B --> S4C --> S4D --> S4E --> S4F --> S4G --> S4H
    S4H --> Final
    
    style Start fill:#4a90e2,stroke:#2c5aa0,stroke-width:3px,color:#fff
    style CreateExec fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style Stage1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style Stage2 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style Stage3 fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style Stage4 fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style Final fill:#50c878,stroke:#2d7a4e,stroke-width:3px,color:#fff
```

---

## 2. Diagramme de Flux de la Base de DonnÃ©es

### 2.1 SchÃ©ma EntitÃ©-Relation Complet (Vue d'ensemble)

```mermaid
flowchart TB
    subgraph Core["ğŸ’¾ Tables Principales"]
        SP[ğŸ¢ site_profiles<br/>Site Client]
        WE[âš™ï¸ workflow_executions<br/>ExÃ©cutions]
        SAR[ğŸ“Š site_analysis_results<br/>RÃ©sultats Analyse]
    end
    
    subgraph Editorial["ğŸ“Š Editorial Analysis"]
        CA[ğŸ“š client_articles<br/>Articles Client]
    end
    
    subgraph Competitor["ğŸ” Competitor & Scraping"]
        CompArt[ğŸ“° competitor_articles<br/>Articles Concurrents]
        SDP[ğŸ” site_discovery_profiles<br/>Profils DÃ©couverte]
        UDS[ğŸ“Š url_discovery_scores<br/>Scores URLs]
        DL[ğŸ“ discovery_logs<br/>Logs DÃ©couverte]
    end
    
    subgraph Trend["ğŸ“ˆ Trend Pipeline"]
        TPE[âš™ï¸ trend_pipeline_executions<br/>ExÃ©cutions Pipeline]
        TC[ğŸ¯ topic_clusters<br/>Clusters Topics]
        TO[ğŸ“Œ topic_outliers<br/>Outliers]
        TTM[â±ï¸ topic_temporal_metrics<br/>MÃ©triques Temporelles]
        TA[ğŸ“Š trend_analysis<br/>Analyses Tendances]
        AR[ğŸ“ article_recommendations<br/>Recommandations]
        WSA[ğŸ”® weak_signals_analysis<br/>Signaux Faibles]
        CCA[ğŸ” client_coverage_analysis<br/>Couverture Client]
        CS[ğŸ’ª client_strengths<br/>Forces Client]
        EG[âš ï¸ editorial_gaps<br/>Gaps Ã‰ditoriaux]
        CR[ğŸ—ºï¸ content_roadmap<br/>Roadmap Contenu]
    end
    
    subgraph Monitoring["ğŸ“Š Monitoring & Logs"]
        AL[ğŸ“‹ audit_logs<br/>Logs Audit]
        EL[âŒ error_logs<br/>Logs Erreurs]
        PM[ğŸ“ˆ performance_metrics<br/>MÃ©triques Performance]
    end
    
    subgraph Cache["ğŸ’¾ Cache"]
        CC[ğŸ”„ crawl_cache<br/>Cache Crawl]
        SPerm[ğŸ¤– scraping_permissions<br/>Permissions Scraping]
    end
    
    SP -->|1:N| SAR
    WE -->|1:N| SAR
    SP -->|1:N| CA
    WE -->|1:N| AL
    WE -->|1:N| EL
    WE -->|1:N| PM
    TPE -->|1:N| TC
    TPE -->|1:N| TO
    TPE -->|1:N| TTM
    TPE -->|1:N| TA
    TPE -->|1:N| AR
    TPE -->|1:N| WSA
    TPE -->|1:N| CCA
    TPE -->|1:N| CS
    TPE -->|1:N| EG
    TPE -->|1:N| CR
    TC -->|1:N| TTM
    TC -->|1:N| TA
    TC -->|1:N| AR
    TC -->|1:N| CCA
    TC -->|1:N| CS
    TC -->|1:N| EG
    EG -->|1:N| CR
    SDP -->|1:N| UDS
    SDP -->|1:N| DL
    
    style Core fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    style Editorial fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style Competitor fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style Trend fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style Monitoring fill:#ffebee,stroke:#c62828,stroke-width:2px
    style Cache fill:#f1f8e9,stroke:#558b2f,stroke-width:2px
```

### 2.1.1 SchÃ©ma EntitÃ©-Relation DÃ©taillÃ©

```mermaid
erDiagram
    %% Tables principales
    site_profiles ||--o{ site_analysis_results : "a plusieurs"
    workflow_executions ||--o{ site_analysis_results : "produit"
    site_profiles ||--o{ client_articles : "contient"
    
    %% Workflow executions et ses relations
    workflow_executions ||--o{ audit_logs : "gÃ©nÃ¨re"
    workflow_executions ||--o{ error_logs : "gÃ©nÃ¨re"
    workflow_executions ||--o{ performance_metrics : "mesure"
    workflow_executions ||--o| workflow_executions : "parent_execution_id"
    
    %% Trend Pipeline
    trend_pipeline_executions ||--o{ topic_clusters : "gÃ©nÃ¨re"
    trend_pipeline_executions ||--o{ topic_outliers : "gÃ©nÃ¨re"
    trend_pipeline_executions ||--o{ topic_temporal_metrics : "gÃ©nÃ¨re"
    trend_pipeline_executions ||--o{ trend_analysis : "gÃ©nÃ¨re"
    trend_pipeline_executions ||--o{ article_recommendations : "gÃ©nÃ¨re"
    trend_pipeline_executions ||--o{ weak_signals_analysis : "gÃ©nÃ¨re"
    trend_pipeline_executions ||--o{ client_coverage_analysis : "gÃ©nÃ¨re"
    trend_pipeline_executions ||--o{ client_strengths : "gÃ©nÃ¨re"
    trend_pipeline_executions ||--o{ editorial_gaps : "gÃ©nÃ¨re"
    trend_pipeline_executions ||--o{ content_roadmap : "gÃ©nÃ¨re"
    
    %% Scraping
    site_discovery_profiles ||--o{ url_discovery_scores : "score"
    site_discovery_profiles ||--o{ discovery_logs : "log"
    
    %% Tables
    site_profiles {
        int id PK
        string domain UK
        timestamp analysis_date
        string language_level
        string editorial_tone
        jsonb target_audience
        jsonb activity_domains
        jsonb content_structure
        jsonb keywords
        jsonb style_features
    }
    
    workflow_executions {
        int id PK
        uuid execution_id UK
        string workflow_type
        string status
        jsonb input_data
        jsonb output_data
        timestamp start_time
        timestamp end_time
        boolean was_success
    }
    
    site_analysis_results {
        int id PK
        int site_profile_id FK
        uuid execution_id FK
        string analysis_phase
        jsonb phase_results
        string llm_model_used
    }
    
    client_articles {
        int id PK
        int site_profile_id FK
        string url UK
        string title
        text content_text
        uuid qdrant_point_id
    }
    
    competitor_articles {
        int id PK
        string domain
        string url UK
        string title
        text content_text
        uuid qdrant_point_id
    }
    
    trend_pipeline_executions {
        int id PK
        uuid execution_id UK
        string client_domain
        jsonb domains_analyzed
        string stage_1_clustering_status
        string stage_2_temporal_status
        string stage_3_llm_status
        string stage_4_gap_status
    }
    
    topic_clusters {
        int id PK
        uuid analysis_id FK
        int topic_id
        string topic_name
        jsonb keywords
        int article_count
    }
    
    topic_temporal_metrics {
        int id PK
        uuid analysis_id FK
        int topic_cluster_id FK
        int volume
        float velocity
        float freshness
    }
    
    trend_analysis {
        int id PK
        uuid analysis_id FK
        int topic_cluster_id FK
        string trend_summary
        jsonb trend_details
    }
    
    article_recommendations {
        int id PK
        uuid analysis_id FK
        int topic_cluster_id FK
        string recommended_title
        jsonb recommended_content
    }
    
    client_coverage_analysis {
        int id PK
        uuid analysis_id FK
        string client_domain
        int topic_cluster_id FK
        float coverage_score
        jsonb coverage_details
    }
    
    client_strengths {
        int id PK
        uuid analysis_id FK
        string client_domain
        int topic_cluster_id FK
        float strength_score
        jsonb strength_details
    }
    
    editorial_gaps {
        int id PK
        uuid analysis_id FK
        string client_domain
        int topic_cluster_id FK
        string gap_type
        jsonb gap_details
    }
    
    content_roadmap {
        int id PK
        uuid analysis_id FK
        string client_domain
        int gap_topic_id FK
        string roadmap_item
        jsonb roadmap_details
    }
    
    site_discovery_profiles {
        int id PK
        string domain UK
        string cms_detected
        boolean has_rest_api
        jsonb api_endpoints
        jsonb sitemap_urls
        jsonb rss_feeds
    }
    
    url_discovery_scores {
        int id PK
        string domain
        string url
        float score
        jsonb score_details
    }
    
    discovery_logs {
        int id PK
        uuid execution_id
        string operation
        jsonb results
    }
    
    audit_logs {
        int id PK
        uuid execution_id FK
        string action
        string status
        text message
    }
    
    error_logs {
        int id PK
        uuid execution_id FK
        string error_type
        text error_message
        string component
    }
    
    performance_metrics {
        int id PK
        uuid execution_id FK
        string metric_type
        float metric_value
    }
```

### 2.2 Flux de DonnÃ©es - Workflow Editorial Analysis

```mermaid
flowchart LR
    subgraph Input["ğŸ“¥ Input"]
        Domain[ğŸŒ Domain<br/>innosys.fr]
        MaxPages[ğŸ“„ Max Pages<br/>10]
    end
    
    subgraph Create["ğŸ“ CrÃ©ation"]
        WE[ğŸ’¾ workflow_executions<br/>execution_id: UUID<br/>workflow_type: editorial_analysis<br/>status: pending â†’ running â†’ completed]
    end
    
    subgraph Process["âš™ï¸ Traitement"]
        SP[ğŸ¢ site_profiles<br/>domain: innosys.fr<br/>id: 15<br/>language_level, editorial_tone]
        SAR[ğŸ“Š site_analysis_results<br/>site_profile_id: 15<br/>execution_id: UUID<br/>phase: discovery, synthesis]
    end
    
    subgraph Output["ğŸ“¤ Output"]
        CA[ğŸ“š client_articles<br/>site_profile_id: 15<br/>Articles scrapÃ©s<br/>url, title, content]
        SDP[ğŸ” site_discovery_profiles<br/>domain: innosys.fr<br/>Profil de dÃ©couverte<br/>CMS, APIs, RSS]
    end
    
    Domain -->|input_data| WE
    MaxPages -->|input_data| WE
    WE -->|CREATE| SP
    WE -->|CREATE| SAR
    SP -->|FK: site_profile_id| SAR
    SAR -->|Trigger| CA
    SAR -->|Trigger| SDP
    
    style Input fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style Create fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style Process fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style Output fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
```

### 2.3 Flux de DonnÃ©es - Trend Pipeline

```mermaid
flowchart TD
    subgraph Input["ğŸ“¥ Input"]
        ClientDomain[ğŸŒ client_domain<br/>innosys.fr]
        TimeWindow[â±ï¸ time_window_days<br/>90 jours]
    end
    
    subgraph Execution["âš™ï¸ ExÃ©cution"]
        TPE[ğŸ’¾ trend_pipeline_executions<br/>execution_id: UUID<br/>client_domain: innosys.fr<br/>stages: 1â†’2â†’3â†’4]
    end
    
    subgraph Stage1["ğŸ¯ Stage 1: Clustering"]
        TC[ğŸ“Š topic_clusters<br/>topic_id, topic_name<br/>keywords, article_count]
        TO[ğŸ“Œ topic_outliers<br/>outlier articles<br/>non-clustered]
    end
    
    subgraph Stage2["â±ï¸ Stage 2: Temporal"]
        TTM[ğŸ“ˆ topic_temporal_metrics<br/>volume: nombre articles<br/>velocity: vitesse croissance<br/>freshness: rÃ©cence]
    end
    
    subgraph Stage3["ğŸ§  Stage 3: LLM"]
        TA[ğŸ“Š trend_analysis<br/>trend_summary<br/>trend_details JSON]
        AR[ğŸ“ article_recommendations<br/>recommended_title<br/>recommended_content]
        WSA[ğŸ”® weak_signals_analysis<br/>disruption_potential<br/>emerging trends]
    end
    
    subgraph Stage4["ğŸ“Š Stage 4: Gap"]
        CCA[ğŸ” client_coverage_analysis<br/>coverage_score<br/>coverage_details]
        CS[ğŸ’ª client_strengths<br/>strength_score<br/>strength_details]
        EG[âš ï¸ editorial_gaps<br/>gap_type<br/>gap_details]
        CR[ğŸ—ºï¸ content_roadmap<br/>roadmap_item<br/>roadmap_details]
    end
    
    ClientDomain -->|input_data| TPE
    TimeWindow -->|input_data| TPE
    TPE -->|CREATE| TC
    TPE -->|CREATE| TO
    TC -->|FK: topic_cluster_id| TTM
    TTM -->|FK: topic_cluster_id| TA
    TTM -->|FK: topic_cluster_id| AR
    TTM -->|FK: topic_cluster_id| WSA
    TA -->|FK: topic_cluster_id| CCA
    AR -->|FK: topic_cluster_id| CS
    CCA -->|FK: topic_cluster_id| EG
    EG -->|FK: gap_topic_id| CR
    
    style Input fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style Execution fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style Stage1 fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style Stage2 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style Stage3 fill:#ffebee,stroke:#c62828,stroke-width:2px
    style Stage4 fill:#f1f8e9,stroke:#558b2f,stroke-width:2px
```

### 2.4 Relations entre Workflows et Site Client

```mermaid
flowchart TB
    subgraph SiteClient["ğŸ¢ Site Client"]
        SP[ğŸ’¾ site_profiles<br/>id: 15<br/>domain: innosys.fr<br/>language_level, editorial_tone]
    end
    
    subgraph Workflows["âš™ï¸ Workflows"]
        direction TB
        WE1[ğŸ“Š workflow_executions<br/>execution_id: e855cd4f-...<br/>type: editorial_analysis<br/>âœ… LiÃ© via FK]
        WE2[ğŸ” workflow_executions<br/>execution_id: 378c14c4-...<br/>type: competitor_search<br/>âŒ RÃ©fÃ©rencÃ© dans input_data]
        WE3[ğŸ•·ï¸ workflow_executions<br/>execution_id: 19b5ba22-...<br/>type: enhanced_scraping<br/>âŒ RÃ©fÃ©rencÃ© dans input_data]
        WE4[ğŸ“ˆ workflow_executions<br/>execution_id: 08083962-...<br/>type: trend_pipeline<br/>âŒ RÃ©fÃ©rencÃ© dans input_data]
    end
    
    subgraph Results["ğŸ“Š RÃ©sultats"]
        direction TB
        SAR[ğŸ“‹ site_analysis_results<br/>site_profile_id: 15<br/>execution_id: e855cd4f-...<br/>phase: discovery, synthesis]
        CA[ğŸ“š client_articles<br/>site_profile_id: 15<br/>Articles du client]
        CompArt[ğŸ“° competitor_articles<br/>domain: concurrents<br/>Articles des concurrents]
        TPE[ğŸ“ˆ trend_pipeline_executions<br/>client_domain: innosys.fr<br/>RÃ©sultats Trend Pipeline]
    end
    
    SP -->|FK: site_profile_id| SAR
    SP -->|FK: site_profile_id| CA
    WE1 -->|FK: execution_id| SAR
    WE2 -.->|input_data.domain<br/>"innosys.fr"| CompArt
    WE3 -.->|input_data.domain<br/>"concurrents"| CompArt
    WE4 -.->|input_data.client_domain<br/>"innosys.fr"| TPE
    
    style SiteClient fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    style Workflows fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style Results fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style WE1 fill:#50c878,stroke:#2d7a4e,stroke-width:2px,color:#fff
    style WE2 fill:#ff9800,stroke:#cc7700,stroke-width:2px,color:#fff
    style WE3 fill:#ff9800,stroke:#cc7700,stroke-width:2px,color:#fff
    style WE4 fill:#ff9800,stroke:#cc7700,stroke-width:2px,color:#fff
```

---

## 3. Routes API et FonctionnalitÃ©s

### 3.1 Liste des Routes Principales

| Route | MÃ©thode | Description | Workflow Type |
|-------|---------|-------------|---------------|
| `/api/v1/health` | GET | Health check | - |
| `/api/v1/sites/analyze` | POST | Analyse Ã©ditoriale | `editorial_analysis` |
| `/api/v1/sites/{domain}` | GET | Profil du site | - |
| `/api/v1/competitors/search` | POST | Recherche concurrents | `competitor_search` |
| `/api/v1/competitors/{domain}` | GET | Concurrents d'un domaine | - |
| `/api/v1/discovery/scrape` | POST | Scraping amÃ©liorÃ© | `enhanced_scraping` |
| `/api/v1/discovery/{domain}` | GET | Profil de dÃ©couverte | - |
| `/api/v1/trend-pipeline/analyze` | POST | Analyse des tendances | `trend_pipeline` |
| `/api/v1/trend-pipeline/{execution_id}` | GET | RÃ©sultats Trend Pipeline | - |
| `/api/v1/executions/{execution_id}` | GET | Statut d'exÃ©cution | - |
| `/api/v1/errors` | GET | Liste des erreurs | - |
| `/api/v1/articles/enrich` | POST | Enrichissement d'articles | - |

### 3.2 Types de Workflows

| Type | Objectif | Tables Principales | LiÃ© Ã  site_profiles ? |
|------|----------|-------------------|----------------------|
| `editorial_analysis` | Analyser le style Ã©ditorial | `site_profiles`, `site_analysis_results` | âœ… Oui (via FK) |
| `competitor_search` | Trouver les concurrents | - | âŒ Non (dans input_data) |
| `enhanced_scraping` | Scraper les articles | `competitor_articles`, `client_articles` | âš ï¸ Peut-Ãªtre |
| `trend_pipeline` | Analyser les tendances | `trend_pipeline_executions`, `topic_clusters`, etc. | âŒ Non (dans input_data) |

---

## 4. Explications DÃ©taillÃ©es

### 4.1 Relation Site Client â†” Workflows

**Point important** : Seul le workflow `editorial_analysis` est **directement liÃ©** Ã  `site_profiles` via la table de liaison `site_analysis_results`.

Les autres workflows (`competitor_search`, `enhanced_scraping`, `trend_pipeline`) rÃ©fÃ©rencent le domaine client dans leurs donnÃ©es d'entrÃ©e (`input_data.domain` ou `input_data.client_domain`) mais ne sont **pas liÃ©s** par une clÃ© Ã©trangÃ¨re.

### 4.2 Flux de DonnÃ©es Typique

1. **Analyse Ã‰ditoriale** â†’ CrÃ©e/met Ã  jour `site_profiles`
2. **Recherche Concurrents** â†’ Trouve les concurrents (stockÃ©s dans `output_data`)
3. **Scraping AmÃ©liorÃ©** â†’ Scrape les articles des concurrents â†’ `competitor_articles`
4. **Trend Pipeline** â†’ Analyse les tendances â†’ Tables du Trend Pipeline

### 4.3 RequÃªtes SQL Utiles

#### Trouver tous les workflows d'un site client

```sql
-- Workflows directement liÃ©s (editorial_analysis)
SELECT 
    we.execution_id,
    we.workflow_type,
    we.status,
    we.start_time
FROM workflow_executions we
INNER JOIN site_analysis_results sar 
    ON sar.execution_id = we.execution_id
INNER JOIN site_profiles sp 
    ON sp.id = sar.site_profile_id
WHERE sp.domain = 'innosys.fr';

-- Tous les workflows qui mentionnent le domaine
SELECT 
    execution_id,
    workflow_type,
    status,
    input_data->>'domain' as domain,
    input_data->>'client_domain' as client_domain
FROM workflow_executions
WHERE input_data->>'domain' = 'innosys.fr'
   OR input_data->>'client_domain' = 'innosys.fr';
```

#### Trouver les rÃ©sultats d'un Trend Pipeline

```sql
SELECT 
    tpe.execution_id,
    tpe.client_domain,
    COUNT(tc.id) as topics_count,
    COUNT(ar.id) as recommendations_count,
    COUNT(eg.id) as gaps_count
FROM trend_pipeline_executions tpe
LEFT JOIN topic_clusters tc ON tc.analysis_id = tpe.execution_id
LEFT JOIN article_recommendations ar ON ar.analysis_id = tpe.execution_id
LEFT JOIN editorial_gaps eg ON eg.analysis_id = tpe.execution_id
WHERE tpe.client_domain = 'innosys.fr'
GROUP BY tpe.execution_id, tpe.client_domain;
```

---

## 5. RÃ©sumÃ©

### Points ClÃ©s

1. âœ… **4 types de workflows principaux** : `editorial_analysis`, `competitor_search`, `enhanced_scraping`, `trend_pipeline`
2. âœ… **Seul `editorial_analysis` est liÃ© Ã  `site_profiles`** via `site_analysis_results`
3. âœ… **Les autres workflows** rÃ©fÃ©rencent le domaine dans `input_data`
4. âœ… **Chaque workflow est indÃ©pendant** et peut Ãªtre exÃ©cutÃ© plusieurs fois
5. âœ… **Le Trend Pipeline** a sa propre table d'exÃ©cution (`trend_pipeline_executions`)

### Architecture

- **API FastAPI** avec routes modulaires
- **Agents Multi-LLM** pour l'analyse
- **PostgreSQL** pour la persistance
- **Qdrant** pour les embeddings vectoriels
- **Services externes** : Tavily, DuckDuckGo

---

## 6. Diagramme Visuel - Cycle de Vie Complet

### 6.1 Cycle de Vie d'un Workflow Editorial Analysis

```mermaid
stateDiagram-v2
    [*] --> Pending: ğŸ“¥ POST /sites/analyze
    
    Pending: â³ Pending<br/>workflow_execution crÃ©Ã©<br/>execution_id gÃ©nÃ©rÃ©
    
    Pending --> Running: ğŸš€ Background Task Start
    
    Running: ğŸ”„ Running<br/>Orchestrator actif<br/>Phases en cours
    
    state Running {
        [*] --> Discovery
        Discovery: ğŸ” Discovery Phase<br/>Sitemap URLs
        Discovery --> Crawling
        Crawling: ğŸ•·ï¸ Crawling Phase<br/>Fetch pages
        Crawling --> Analysis
        Analysis: ğŸ§  LLM Analysis<br/>Multi-modÃ¨les
        Analysis --> Saving
        Saving: ğŸ’¾ Saving Results<br/>site_profile<br/>site_analysis_results
        Saving --> [*]
    }
    
    Running --> Completed: âœ… Success<br/>All phases done
    Running --> Failed: âŒ Error<br/>Exception caught
    
    Completed: âœ… Completed<br/>was_success: true<br/>output_data filled
    Failed: âŒ Failed<br/>was_success: false<br/>error_message set
    
    Completed --> [*]
    Failed --> [*]
    
    note right of Pending
        Client reÃ§oit execution_id
        Peut poller le statut
    end note
    
    note right of Running
        Phases exÃ©cutÃ©es:
        1. Discovery
        2. Crawling
        3. LLM Analysis
        4. Saving
    end note
    
    note right of Completed
        RÃ©sultats disponibles:
        - site_profile mis Ã  jour
        - site_analysis_results crÃ©Ã©s
        - client_articles (optionnel)
    end note
```

### 6.2 Vue d'Ensemble Visuelle - Architecture ComplÃ¨te

```mermaid
graph TB
    subgraph ClientLayer["ğŸ‘¤ Couche Client"]
        WebApp[ğŸŒ Web Application]
        MobileApp[ğŸ“± Mobile App]
        API_Client[ğŸ”Œ API Client]
    end
    
    subgraph APILayer["ğŸš€ Couche API"]
        FastAPI[âš¡ FastAPI Server<br/>Port 8000]
        WebSocket[ğŸ”Œ WebSocket<br/>Real-time Updates]
        REST[ğŸ“¡ REST API<br/>8 Routes]
    end
    
    subgraph BusinessLayer["ğŸ¤– Couche MÃ©tier"]
        Orchestrator[ğŸ¯ Orchestrator]
        EditorialAgent[ğŸ“Š Editorial Agent]
        CompetitorAgent[ğŸ” Competitor Agent]
        ScrapingAgent[ğŸ•·ï¸ Scraping Agent]
        TrendAgent[ğŸ“ˆ Trend Agent]
    end
    
    subgraph DataLayer["ğŸ’¾ Couche DonnÃ©es"]
        PostgreSQL[(ğŸ—„ï¸ PostgreSQL<br/>20+ Tables)]
        Qdrant[(ğŸ” Qdrant<br/>Vector DB)]
    end
    
    subgraph ExternalLayer["ğŸŒ Services Externes"]
        LLM_Services[ğŸ§  LLM Services<br/>Llama3 ğŸ¤–<br/>Mistral ğŸŒŠ<br/>Phi3 âš¡]
        SearchAPIs[ğŸ” Search APIs<br/>Tavily ğŸ”<br/>DuckDuckGo ğŸ¦†]
    end
    
    WebApp --> FastAPI
    MobileApp --> FastAPI
    API_Client --> FastAPI
    FastAPI --> WebSocket
    FastAPI --> REST
    REST --> Orchestrator
    Orchestrator --> EditorialAgent
    Orchestrator --> CompetitorAgent
    Orchestrator --> ScrapingAgent
    Orchestrator --> TrendAgent
    EditorialAgent --> LLM_Services
    CompetitorAgent --> SearchAPIs
    ScrapingAgent --> SearchAPIs
    TrendAgent --> LLM_Services
    EditorialAgent --> PostgreSQL
    CompetitorAgent --> PostgreSQL
    ScrapingAgent --> PostgreSQL
    TrendAgent --> PostgreSQL
    EditorialAgent --> Qdrant
    ScrapingAgent --> Qdrant
    TrendAgent --> Qdrant
    
    style ClientLayer fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    style APILayer fill:#50c878,stroke:#2d7a4e,stroke-width:3px,color:#fff
    style BusinessLayer fill:#fff3e0,stroke:#f57c00,stroke-width:3px
    style DataLayer fill:#9370db,stroke:#5e4a9e,stroke-width:3px,color:#fff
    style ExternalLayer fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px
```

### 6.3 Flux de DonnÃ©es Visuel - End-to-End

```mermaid
flowchart LR
    subgraph Input["ğŸ“¥ INPUT"]
        User[ğŸ‘¤ Utilisateur]
        Domain[ğŸŒ Domain: innosys.fr]
    end
    
    subgraph API["ğŸš€ API"]
        Request[ğŸ“¥ POST Request]
        Response[ğŸ“¤ Response<br/>execution_id]
    end
    
    subgraph Processing["âš™ï¸ PROCESSING"]
        Workflow[âš™ï¸ Workflow Execution]
        Agent[ğŸ¤– Agent Processing]
        LLM[ğŸ§  LLM Analysis]
    end
    
    subgraph Storage["ğŸ’¾ STORAGE"]
        DB[(ğŸ—„ï¸ PostgreSQL)]
        Vector[(ğŸ” Qdrant)]
    end
    
    subgraph Output["ğŸ“¤ OUTPUT"]
        Results[ğŸ“Š Results]
        Profile[ğŸ¢ Site Profile]
        Articles[ğŸ“š Articles]
    end
    
    User -->|Request| Request
    Domain -->|Input| Request
    Request -->|Create| Workflow
    Request -->|Return| Response
    Response -->|execution_id| User
    Workflow -->|Execute| Agent
    Agent -->|Query| LLM
    Agent -->|Save| DB
    Agent -->|Index| Vector
    DB -->|Read| Results
    DB -->|Read| Profile
    DB -->|Read| Articles
    Results -->|Display| User
    Profile -->|Display| User
    Articles -->|Display| User
    
    style Input fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style API fill:#50c878,stroke:#2d7a4e,stroke-width:3px,color:#fff
    style Processing fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style Storage fill:#9370db,stroke:#5e4a9e,stroke-width:3px,color:#fff
    style Output fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
```

---

## 7. Diagramme de Flux Principal - Workflow Complet (Style Processus)

### 7.1 Workflow Principal - De la Demande au RÃ©sultat Final

```mermaid
flowchart TD
    Start([ğŸŒ Demande Client<br/>Domain: innosys.fr])
    
    subgraph Inputs["ğŸ“¥ Inputs Externes"]
        Domain((ğŸŒ Domain<br/>innosys.fr))
        MaxPages((ğŸ“„ Max Pages<br/>10))
        TimeWindow((â±ï¸ Time Window<br/>90 jours))
    end
    
    subgraph Init["ğŸš€ Initialisation"]
        CreateWE[ğŸ“ CrÃ©er workflow_execution<br/>type: editorial_analysis<br/>status: pending]
    end
    
    subgraph Analysis["ğŸ“Š Analyse Ã‰ditoriale"]
        Discovery[ğŸ” DÃ©couverte URLs<br/>Sitemap]
        Crawling[ğŸ•·ï¸ Crawling Pages<br/>httpx + robots.txt]
        LLMAnalysis[ğŸ§  Analyse LLM<br/>Multi-modÃ¨les]
    end
    
    subgraph Profile["ğŸ¢ Profil Site"]
        CreateProfile[ğŸ’¾ CrÃ©er/Mettre Ã  jour<br/>site_profiles<br/>id: 15]
        SaveResults[ğŸ“Š Sauvegarder<br/>site_analysis_results<br/>site_profile_id: 15]
    end
    
    subgraph Workflows["âš™ï¸ Workflows ParallÃ¨les"]
        direction TB
        CompSearch[ğŸ” Recherche Concurrents<br/>competitor_search]
        Scraping[ğŸ•·ï¸ Scraping AmÃ©liorÃ©<br/>enhanced_scraping]
        TrendPipe[ğŸ“ˆ Trend Pipeline<br/>trend_pipeline]
    end
    
    subgraph Results["ğŸ“Š RÃ©sultats"]
        direction TB
        ClientArticles[ğŸ“š client_articles<br/>Articles du client]
        CompArticles[ğŸ“° competitor_articles<br/>Articles concurrents]
        Trends[ğŸ“ˆ Topics & Trends<br/>topic_clusters<br/>trend_analysis]
        Gaps[âš ï¸ Gaps & Roadmap<br/>editorial_gaps<br/>content_roadmap]
    end
    
    subgraph Final["âœ… Finalisation"]
        Distribution[ğŸ“¤ Distribution<br/>RÃ©sultats disponibles<br/>via API]
    end
    
    Start --> CreateWE
    Domain --> Discovery
    MaxPages --> Crawling
    CreateWE --> Discovery
    Discovery --> Crawling
    Crawling --> LLMAnalysis
    LLMAnalysis --> CreateProfile
    CreateProfile --> SaveResults
    
    SaveResults --> CompSearch
    SaveResults --> Scraping
    SaveResults --> TrendPipe
    
    TimeWindow --> TrendPipe
    
    CompSearch --> CompArticles
    Scraping --> CompArticles
    Scraping --> ClientArticles
    TrendPipe --> Trends
    TrendPipe --> Gaps
    
    CompArticles --> Distribution
    ClientArticles --> Distribution
    Trends --> Distribution
    Gaps --> Distribution
    
    style Start fill:#4a90e2,stroke:#2c5aa0,stroke-width:3px,color:#fff
    style Inputs fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style Init fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style Analysis fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style Profile fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style Workflows fill:#ffebee,stroke:#c62828,stroke-width:2px
    style Results fill:#f1f8e9,stroke:#558b2f,stroke-width:2px
    style Final fill:#50c878,stroke:#2d7a4e,stroke-width:3px,color:#fff
```

### 7.2 Workflow DÃ©taillÃ© - Relations Site Client et Workflows

```mermaid
flowchart TD
    ClientRequest([ğŸ‘¤ Demande Client<br/>POST /sites/analyze<br/>domain: innosys.fr])
    
    subgraph ExternalInputs["ğŸ“¥ Inputs Externes"]
        DomainInput((ğŸŒ Domain<br/>innosys.fr))
        ConfigInput((âš™ï¸ Configuration<br/>max_pages: 10))
    end
    
    subgraph Creation["ğŸ“ CrÃ©ation"]
        WorkflowExec[ğŸ“ workflow_executions<br/>execution_id: UUID<br/>workflow_type: editorial_analysis<br/>status: pending â†’ running]
    end
    
    subgraph Processing["âš™ï¸ Traitement"]
        SiteProfile[ğŸ¢ site_profiles<br/>id: 15<br/>domain: innosys.fr<br/>language_level, editorial_tone]
        AnalysisResults[ğŸ“Š site_analysis_results<br/>site_profile_id: 15<br/>execution_id: UUID<br/>phase: discovery, synthesis]
    end
    
    subgraph ParallelWorkflows["âš™ï¸ Workflows ParallÃ¨les"]
        direction TB
        W1[ğŸ” competitor_search<br/>Recherche concurrents<br/>execution_id: 378c14c4-...]
        W2[ğŸ•·ï¸ enhanced_scraping<br/>Scraping amÃ©liorÃ©<br/>execution_id: 19b5ba22-...]
        W3[ğŸ“ˆ trend_pipeline<br/>Analyse tendances<br/>execution_id: 08083962-...]
    end
    
    subgraph DataStorage["ğŸ’¾ Stockage DonnÃ©es"]
        direction TB
        ClientArts[ğŸ“š client_articles<br/>site_profile_id: 15<br/>Articles client]
        CompArts[ğŸ“° competitor_articles<br/>domain: concurrents<br/>Articles concurrents]
        TrendData[ğŸ“ˆ Trend Pipeline Data<br/>topic_clusters<br/>trend_analysis<br/>editorial_gaps]
    end
    
    subgraph FinalOutput["ğŸ“¤ RÃ©sultats Finaux"]
        APIResponse[ğŸ“¡ API Response<br/>GET /sites/innosys.fr<br/>GET /trend-pipeline/{id}]
    end
    
    ClientRequest --> WorkflowExec
    DomainInput --> SiteProfile
    ConfigInput --> WorkflowExec
    
    WorkflowExec --> SiteProfile
    WorkflowExec --> AnalysisResults
    SiteProfile --> AnalysisResults
    
    AnalysisResults -.->|DÃ©clenche| W1
    AnalysisResults -.->|DÃ©clenche| W2
    AnalysisResults -.->|DÃ©clenche| W3
    
    W1 --> CompArts
    W2 --> CompArts
    W2 --> ClientArts
    W3 --> TrendData
    
    SiteProfile --> APIResponse
    ClientArts --> APIResponse
    CompArts --> APIResponse
    TrendData --> APIResponse
    
    style ClientRequest fill:#4a90e2,stroke:#2c5aa0,stroke-width:3px,color:#fff
    style ExternalInputs fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style Creation fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style Processing fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style ParallelWorkflows fill:#ffebee,stroke:#c62828,stroke-width:2px
    style DataStorage fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style FinalOutput fill:#50c878,stroke:#2d7a4e,stroke-width:3px,color:#fff
```

### 7.3 Workflow Trend Pipeline - 4 Stages DÃ©taillÃ©s

```mermaid
flowchart TD
    Start([ğŸ“¥ POST /trend-pipeline/analyze<br/>client_domain: innosys.fr])
    
    subgraph Inputs["ğŸ“¥ Inputs"]
        ClientDomain((ğŸŒ Client Domain<br/>innosys.fr))
        TimeWindow((â±ï¸ Time Window<br/>90 jours))
        Competitors((ğŸ” Concurrents<br/>Domains list))
    end
    
    subgraph Execution["âš™ï¸ ExÃ©cution"]
        CreateExec[ğŸ“ CrÃ©er trend_pipeline_executions<br/>execution_id: UUID<br/>client_domain: innosys.fr]
    end
    
    subgraph Stage1["ğŸ¯ Stage 1: Clustering"]
        S1A[ğŸ“š RÃ©cupÃ©rer articles<br/>competitor_articles]
        S1B[ğŸ”¢ GÃ©nÃ©rer embeddings<br/>Vector DB]
        S1C[ğŸ¯ BERTopic clustering<br/>Topic discovery]
        S1D[ğŸ’¾ Sauvegarder<br/>topic_clusters<br/>topic_outliers]
    end
    
    subgraph Stage2["â±ï¸ Stage 2: Temporal"]
        S2A[ğŸ“ˆ Calculer mÃ©triques<br/>temporelles]
        S2B[ğŸ’¾ Sauvegarder<br/>topic_temporal_metrics]
    end
    
    subgraph Stage3["ğŸ§  Stage 3: LLM Enrichment"]
        S3A[âœ¨ Enrichir topics<br/>avec LLM]
        S3B[ğŸ’¾ Sauvegarder<br/>trend_analysis<br/>article_recommendations<br/>weak_signals_analysis]
    end
    
    subgraph Stage4["ğŸ“Š Stage 4: Gap Analysis"]
        S4A[ğŸ” Analyser couverture<br/>client]
        S4B[ğŸ’¾ Sauvegarder<br/>client_coverage_analysis<br/>client_strengths<br/>editorial_gaps<br/>content_roadmap]
    end
    
    subgraph Results["ğŸ“Š RÃ©sultats"]
        FinalResults[ğŸ“¤ RÃ©sultats disponibles<br/>Topics, Trends, Gaps, Roadmap]
    end
    
    Start --> CreateExec
    ClientDomain --> CreateExec
    TimeWindow --> CreateExec
    Competitors --> S1A
    
    CreateExec --> S1A
    S1A --> S1B
    S1B --> S1C
    S1C --> S1D
    
    S1D --> S2A
    S2A --> S2B
    
    S2B --> S3A
    S3A --> S3B
    
    S3B --> S4A
    S4A --> S4B
    
    S4B --> FinalResults
    
    style Start fill:#4a90e2,stroke:#2c5aa0,stroke-width:3px,color:#fff
    style Inputs fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style Execution fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style Stage1 fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style Stage2 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style Stage3 fill:#ffebee,stroke:#c62828,stroke-width:2px
    style Stage4 fill:#f1f8e9,stroke:#558b2f,stroke-width:2px
    style Results fill:#50c878,stroke:#2d7a4e,stroke-width:3px,color:#fff
```

---

**Date de crÃ©ation** : 2025-12-10  
**Version** : 1.0.0  
**DerniÃ¨re mise Ã  jour** : 2025-12-10












