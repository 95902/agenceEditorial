# Sch√©ma de Base de Donn√©es et Fonctionnalit√©s - Route POST /api/v1/discovery/scrape

## Vue d'ensemble

La route `POST /api/v1/discovery/scrape` lance un scraping am√©lior√© avec pipeline de d√©couverte en 4 phases pour d√©couvrir et extraire des articles de mani√®re optimis√©e.

**Cas d'usage avec `client_domain=innosys.fr`** :
- R√©cup√®re automatiquement les concurrents valid√©s depuis une recherche de concurrents pr√©c√©dente
- Scrape les articles de tous les concurrents trouv√©s
- Utilise un pipeline optimis√© de d√©couverte multi-sources

## Flux d'ex√©cution

### Phase initiale : R√©cup√©ration des domaines

1. **Si `client_domain` fourni** (ex: `innosys.fr`) :
   - Recherche la derni√®re ex√©cution `competitor_search` compl√©t√©e pour ce domaine
   - Extrait les domaines des concurrents valid√©s depuis `workflow_executions.output_data.competitors`
   - Force `is_client_site=false` (on scrape les concurrents, pas le client)

2. **Si `domains` fourni directement** :
   - Utilise les domaines fournis directement

3. **Cr√©ation de l'ex√©cution** ‚Üí `workflow_executions` (CREATE)

### Pipeline 4 phases (par domaine)

Pour chaque domaine √† scraper :

#### **Phase 0 - Profiling** üîç
- Analyse la structure du site
- D√©tecte le CMS (WordPress, Drupal, etc.)
- D√©tecte les APIs REST disponibles
- D√©couvre les sitemaps
- D√©couvre les flux RSS
- Identifie les patterns d'URLs
- D√©termine les s√©lecteurs CSS optimaux

#### **Phase 1 - Discovery** üì°
D√©couverte multi-sources (dans l'ordre de priorit√©) :
1. **API REST** : Si le site expose une API, r√©cup√®re les articles via l'API
2. **RSS** : Parse les flux RSS d√©couverts
3. **Sitemap** : Parse les sitemaps XML
4. **Heuristiques** : D√©couverte par patterns et exploration de pages

#### **Phase 2 - Scoring** üìä
- Calcule un score de probabilit√© pour chaque URL d√©couverte
- Score bas√© sur : patterns d'URL, titre, source, etc.
- Trie les URLs par score d√©croissant
- S√©lectionne les meilleures URLs √† scraper

#### **Phase 3 - Extraction** ‚úÇÔ∏è
- Crawl des URLs s√©lectionn√©es
- Extraction adaptative selon le profil du site
- Validation du contenu (nombre de mots, qualit√©, etc.)
- Sauvegarde des articles valides

## Tables impact√©es

### 1. `workflow_executions` ‚≠ê **CRITIQUE**
- **Op√©ration** : CREATE, UPDATE, READ
- **Description** : Enregistre l'ex√©cution du workflow de scraping am√©lior√©
- **Champs impact√©s** :
  - `execution_id` (UUID, unique)
  - `workflow_type` = "enhanced_scraping"
  - `status` : "pending" ‚Üí "running" ‚Üí "completed" ou "failed"
  - `input_data` : 
    ```json
    {
      "domains": ["competitor1.fr", "competitor2.fr", ...],
      "max_articles": 100,
      "is_client_site": false,
      "site_profile_id": null,
      "force_reprofile": false,
      "client_domain": "innosys.fr"
    }
    ```
  - `output_data` : 
    ```json
    {
      "domains": ["competitor1.fr", ...],
      "results_by_domain": {
        "competitor1.fr": {
          "articles": [...],
          "statistics": {
            "discovered": 150,
            "scraped": 100,
            "valid": 85
          }
        }
      },
      "total_articles_scraped": 85,
      "statistics": {
        "total_domains": 10,
        "domains_with_articles": 8,
        "domains_without_articles": 2,
        "domains_with_errors": 0,
        "total_articles_discovered": 1200,
        "total_articles_scraped": 850,
        "total_articles_valid": 680
      }
    }
    ```
  - `start_time`, `end_time`, `duration_seconds`
  - `was_success` : true/false
  - `error_message` : si √©chec

### 2. `workflow_executions` (READ) üìñ
- **Op√©ration** : READ uniquement
- **Description** : Lecture de la derni√®re ex√©cution `competitor_search` pour r√©cup√©rer les concurrents
- **Requ√™te** :
  ```sql
  SELECT * FROM workflow_executions
  WHERE workflow_type = 'competitor_search'
    AND status = 'completed'
    AND input_data->>'domain' = 'innosys.fr'
  ORDER BY start_time DESC
  LIMIT 1
  ```
- **Donn√©es lues** : `output_data.competitors` (liste des concurrents valid√©s)

### 3. `site_discovery_profiles` ‚≠ê **CRITIQUE**
- **Op√©ration** : CREATE, UPDATE, READ
- **Description** : Profil de d√©couverte optimis√© pour chaque domaine
- **Champs impact√©s** :
  - `domain` (unique)
  - `cms_detected` : CMS d√©tect√© (WordPress, Drupal, etc.)
  - `cms_version` : Version du CMS
  - `has_rest_api` : Pr√©sence d'API REST
  - `api_endpoints` : Endpoints API d√©couverts (JSONB)
  - `sitemap_urls` : URLs des sitemaps (JSONB array)
  - `rss_feeds` : URLs des flux RSS (JSONB array)
  - `blog_listing_pages` : Pages de listing de blog (JSONB array)
  - `url_patterns` : Patterns d'URLs d√©tect√©s (JSONB)
  - `article_url_regex` : Regex pour identifier les URLs d'articles
  - `pagination_pattern` : Pattern de pagination
  - `content_selector` : S√©lecteur CSS optimal pour le contenu
  - `title_selector` : S√©lecteur CSS optimal pour le titre
  - `date_selector` : S√©lecteur CSS optimal pour la date
  - `author_selector` : S√©lecteur CSS optimal pour l'auteur
  - `image_selector` : S√©lecteur CSS optimal pour les images
  - `total_urls_discovered` : Nombre total d'URLs d√©couvertes
  - `total_articles_valid` : Nombre d'articles valides trouv√©s
  - `success_rate` : Taux de succ√®s (0.0 √† 1.0)
  - `avg_article_word_count` : Nombre moyen de mots par article
  - `last_profiled_at` : Date du dernier profilage
  - `last_crawled_at` : Date du dernier crawl
  - `profile_version` : Version du profil
  - `is_active` : Profil actif ou non

### 4. `url_discovery_scores` ‚≠ê **CRITIQUE**
- **Op√©ration** : CREATE, UPDATE
- **Description** : Scores de probabilit√© pour chaque URL d√©couverte
- **Champs impact√©s** :
  - `domain` : Domaine analys√©
  - `url` : URL d√©couverte
  - `url_hash` : Hash de l'URL (pour d√©duplication)
  - `discovery_source` : Source de d√©couverte ("api", "rss", "sitemap", "heuristic")
  - `discovered_in` : Contexte de d√©couverte (ex: "sitemap_index.xml")
  - `initial_score` : Score initial de probabilit√© (0-100)
  - `final_score` : Score final apr√®s validation (peut √™tre mis √† jour)
  - `score_breakdown` : D√©tail du calcul du score (JSONB)
  - `was_scraped` : Indique si l'URL a √©t√© scrap√©e
  - `scrape_status` : Statut du scraping ("success", "failed")
  - `is_valid_article` : Indique si c'est un article valide
  - `validation_reason` : Raison de validation/rejet
  - `title_hint` : Titre sugg√©r√© (si disponible depuis la source)
  - `date_hint` : Date sugg√©r√©e (si disponible depuis la source)
  - `discovered_at` : Date de d√©couverte
  - `scraped_at` : Date de scraping (si scrap√©e)

### 5. `discovery_logs` üìù
- **Op√©ration** : CREATE
- **Description** : Logs de tra√ßabilit√© pour chaque op√©ration de d√©couverte
- **Champs impact√©s** :
  - `domain` : Domaine analys√©
  - `execution_id` : ID de l'ex√©cution (FK vers workflow_executions)
  - `operation` : Type d'op√©ration ("discovery", "scraping", "profiling")
  - `phase` : Phase du pipeline ("phase_0", "phase_1", "phase_2", "phase_3")
  - `status` : Statut ("success", "failed", "partial")
  - `urls_found` : Nombre d'URLs trouv√©es
  - `urls_scraped` : Nombre d'URLs scrap√©es
  - `urls_valid` : Nombre d'URLs valides
  - `sources_used` : Sources utilis√©es (JSONB array: ["api", "rss", "sitemap"])
  - `errors` : Liste des erreurs rencontr√©es (JSONB array)
  - `duration_seconds` : Dur√©e de l'op√©ration
  - `created_at` : Date de cr√©ation

### 6. `competitor_articles` ‚≠ê **CRITIQUE**
- **Op√©ration** : CREATE, READ
- **Description** : Articles des concurrents scrap√©s et valid√©s
- **Champs impact√©s** :
  - `domain` : Domaine du concurrent
  - `url` : URL de l'article (unique)
  - `url_hash` : Hash de l'URL (index√©)
  - `title` : Titre de l'article
  - `author` : Auteur (optionnel)
  - `published_date` : Date de publication
  - `content_text` : Contenu texte de l'article
  - `content_html` : Contenu HTML brut (optionnel)
  - `word_count` : Nombre de mots
  - `keywords` : Mots-cl√©s extraits (JSONB)
  - `article_metadata` : M√©tadonn√©es additionnelles (JSONB)
  - `qdrant_point_id` : ID du point dans Qdrant (apr√®s indexation)
  - `topic_id` : ID du topic (peut √™tre null, rempli plus tard)
  - `is_duplicate` : Indique si c'est un doublon
  - `duplicate_of` : ID de l'article original (si doublon)
  - `scraping_permission_id` : Lien vers scraping_permissions

### 7. `client_articles` (si `is_client_site=true`) ‚≠ê **CONDITIONNEL**
- **Op√©ration** : CREATE, READ
- **Description** : Articles du site client (non utilis√© dans le cas `client_domain=innosys.fr`)
- **Note** : Dans le cas `client_domain=innosys.fr`, `is_client_site` est forc√© √† `false`, donc cette table n'est **PAS** utilis√©e

### 8. `site_profiles` üìñ **LECTURE SEULE** (si client site)
- **Op√©ration** : READ uniquement
- **Description** : Profil √©ditorial du site (uniquement si `is_client_site=true`)
- **Note** : Non utilis√© dans le cas `client_domain=innosys.fr`

### 9. `scraping_permissions` üìñ **LECTURE SEULE**
- **Op√©ration** : READ uniquement (via cache)
- **Description** : Permissions de scraping (robots.txt)
- **Note** : Utilis√© en interne par `crawl_page_async()` pour v√©rifier les permissions

### 10. `error_logs` üìù
- **Op√©ration** : CREATE
- **Description** : Logs d'erreurs pour diagnostic
- **Champs impact√©s** (si erreur) :
  - `execution_id` : ID de l'ex√©cution
  - `domain` : Domaine concern√©
  - `agent_name` : "enhanced_scraping"
  - `component` : "qdrant", "scraping", "discovery", etc.
  - `error_type` : Type d'erreur
  - `error_message` : Message d'erreur
  - `error_traceback` : Stack trace
  - `context` : Contexte additionnel (JSONB)
  - `severity` : "error", "warning", "critical"

### 11. Qdrant Vector Store üîç
- **Op√©ration** : CREATE (indexation)
- **Description** : Base de donn√©es vectorielle pour recherche s√©mantique
- **Collections impact√©es** :
  - `{client_domain}_competitor_articles` : Collection pour les articles de concurrents, nomm√©e selon le domaine du client (ex: `innosys_fr_competitor_articles` si `client_domain=innosys.fr`)
  - `{domain}_client_articles` : Collections par domaine pour les articles clients (non utilis√© ici)
  - **Note** : Si `client_domain` n'est pas fourni, utilise la collection par d√©faut `competitor_articles`
- **Donn√©es index√©es** :
  - Vector embedding (1024 dimensions, mxbai-embed-large-v1)
  - Payload : `article_id`, `domain`, `title`, `url`, `url_hash`, `published_date`, `author`, `keywords`, `topic_id`
- **Fonctionnalit√©s** :
  - D√©tection de doublons par similarit√© (threshold 0.92)
  - Recherche s√©mantique
  - Filtrage par m√©tadonn√©es

## Ordre d'impact (par domaine)

### Phase 0 - Profiling
1. `site_discovery_profiles` (READ) - V√©rifier si profil existe
2. Si absent ou expir√© (>7 jours) :
   - `site_discovery_profiles` (CREATE ou UPDATE) - Cr√©er/mettre √† jour le profil

### Phase 1 - Discovery
3. `url_discovery_scores` (CREATE) - Sauvegarder chaque URL d√©couverte avec score initial
4. `discovery_logs` (CREATE) - Logger les r√©sultats de d√©couverte

### Phase 2 - Scoring
5. `url_discovery_scores` (UPDATE) - Mettre √† jour les scores et breakdowns

### Phase 3 - Extraction
6. `url_discovery_scores` (UPDATE) - Marquer `was_scraped=true`, `scrape_status`
7. `competitor_articles` (READ) - V√©rifier les doublons par `url_hash`
8. `competitor_articles` (CREATE) - Sauvegarder les articles valides
9. Qdrant (CREATE) - Indexer les articles avec embeddings
10. `competitor_articles` (UPDATE) - Mettre √† jour `qdrant_point_id`
11. `url_discovery_scores` (UPDATE) - Marquer `is_valid_article`, `final_score`
12. `discovery_logs` (CREATE) - Logger les r√©sultats finaux
13. `error_logs` (CREATE) - Logger les erreurs si n√©cessaire

### Phase finale
14. `workflow_executions` (UPDATE) - Mettre √† jour avec `output_data` complet et `status=completed`

## Structure des donn√©es dans output_data

```json
{
  "domains": ["competitor1.fr", "competitor2.fr", "competitor3.fr"],
  "results_by_domain": {
    "competitor1.fr": {
      "articles": [
        {
          "id": 12345,
          "url": "https://competitor1.fr/article-1",
          "title": "Titre de l'article",
          "word_count": 850
        }
      ],
      "statistics": {
        "discovered": 150,
        "scraped": 100,
        "valid": 85,
        "sources_used": ["api", "rss", "sitemap"]
      },
      "error": null
    },
    "competitor2.fr": {
      "articles": [...],
      "statistics": {...},
      "error": null
    }
  },
  "total_articles_scraped": 250,
  "statistics": {
    "total_domains": 3,
    "domains_with_articles": 3,
    "domains_without_articles": 0,
    "domains_with_errors": 0,
    "total_articles_discovered": 450,
    "total_articles_scraped": 300,
    "total_articles_valid": 250
  }
}
```

## Diagramme de flux

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ POST /api/v1/discovery/scrape?client_domain=innosys.fr         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. R√©cup√©ration des concurrents                                 ‚îÇ
‚îÇ    - READ workflow_executions (competitor_search)                ‚îÇ
‚îÇ    - Extraire domains depuis output_data.competitors             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. Cr√©ation de l'ex√©cution                                      ‚îÇ
‚îÇ    - CREATE workflow_executions (enhanced_scraping)              ‚îÇ
‚îÇ    - status: pending                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Pour chaque domaine (concurrent) :                              ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ ‚îÇ PHASE 0 - Profiling                                        ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - READ site_discovery_profiles                            ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - Si absent/expir√©: CREATE/UPDATE site_discovery_profiles ‚îÇ  ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                              ‚îÇ                                    ‚îÇ
‚îÇ                              ‚ñº                                    ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ ‚îÇ PHASE 1 - Discovery                                        ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - API REST ‚Üí discovered_urls                              ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - RSS ‚Üí discovered_urls                                    ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - Sitemap ‚Üí discovered_urls                                ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - Heuristics ‚Üí discovered_urls                            ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - CREATE url_discovery_scores (pour chaque URL)           ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - CREATE discovery_logs                                    ‚îÇ  ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                              ‚îÇ                                    ‚îÇ
‚îÇ                              ‚ñº                                    ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ ‚îÇ PHASE 2 - Scoring                                          ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - Calculer score pour chaque URL                           ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - UPDATE url_discovery_scores (score, breakdown)           ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - Trier et s√©lectionner les meilleures URLs                ‚îÇ  ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                              ‚îÇ                                    ‚îÇ
‚îÇ                              ‚ñº                                    ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ ‚îÇ PHASE 3 - Extraction                                        ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - Crawl chaque URL s√©lectionn√©e                            ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - UPDATE url_discovery_scores (was_scraped, status)       ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - Extraction adaptative                                    ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - Validation du contenu                                    ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - READ competitor_articles (v√©rifier doublons)             ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - CREATE competitor_articles (si valide et non doublon)    ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - CREATE Qdrant point (indexation vectorielle)             ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - UPDATE competitor_articles (qdrant_point_id)            ‚îÇ  ‚îÇ
‚îÇ ‚îÇ - UPDATE url_discovery_scores (is_valid_article)           ‚îÇ  ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. Finalisation                                                 ‚îÇ
‚îÇ    - CREATE discovery_logs (r√©sum√© final)                       ‚îÇ
‚îÇ    - UPDATE workflow_executions                                 ‚îÇ
‚îÇ      * status: completed                                        ‚îÇ
‚îÇ      * output_data: r√©sultats complets                          ‚îÇ
‚îÇ      * was_success: true                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Dependencies entre tables

```
workflow_executions (competitor_search)
    ‚îî‚îÄ> output_data.competitors
            ‚îî‚îÄ> domains list
                    ‚îî‚îÄ> workflow_executions (enhanced_scraping)
                            ‚îú‚îÄ> site_discovery_profiles (per domain)
                            ‚îú‚îÄ> url_discovery_scores (per URL)
                            ‚îú‚îÄ> discovery_logs (per operation)
                            ‚îú‚îÄ> competitor_articles (per article)
                            ‚îÇ       ‚îî‚îÄ> qdrant_point_id ‚Üí Qdrant
                            ‚îî‚îÄ> error_logs (if errors)
```

## Notes importantes

- ‚≠ê **CRITIQUE** : Table essentielle pour le fonctionnement de la route
- üìñ **LECTURE SEULE** : Table lue mais non modifi√©e
- üîç **EXTERNE** : Service externe (API, base vectorielle)
- üîÑ **PIPELINE** : Traitement en m√©moire, pas d'√©criture directe en base
- üìù **LOGGING** : Table de tra√ßabilit√© et diagnostic

### Points cl√©s

1. **Mode auto-fetch** : Avec `client_domain=innosys.fr`, la route r√©cup√®re automatiquement les concurrents depuis une recherche pr√©c√©dente
2. **Pipeline optimis√©** : Les 4 phases permettent une d√©couverte et extraction plus efficace que le scraping standard
3. **Profils r√©utilisables** : Les profils de d√©couverte sont mis en cache et r√©utilis√©s (reprofilage apr√®s 7 jours)
4. **Scoring intelligent** : Chaque URL re√ßoit un score de probabilit√© pour prioriser le scraping
5. **Extraction adaptative** : Les s√©lecteurs CSS sont adapt√©s selon le profil du site
6. **Indexation vectorielle** : Tous les articles sont index√©s dans Qdrant pour recherche s√©mantique
7. **Tra√ßabilit√© compl√®te** : Toutes les op√©rations sont logg√©es dans `discovery_logs` et `url_discovery_scores`

### Performance

- Dur√©e typique : ~8 minutes pour 10-50 domaines avec max_articles=100
- D√©couverte multi-sources : API > RSS > Sitemap > Heuristics (ordre de priorit√©)
- Cache de profils : R√©duit le temps de profilage pour les domaines d√©j√† analys√©s






