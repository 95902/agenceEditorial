# SchÃ©ma de Base de DonnÃ©es et FonctionnalitÃ©s - Route POST /api/v1/trend-pipeline/analyze

## Vue d'ensemble

La route `POST /api/v1/trend-pipeline/analyze` lance un pipeline d'analyse de tendances en 4 Ã©tapes (stages) pour dÃ©couvrir, analyser et recommander du contenu Ã©ditorial basÃ© sur l'analyse des articles des concurrents.

**Pipeline 4 Ã©tapes** :
1. **Stage 1 - Clustering** : DÃ©couverte de topics via BERTopic + HDBSCAN
2. **Stage 2 - Analyse Temporelle** : MÃ©triques de volume, vÃ©locitÃ©, fraÃ®cheur
3. **Stage 3 - Enrichissement LLM** : SynthÃ¨se de tendances et recommandations d'articles
4. **Stage 4 - Gap Analysis** : Identification des gaps Ã©ditoriaux et roadmap de contenu

## Flux d'exÃ©cution

### Phase initiale : RÃ©cupÃ©ration des domaines

1. **Si `client_domain` fourni** (ex: `innosys.fr`) :
   - Recherche la derniÃ¨re exÃ©cution `competitor_search` complÃ©tÃ©e pour ce domaine
   - Extrait les domaines des concurrents validÃ©s depuis `workflow_executions.output_data.competitors`
   - Filtre uniquement les concurrents validÃ©s (non exclus)

2. **Si `domains` fourni directement** :
   - Utilise les domaines fournis directement

3. **CrÃ©ation de l'exÃ©cution** â†’ `trend_pipeline_executions` (CREATE)

### Pipeline 4 Ã©tapes

#### **Stage 1 - Clustering (BERTopic + HDBSCAN)** ðŸ”
- RÃ©cupÃ©ration des embeddings depuis Qdrant (collection `{client_domain}_competitor_articles`)
- Filtrage par fenÃªtre temporelle (`time_window_days`, dÃ©faut: 365 jours)
- Clustering avec BERTopic + HDBSCAN
- GÃ©nÃ©ration de labels pour chaque cluster
- Calcul des scores de cohÃ©rence
- Extraction des outliers (documents non classifiÃ©s)
- CatÃ©gorisation des outliers

#### **Stage 2 - Analyse Temporelle** ðŸ“Š
- Calcul de mÃ©triques temporelles par topic :
  - **Volume** : Nombre d'articles par fenÃªtre temporelle
  - **VÃ©locitÃ©** : Taux de croissance du volume
  - **FraÃ®cheur** : Ratio d'articles rÃ©cents
  - **DiversitÃ© des sources** : Nombre de domaines diffÃ©rents
  - **Score de potentiel** : Score combinÃ© pour priorisation
- DÃ©tection de drift (Ã©volution des topics dans le temps)
- Analyse de cohÃ©sion

#### **Stage 3 - Enrichissement LLM** ðŸ¤–
- SynthÃ¨se de tendances pour les top topics (top 10 par score de potentiel)
- GÃ©nÃ©ration de recommandations d'articles :
  - Titre, hook, outline
  - Score de diffÃ©renciation
  - Niveau d'effort (easy, medium, complex)
- Analyse des angles saturÃ©s et opportunitÃ©s
- Analyse des signaux faibles (outliers)

#### **Stage 4 - Gap Analysis** ðŸŽ¯
- Analyse de couverture client par topic
- Calcul des scores de couverture et prioritÃ©
- Identification des gaps Ã©ditoriaux
- GÃ©nÃ©ration d'une roadmap de contenu priorisÃ©e
- Identification des forces compÃ©titives du client

## Tables impactÃ©es

### 1. `workflow_executions` ðŸ“– **LECTURE SEULE**
- **OpÃ©ration** : READ uniquement
- **Description** : Lecture de la derniÃ¨re exÃ©cution `competitor_search` pour rÃ©cupÃ©rer les concurrents
- **RequÃªte** :
  ```sql
  SELECT * FROM workflow_executions
  WHERE workflow_type = 'competitor_search'
    AND status = 'completed'
    AND input_data->>'domain' = 'innosys.fr'
  ORDER BY start_time DESC
  LIMIT 1
  ```
- **DonnÃ©es lues** : `output_data.competitors` (liste des concurrents validÃ©s)

### 2. `trend_pipeline_executions` â­ **CRITIQUE**
- **OpÃ©ration** : CREATE, UPDATE
- **Description** : Enregistre l'exÃ©cution du pipeline de tendances
- **Champs impactÃ©s** :
  - `execution_id` (UUID, unique)
  - `client_domain` : Domaine du client (optionnel)
  - `domains_analyzed` : Liste des domaines analysÃ©s (JSONB)
  - `time_window_days` : FenÃªtre temporelle en jours
  - `stage_1_clustering_status` : "pending" â†’ "in_progress" â†’ "completed" / "failed"
  - `stage_2_temporal_status` : "pending" â†’ "in_progress" â†’ "completed"
  - `stage_3_llm_status` : "pending" â†’ "in_progress" â†’ "completed" / "skipped"
  - `stage_4_gap_status` : "pending" â†’ "in_progress" â†’ "completed" / "skipped"
  - `total_articles` : Nombre total d'articles analysÃ©s
  - `total_clusters` : Nombre de clusters dÃ©couverts
  - `total_outliers` : Nombre d'outliers
  - `total_recommendations` : Nombre de recommandations gÃ©nÃ©rÃ©es
  - `total_gaps` : Nombre de gaps identifiÃ©s
  - `error_message` : Message d'erreur si Ã©chec
  - `start_time`, `end_time`, `duration_seconds`

### 3. `topic_clusters` â­ **CRITIQUE** (Stage 1)
- **OpÃ©ration** : CREATE (batch)
- **Description** : Clusters thÃ©matiques dÃ©couverts par BERTopic
- **Champs impactÃ©s** :
  - `analysis_id` : ID de l'exÃ©cution (FK vers `trend_pipeline_executions.id`)
  - `topic_id` : ID du topic (unique par analysis)
  - `label` : Label gÃ©nÃ©rÃ© pour le topic
  - `top_terms` : Top termes du topic (JSONB)
  - `size` : Nombre de documents dans le cluster
  - `centroid_vector_id` : ID du vecteur centroÃ¯de (optionnel)
  - `document_ids` : IDs des documents du cluster (JSONB)
  - `coherence_score` : Score de cohÃ©rence du cluster
  - `created_at` : Date de crÃ©ation

### 4. `topic_outliers` ðŸ“ (Stage 1)
- **OpÃ©ration** : CREATE (batch)
- **Description** : Documents non classifiÃ©s (outliers, topic_id=-1)
- **Champs impactÃ©s** :
  - `analysis_id` : ID de l'exÃ©cution
  - `document_id` : ID du document
  - `article_id` : ID de l'article (optionnel)
  - `potential_category` : CatÃ©gorie potentielle suggÃ©rÃ©e
  - `embedding_distance` : Distance au cluster le plus proche
  - `created_at` : Date de crÃ©ation

### 5. `topic_temporal_metrics` â­ **CRITIQUE** (Stage 2)
- **OpÃ©ration** : CREATE
- **Description** : MÃ©triques temporelles par topic et fenÃªtre temporelle
- **Champs impactÃ©s** :
  - `topic_cluster_id` : ID du cluster (FK vers `topic_clusters.id`)
  - `window_start` : DÃ©but de la fenÃªtre temporelle
  - `window_end` : Fin de la fenÃªtre temporelle
  - `volume` : Nombre d'articles dans la fenÃªtre
  - `velocity` : Taux de croissance (vÃ©locitÃ©)
  - `freshness_ratio` : Ratio d'articles rÃ©cents
  - `source_diversity` : Nombre de domaines sources diffÃ©rents
  - `cohesion_score` : Score de cohÃ©sion du topic
  - `potential_score` : Score de potentiel (pour priorisation)
  - `drift_detected` : Indique si un drift a Ã©tÃ© dÃ©tectÃ©
  - `drift_distance` : Distance du drift (si dÃ©tectÃ©)
  - `created_at` : Date de crÃ©ation

### 6. `trend_analysis` â­ **CRITIQUE** (Stage 3)
- **OpÃ©ration** : CREATE
- **Description** : SynthÃ¨ses de tendances gÃ©nÃ©rÃ©es par LLM
- **Champs impactÃ©s** :
  - `topic_cluster_id` : ID du cluster (FK vers `topic_clusters.id`)
  - `synthesis` : SynthÃ¨se de la tendance (texte gÃ©nÃ©rÃ© par LLM)
  - `saturated_angles` : Angles saturÃ©s identifiÃ©s (JSONB)
  - `opportunities` : OpportunitÃ©s identifiÃ©es (JSONB)
  - `llm_model_used` : ModÃ¨le LLM utilisÃ© (ex: "llama3", "mistral")
  - `processing_time_seconds` : Temps de traitement
  - `created_at` : Date de crÃ©ation

### 7. `article_recommendations` â­ **CRITIQUE** (Stage 3)
- **OpÃ©ration** : CREATE
- **Description** : Recommandations d'articles gÃ©nÃ©rÃ©es par LLM
- **Champs impactÃ©s** :
  - `topic_cluster_id` : ID du cluster (FK vers `topic_clusters.id`)
  - `title` : Titre de l'article recommandÃ©
  - `hook` : Accroche de l'article
  - `outline` : Plan de l'article (JSONB)
  - `differentiation_score` : Score de diffÃ©renciation
  - `effort_level` : Niveau d'effort ("easy", "medium", "complex")
  - `status` : Statut ("suggested", "approved", "in_progress", "published")
  - `created_at` : Date de crÃ©ation

### 8. `weak_signals_analysis` ðŸ“ (Stage 3)
- **OpÃ©ration** : CREATE
- **Description** : Analyse des signaux faibles (outliers)
- **Champs impactÃ©s** :
  - `analysis_id` : ID de l'exÃ©cution
  - `outlier_ids` : IDs des outliers analysÃ©s (JSONB)
  - `common_thread` : Fil conducteur commun identifiÃ©
  - `disruption_potential` : Potentiel de disruption
  - `recommendation` : Recommandation ("early_adopter", "wait", "monitor")
  - `llm_model_used` : ModÃ¨le LLM utilisÃ©
  - `created_at` : Date de crÃ©ation

### 9. `client_coverage_analysis` â­ **CRITIQUE** (Stage 4)
- **OpÃ©ration** : CREATE
- **Description** : Analyse de couverture client par topic
- **Champs impactÃ©s** :
  - `domain` : Domaine du client
  - `topic_cluster_id` : ID du cluster (FK vers `topic_clusters.id`)
  - `client_article_count` : Nombre d'articles du client sur ce topic
  - `coverage_score` : Score de couverture (0.0 Ã  1.0)
  - `avg_distance_to_centroid` : Distance moyenne au centroÃ¯de
  - `analysis_date` : Date de l'analyse

### 10. `editorial_gaps` â­ **CRITIQUE** (Stage 4)
- **OpÃ©ration** : CREATE
- **Description** : Gaps Ã©ditoriaux identifiÃ©s
- **Champs impactÃ©s** :
  - `client_domain` : Domaine du client
  - `topic_cluster_id` : ID du cluster (FK vers `topic_clusters.id`)
  - `coverage_score` : Score de couverture (faible = gap)
  - `priority_score` : Score de prioritÃ© (pour tri)
  - `diagnostic` : Diagnostic du gap
  - `opportunity_description` : Description de l'opportunitÃ©
  - `risk_assessment` : Ã‰valuation des risques
  - `created_at` : Date de crÃ©ation

### 11. `client_strengths` ðŸ“ (Stage 4)
- **OpÃ©ration** : CREATE
- **Description** : Forces compÃ©titives du client (topics oÃ¹ le client surperforme)
- **Champs impactÃ©s** :
  - `domain` : Domaine du client
  - `topic_cluster_id` : ID du cluster (FK vers `topic_clusters.id`)
  - `advantage_score` : Score d'avantage compÃ©titif
  - `description` : Description de la force
  - `created_at` : Date de crÃ©ation

### 12. `content_roadmap` â­ **CRITIQUE** (Stage 4)
- **OpÃ©ration** : CREATE
- **Description** : Roadmap de contenu priorisÃ©e
- **Champs impactÃ©s** :
  - `client_domain` : Domaine du client
  - `gap_id` : ID du gap (FK vers `editorial_gaps.id`)
  - `recommendation_id` : ID de la recommandation (FK vers `article_recommendations.id`)
  - `priority_order` : Ordre de prioritÃ© (1, 2, 3, ...)
  - `estimated_effort` : Effort estimÃ© ("easy", "medium", "complex")
  - `status` : Statut ("pending", "in_progress", "completed")
  - `created_at` : Date de crÃ©ation

### 13. Qdrant Vector Store ðŸ” **LECTURE SEULE**
- **OpÃ©ration** : READ uniquement
- **Description** : Base de donnÃ©es vectorielle pour rÃ©cupÃ©ration des embeddings
- **Collections utilisÃ©es** :
  - `{client_domain}_competitor_articles` : Collection des articles concurrents (ex: `innosys_fr_competitor_articles` si `client_domain=innosys.fr`)
  - **Note** : Le nom de collection est gÃ©nÃ©rÃ© automatiquement depuis `client_domain` via `get_competitor_collection_name()`
  - **Filtres** :
    - Par domaines (domains list)
    - Par fenÃªtre temporelle (`max_age_days`)
- **DonnÃ©es lues** :
  - Embeddings (vecteurs 1024 dimensions)
  - MÃ©tadonnÃ©es : `domain`, `title`, `content_text`, `published_date`, `url`, etc.

### 14. `competitor_articles` ðŸ“– **LECTURE SEULE** (via Qdrant)
- **OpÃ©ration** : READ indirect (via Qdrant)
- **Description** : Articles des concurrents utilisÃ©s pour l'analyse
- **Note** : Les articles sont rÃ©cupÃ©rÃ©s via Qdrant, pas directement depuis PostgreSQL

## Ordre d'impact par Ã©tape

### Phase initiale
1. `workflow_executions` (READ) - RÃ©cupÃ©ration des concurrents si `client_domain` fourni
2. `trend_pipeline_executions` (CREATE) - CrÃ©ation de l'exÃ©cution

### Stage 1 - Clustering
3. Qdrant (READ) - RÃ©cupÃ©ration des embeddings et mÃ©tadonnÃ©es
4. `topic_clusters` (CREATE batch) - Sauvegarde des clusters
5. `topic_outliers` (CREATE batch) - Sauvegarde des outliers
6. `trend_pipeline_executions` (UPDATE) - Mise Ã  jour du statut et statistiques

### Stage 2 - Analyse Temporelle
7. `topic_temporal_metrics` (CREATE) - Sauvegarde des mÃ©triques temporelles
8. `trend_pipeline_executions` (UPDATE) - Mise Ã  jour du statut

### Stage 3 - Enrichissement LLM
9. `trend_analysis` (CREATE) - Sauvegarde des synthÃ¨ses de tendances
10. `article_recommendations` (CREATE) - Sauvegarde des recommandations
11. `weak_signals_analysis` (CREATE) - Sauvegarde de l'analyse des signaux faibles (optionnel)
12. `trend_pipeline_executions` (UPDATE) - Mise Ã  jour du statut et `total_recommendations`

### Stage 4 - Gap Analysis
13. `client_coverage_analysis` (CREATE) - Analyse de couverture par topic
14. `editorial_gaps` (CREATE) - Identification des gaps
15. `client_strengths` (CREATE) - Identification des forces (optionnel)
16. `content_roadmap` (CREATE) - GÃ©nÃ©ration de la roadmap
17. `trend_pipeline_executions` (UPDATE) - Mise Ã  jour du statut et `total_gaps`

### Phase finale
18. `trend_pipeline_executions` (UPDATE) - Finalisation avec `end_time` et `duration_seconds`

## Structure des donnÃ©es

### Request Body
```json
{
  "client_domain": "innosys.fr",
  "domains": null,
  "time_window_days": 365,
  "skip_llm": false,
  "skip_gap_analysis": false
}
```

### Response (ExecutionResponse)
```json
{
  "execution_id": "uuid",
  "status": "accepted",
  "start_time": null,
  "estimated_duration_minutes": 10
}
```

## Diagramme de flux

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ POST /api/v1/trend-pipeline/analyze                            â”‚
â”‚ { client_domain: "innosys.fr", time_window_days: 365 }        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase Initiale : RÃ©cupÃ©ration des domaines                    â”‚
â”‚ - READ workflow_executions (competitor_search)                  â”‚
â”‚ - Extraire domains depuis output_data.competitors               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CrÃ©ation de l'exÃ©cution                                         â”‚
â”‚ - CREATE trend_pipeline_executions                              â”‚
â”‚   * execution_id, client_domain, domains_analyzed               â”‚
â”‚   * time_window_days, status: pending                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 1 - Clustering (BERTopic + HDBSCAN)                      â”‚
â”‚                                                                  â”‚
â”‚ 1. READ Qdrant ({client_domain}_competitor_articles)            â”‚
â”‚    - Filtre par domains et time_window_days                     â”‚
â”‚    - RÃ©cupÃ¨re embeddings + mÃ©tadonnÃ©es                          â”‚
â”‚                                                                  â”‚
â”‚ 2. Clustering BERTopic + HDBSCAN                               â”‚
â”‚    - GÃ©nÃ©ration de topics                                       â”‚
â”‚    - Calcul de centroÃ¯des                                       â”‚
â”‚                                                                  â”‚
â”‚ 3. GÃ©nÃ©ration de labels                                         â”‚
â”‚    - Labels automatiques pour chaque topic                       â”‚
â”‚    - Calcul de cohÃ©rence                                        â”‚
â”‚                                                                  â”‚
â”‚ 4. Extraction d'outliers                                        â”‚
â”‚    - Documents non classifiÃ©s (topic_id=-1)                    â”‚
â”‚    - CatÃ©gorisation                                            â”‚
â”‚                                                                  â”‚
â”‚ 5. CREATE topic_clusters (batch)                                â”‚
â”‚ 6. CREATE topic_outliers (batch)                                â”‚
â”‚ 7. UPDATE trend_pipeline_executions                             â”‚
â”‚    * stage_1_clustering_status: completed                       â”‚
â”‚    * total_clusters, total_outliers, total_articles             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 2 - Analyse Temporelle                                   â”‚
â”‚                                                                  â”‚
â”‚ 1. Calcul de mÃ©triques par topic                                â”‚
â”‚    - Volume (articles par fenÃªtre)                              â”‚
â”‚    - VÃ©locitÃ© (taux de croissance)                              â”‚
â”‚    - FraÃ®cheur (ratio articles rÃ©cents)                         â”‚
â”‚    - DiversitÃ© sources                                         â”‚
â”‚    - Score de potentiel                                        â”‚
â”‚                                                                  â”‚
â”‚ 2. DÃ©tection de drift                                           â”‚
â”‚    - Ã‰volution des topics dans le temps                         â”‚
â”‚                                                                  â”‚
â”‚ 3. CREATE topic_temporal_metrics                                â”‚
â”‚ 4. UPDATE trend_pipeline_executions                             â”‚
â”‚    * stage_2_temporal_status: completed                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 3 - Enrichissement LLM                                   â”‚
â”‚ (si skip_llm=false)                                             â”‚
â”‚                                                                  â”‚
â”‚ Pour chaque top topic (top 10 par potential_score) :          â”‚
â”‚                                                                  â”‚
â”‚ 1. SynthÃ¨se de tendance                                         â”‚
â”‚    - Appel LLM (Llama3, Mistral, etc.)                         â”‚
â”‚    - GÃ©nÃ©ration de synthÃ¨se                                     â”‚
â”‚    - Identification angles saturÃ©s / opportunitÃ©s              â”‚
â”‚    - CREATE trend_analysis                                      â”‚
â”‚                                                                  â”‚
â”‚ 2. Recommandations d'articles                                  â”‚
â”‚    - GÃ©nÃ©ration titre, hook, outline                            â”‚
â”‚    - Calcul score de diffÃ©renciation                            â”‚
â”‚    - DÃ©termination niveau d'effort                              â”‚
â”‚    - CREATE article_recommendations                             â”‚
â”‚                                                                  â”‚
â”‚ 3. Analyse signaux faibles (optionnel)                          â”‚
â”‚    - Analyse des outliers                                       â”‚
â”‚    - CREATE weak_signals_analysis                                â”‚
â”‚                                                                  â”‚
â”‚ 4. UPDATE trend_pipeline_executions                             â”‚
â”‚    * stage_3_llm_status: completed                             â”‚
â”‚    * total_recommendations                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 4 - Gap Analysis                                          â”‚
â”‚ (si skip_gap_analysis=false et client_domain fourni)            â”‚
â”‚                                                                  â”‚
â”‚ 1. Analyse de couverture client                                 â”‚
â”‚    - Comparaison articles client vs concurrents                 â”‚
â”‚    - Calcul coverage_score par topic                            â”‚
â”‚    - CREATE client_coverage_analysis                            â”‚
â”‚                                                                  â”‚
â”‚ 2. Identification des gaps                                      â”‚
â”‚    - Topics avec faible couverture                              â”‚
â”‚    - Calcul priority_score                                      â”‚
â”‚    - GÃ©nÃ©ration diagnostic et opportunitÃ©s                      â”‚
â”‚    - CREATE editorial_gaps                                      â”‚
â”‚                                                                  â”‚
â”‚ 3. Identification des forces                                    â”‚
â”‚    - Topics oÃ¹ client surperforme                               â”‚
â”‚    - CREATE client_strengths                                    â”‚
â”‚                                                                  â”‚
â”‚ 4. GÃ©nÃ©ration roadmap                                           â”‚
â”‚    - Association gaps â†’ recommandations                          â”‚
â”‚    - Priorisation (priority_order)                              â”‚
â”‚    - CREATE content_roadmap                                     â”‚
â”‚                                                                  â”‚
â”‚ 5. UPDATE trend_pipeline_executions                             â”‚
â”‚    * stage_4_gap_status: completed                             â”‚
â”‚    * total_gaps                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Finalisation                                                    â”‚
â”‚ - UPDATE trend_pipeline_executions                              â”‚
â”‚   * end_time, duration_seconds                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Dependencies entre tables

```
workflow_executions (competitor_search)
    â””â”€> output_data.competitors
            â””â”€> domains list
                    â””â”€> trend_pipeline_executions
                            â”œâ”€> topic_clusters (Stage 1)
                            â”‚       â”œâ”€> topic_temporal_metrics (Stage 2)
                            â”‚       â”œâ”€> trend_analysis (Stage 3)
                            â”‚       â”œâ”€> article_recommendations (Stage 3)
                            â”‚       â”œâ”€> client_coverage_analysis (Stage 4)
                            â”‚       â”œâ”€> editorial_gaps (Stage 4)
                            â”‚       â””â”€> client_strengths (Stage 4)
                            â”œâ”€> topic_outliers (Stage 1)
                            â”‚       â””â”€> weak_signals_analysis (Stage 3)
                            â””â”€> content_roadmap (Stage 4)
                                    â”œâ”€> editorial_gaps (FK)
                                    â””â”€> article_recommendations (FK)
```

## Endpoints associÃ©s

### GET /api/v1/trend-pipeline/{execution_id}/status
- RÃ©cupÃ¨re le statut de l'exÃ©cution
- Retourne : statuts des 4 Ã©tapes, totaux (clusters, gaps), durÃ©e

### GET /api/v1/trend-pipeline/{execution_id}/clusters
- RÃ©cupÃ¨re les clusters dÃ©couverts
- Retourne : liste des clusters avec labels, tailles, scores

### GET /api/v1/trend-pipeline/{execution_id}/gaps
- RÃ©cupÃ¨re les gaps Ã©ditoriaux identifiÃ©s
- Retourne : liste des gaps avec scores de prioritÃ©

### GET /api/v1/trend-pipeline/{execution_id}/roadmap
- RÃ©cupÃ¨re la roadmap de contenu
- Retourne : roadmap priorisÃ©e avec recommandations

### GET /api/v1/trend-pipeline/{execution_id}/llm-results
- RÃ©cupÃ¨re les rÃ©sultats LLM (synthÃ¨ses + recommandations)
- Retourne : synthÃ¨ses de tendances et recommandations d'articles

## Notes importantes

- â­ **CRITIQUE** : Table essentielle pour le fonctionnement de la route
- ðŸ“– **LECTURE SEULE** : Table lue mais non modifiÃ©e
- ðŸ” **EXTERNE** : Service externe (Qdrant, LLM)
- ðŸ“ **LOGGING** : Table de traÃ§abilitÃ©

### Points clÃ©s

1. **Mode auto-fetch** : Avec `client_domain`, rÃ©cupÃ¨re automatiquement les concurrents depuis une recherche prÃ©cÃ©dente
2. **Pipeline sÃ©quentiel** : Les 4 Ã©tapes s'exÃ©cutent sÃ©quentiellement, chaque Ã©tape dÃ©pend de la prÃ©cÃ©dente
3. **Skip options** : PossibilitÃ© de sauter l'enrichissement LLM (`skip_llm`) ou l'analyse de gaps (`skip_gap_analysis`)
4. **FenÃªtre temporelle** : Filtre les articles par `time_window_days` (dÃ©faut: 365 jours)
5. **Top topics** : Seuls les top 10 topics (par `potential_score`) sont enrichis par LLM
6. **Gap analysis conditionnelle** : NÃ©cessite `client_domain` et `skip_gap_analysis=false`
7. **Performance** : DurÃ©e estimÃ©e ~10 minutes pour une analyse complÃ¨te

### Performance et limitations

- **DurÃ©e typique** : ~10 minutes pour une analyse complÃ¨te
- **Minimum d'articles** : NÃ©cessite un minimum d'articles (configurable, dÃ©faut: ~50)
- **CoÃ»t LLM** : L'enrichissement LLM peut Ãªtre coÃ»teux (appels multiples)
- **ScalabilitÃ©** : Le clustering peut Ãªtre lent avec beaucoup d'articles (>10k)

