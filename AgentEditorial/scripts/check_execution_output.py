"""Script pour v√©rifier la validit√© de l'output_data d'une ex√©cution de workflow."""

import asyncio
import json
import sys
from pathlib import Path
from uuid import UUID

# Ajouter le r√©pertoire parent au path pour les imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from python_scripts.database.db_session import AsyncSessionLocal
from python_scripts.database.models import WorkflowExecution
from python_scripts.utils.logging import get_logger

logger = get_logger(__name__)


def validate_json_serializable(obj, path="root"):
    """Valide qu'un objet est JSON-serializable et d√©tecte les valeurs probl√©matiques."""
    issues = []
    
    if obj is None:
        return issues
    
    if isinstance(obj, dict):
        for key, value in obj.items():
            current_path = f"{path}.{key}" if path != "root" else key
            issues.extend(validate_json_serializable(value, current_path))
    elif isinstance(obj, list):
        for i, item in enumerate(obj):
            current_path = f"{path}[{i}]"
            issues.extend(validate_json_serializable(item, current_path))
    elif isinstance(obj, (int, str, bool)):
        pass  # Types valides
    elif isinstance(obj, float):
        if not (obj == obj):  # NaN check
            issues.append(f"{path}: NaN d√©tect√©")
        elif obj == float('inf') or obj == float('-inf'):
            issues.append(f"{path}: Infinity d√©tect√©")
    else:
        try:
            json.dumps(obj)
        except (TypeError, ValueError) as e:
            issues.append(f"{path}: Type non s√©rialisable {type(obj).__name__}: {str(e)}")
    
    return issues


def validate_output_structure(output_data: dict, workflow_type: str) -> list:
    """Valide la structure de l'output_data selon le sch√©ma WorkflowOutputSchema."""
    issues = []
    
    if not isinstance(output_data, dict):
        issues.append("output_data doit √™tre un dictionnaire")
        return issues
    
    # Pour competitor_search, la structure est directe (sans result_type/result_data)
    if workflow_type == "competitor_search":
        # Structure attendue: {"competitors": [...], "total_found": ..., "domain": ...}
        if "competitors" not in output_data:
            issues.append("Pour competitor_search: 'competitors' manquant (requis)")
        elif not isinstance(output_data["competitors"], list):
            issues.append("Pour competitor_search: 'competitors' doit √™tre une liste")
        
        if "domain" not in output_data:
            issues.append("Pour competitor_search: 'domain' manquant (recommand√©)")
        elif not isinstance(output_data["domain"], str):
            issues.append("Pour competitor_search: 'domain' doit √™tre une cha√Æne de caract√®res")
        
        # V√©rifier la structure des concurrents
        if "competitors" in output_data and isinstance(output_data["competitors"], list):
            for i, competitor in enumerate(output_data["competitors"]):
                if not isinstance(competitor, dict):
                    issues.append(f"competitors[{i}] doit √™tre un dictionnaire")
                else:
                    if "domain" not in competitor:
                        issues.append(f"competitors[{i}]: 'domain' manquant")
                    if "url" not in competitor:
                        issues.append(f"competitors[{i}]: 'url' manquant")
    
    # Pour les autres workflow_types, utiliser la structure WorkflowOutputSchema standard
    else:
        # V√©rifier les champs requis selon WorkflowOutputSchema
        if "result_type" not in output_data:
            issues.append("Champ 'result_type' manquant (requis)")
        elif not isinstance(output_data["result_type"], str):
            issues.append("Champ 'result_type' doit √™tre une cha√Æne de caract√®res")
        
        if "result_data" not in output_data:
            issues.append("Champ 'result_data' manquant (requis)")
        elif not isinstance(output_data["result_data"], dict):
            issues.append("Champ 'result_data' doit √™tre un dictionnaire")
        
        # V√©rifier les champs optionnels
        if "artifacts" in output_data:
            if not isinstance(output_data["artifacts"], list):
                issues.append("Champ 'artifacts' doit √™tre une liste")
            elif output_data["artifacts"]:
                for i, artifact in enumerate(output_data["artifacts"]):
                    if not isinstance(artifact, str):
                        issues.append(f"artifacts[{i}] doit √™tre une cha√Æne de caract√®res")
        
        if "metrics" in output_data:
            if not isinstance(output_data["metrics"], dict):
                issues.append("Champ 'metrics' doit √™tre un dictionnaire")
        
        # V√©rifications sp√©cifiques selon le workflow_type
        if workflow_type == "editorial_analysis":
            if "result_data" in output_data and isinstance(output_data["result_data"], dict):
                result_data = output_data["result_data"]
                if "site_profile" not in result_data:
                    issues.append("Pour editorial_analysis: 'result_data.site_profile' manquant")
    
    return issues


async def check_execution_output(execution_id_str: str = None, workflow_id: int = None):
    """V√©rifie la validit√© de l'output_data pour une ex√©cution donn√©e."""
    async with AsyncSessionLocal() as session:
        # Construire la requ√™te
        query = select(WorkflowExecution).where(
            WorkflowExecution.is_valid == True  # noqa: E712
        )
        
        # Recherche par id uniquement
        if workflow_id is not None and execution_id_str is None:
            query = query.where(WorkflowExecution.id == workflow_id)
        # Recherche par execution_id
        elif execution_id_str is not None:
            try:
                execution_id = UUID(execution_id_str)
                query = query.where(WorkflowExecution.execution_id == execution_id)
                if workflow_id is not None:
                    query = query.where(WorkflowExecution.id == workflow_id)
            except ValueError:
                print(f"‚ùå ERREUR: execution_id invalide: {execution_id_str}")
                return False
        else:
            print("‚ùå ERREUR: Vous devez fournir soit execution_id soit workflow_id")
            return False
        
        result = await session.execute(query)
        execution = result.scalar_one_or_none()
        
        if not execution:
            print(f"‚ùå ERREUR: Ex√©cution non trouv√©e")
            if execution_id_str:
                print(f"   execution_id: {execution_id_str}")
            if workflow_id:
                print(f"   id: {workflow_id}")
            return False
        
        print("=" * 80)
        print(f"üìã V√âRIFICATION DE L'EX√âCUTION")
        print("=" * 80)
        print(f"ID: {execution.id}")
        print(f"Execution ID: {execution.execution_id}")
        print(f"Workflow Type: {execution.workflow_type}")
        print(f"Status: {execution.status}")
        print(f"Was Success: {execution.was_success}")
        print(f"Start Time: {execution.start_time}")
        print(f"End Time: {execution.end_time}")
        print(f"Duration: {execution.duration_seconds}s" if execution.duration_seconds else "Duration: N/A")
        if execution.error_message:
            print(f"Error Message: {execution.error_message}")
        print()
        
        # V√©rifier si output_data existe
        if execution.output_data is None:
            print("‚ö†Ô∏è  ATTENTION: output_data est NULL")
            if execution.status == "completed" and execution.was_success:
                print("   ‚ö†Ô∏è  Probl√®me: Status 'completed' avec was_success=True mais output_data est NULL")
            return False
        
        print("=" * 80)
        print("üîç VALIDATION DE L'OUTPUT_DATA")
        print("=" * 80)
        
        # 1. V√©rifier la s√©rialisation JSON
        print("\n1Ô∏è‚É£  V√©rification de la s√©rialisation JSON...")
        json_issues = validate_json_serializable(execution.output_data)
        if json_issues:
            print("   ‚ùå Probl√®mes de s√©rialisation JSON d√©tect√©s:")
            for issue in json_issues:
                print(f"      - {issue}")
        else:
            print("   ‚úÖ S√©rialisation JSON valide")
        
        # 2. V√©rifier la structure
        print("\n2Ô∏è‚É£  V√©rification de la structure...")
        structure_issues = validate_output_structure(execution.output_data, execution.workflow_type)
        if structure_issues:
            print("   ‚ùå Probl√®mes de structure d√©tect√©s:")
            for issue in structure_issues:
                print(f"      - {issue}")
        else:
            print("   ‚úÖ Structure valide")
        
        # 3. Tester la s√©rialisation compl√®te
        print("\n3Ô∏è‚É£  Test de s√©rialisation compl√®te...")
        try:
            json_str = json.dumps(execution.output_data, default=str, allow_nan=False)
            print(f"   ‚úÖ S√©rialisation r√©ussie ({len(json_str)} caract√®res)")
        except (TypeError, ValueError) as e:
            print(f"   ‚ùå √âchec de la s√©rialisation: {str(e)}")
            json_issues.append(f"Erreur de s√©rialisation: {str(e)}")
        
        # 4. V√©rifier la compl√©tude des donn√©es
        print("\n4Ô∏è‚É£  V√©rification de la compl√©tude...")
        completeness_issues = []
        
        if execution.workflow_type == "competitor_search":
            competitors = execution.output_data.get("competitors", [])
            total_found = execution.output_data.get("total_found")
            total_evaluated = execution.output_data.get("total_evaluated")
            all_candidates = execution.output_data.get("all_candidates", [])
            excluded_candidates = execution.output_data.get("excluded_candidates", [])
            
            # V√©rifier les champs attendus selon la documentation
            expected_fields = ["competitors", "domain"]
            optional_fields = ["total_found", "total_evaluated", "all_candidates", "excluded_candidates"]
            
            for field in expected_fields:
                if field not in execution.output_data:
                    completeness_issues.append(f"Champ requis manquant: '{field}'")
            
            # V√©rifier total_found
            if total_found is None:
                completeness_issues.append(f"Champ 'total_found' manquant (devrait √™tre {len(competitors)})")
            elif total_found != len(competitors):
                completeness_issues.append(f"Incoh√©rence: total_found={total_found} mais {len(competitors)} concurrents dans la liste")
            
            # V√©rifier total_evaluated
            if total_evaluated is None:
                completeness_issues.append("Champ 'total_evaluated' manquant (recommand√©)")
            
            # V√©rifier all_candidates
            if "all_candidates" not in execution.output_data:
                completeness_issues.append("Champ 'all_candidates' manquant (recommand√© pour tra√ßabilit√©)")
            elif not all_candidates:
                completeness_issues.append("Champ 'all_candidates' pr√©sent mais vide")
            
            # V√©rifier excluded_candidates
            if excluded_candidates is None:
                completeness_issues.append("Champ 'excluded_candidates' manquant (recommand√©)")
            
            if len(competitors) == 0 and execution.status == "completed" and execution.was_success:
                completeness_issues.append("Aucun concurrent trouv√© malgr√© un statut 'completed'")
            
            # V√©rifier que chaque concurrent a les champs essentiels
            missing_essential = 0
            for i, competitor in enumerate(competitors[:10]):  # Limiter √† 10 pour √©viter trop de messages
                if not isinstance(competitor, dict):
                    continue
                missing_fields = []
                if not competitor.get("domain"):
                    missing_fields.append("domain")
                if not competitor.get("url"):
                    missing_fields.append("url")
                if missing_fields:
                    missing_essential += 1
                    if missing_essential <= 5:  # Limiter l'affichage
                        completeness_issues.append(f"competitors[{i}] manque: {', '.join(missing_fields)}")
            
            if missing_essential > 5:
                completeness_issues.append(f"... et {missing_essential - 5} autres concurrents avec champs manquants")
        
        elif execution.workflow_type == "editorial_analysis":
            if "result_data" in execution.output_data:
                result_data = execution.output_data["result_data"]
                if not result_data.get("site_profile") and execution.status == "completed":
                    completeness_issues.append("site_profile manquant dans result_data")
        
        if completeness_issues:
            print("   ‚ö†Ô∏è  Probl√®mes de compl√©tude d√©tect√©s:")
            for issue in completeness_issues:
                print(f"      - {issue}")
        else:
            print("   ‚úÖ Donn√©es compl√®tes")
        
        # 5. Afficher un aper√ßu de l'output_data
        print("\n5Ô∏è‚É£  Aper√ßu de l'output_data:")
        print("-" * 80)
        try:
            preview = json.dumps(execution.output_data, indent=2, default=str, ensure_ascii=False)
            # Limiter l'affichage √† 2000 caract√®res pour voir plus de d√©tails
            if len(preview) > 2000:
                print(preview[:2000] + "\n... (tronqu√©)")
                print(f"\n   Taille totale: {len(preview)} caract√®res")
            else:
                print(preview)
        except Exception as e:
            print(f"   ‚ùå Impossible d'afficher l'aper√ßu: {str(e)}")
        
        # R√©sum√©
        print("\n" + "=" * 80)
        print("üìä R√âSUM√â")
        print("=" * 80)
        
        all_issues = json_issues + structure_issues + completeness_issues
        if all_issues:
            print(f"‚ùå VALIDATION √âCHOU√âE: {len(all_issues)} probl√®me(s) d√©tect√©(s)")
            print(f"   - S√©rialisation JSON: {len(json_issues)}")
            print(f"   - Structure: {len(structure_issues)}")
            print(f"   - Compl√©tude: {len(completeness_issues)}")
            return False
        else:
            print("‚úÖ VALIDATION R√âUSSIE: output_data est valide et complet")
            return True


async def main():
    """Point d'entr√©e principal."""
    if len(sys.argv) < 2:
        print("Usage: python check_execution_output.py <execution_id> [workflow_id]")
        print("   ou: python check_execution_output.py --id <workflow_id>")
        print("Exemple: python check_execution_output.py 7997bd9a-2758-40fa-b867-f1cf334a618a 103")
        print("Exemple: python check_execution_output.py --id 106")
        sys.exit(1)
    
    execution_id = None
    workflow_id = None
    
    # G√©rer l'option --id
    if sys.argv[1] == "--id" and len(sys.argv) >= 3:
        workflow_id = int(sys.argv[2])
    else:
        execution_id = sys.argv[1]
        if len(sys.argv) > 2:
            workflow_id = int(sys.argv[2])
    
    success = await check_execution_output(execution_id, workflow_id)
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    asyncio.run(main())















