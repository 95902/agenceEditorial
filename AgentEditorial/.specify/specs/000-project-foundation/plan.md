# Implementation Plan: Agent Éditorial & Concurrentiel

**Branch**: `main` | **Date**: 2025-01-25 | **Spec**: [spec.md](./spec.md)  
**Input**: Feature specification from `/AgentEditorial/.specify/specs/000-project-foundation/spec.md`

**Note**: This plan is generated by the `/speckit.plan` command based on the feature specification and constitution.

## Summary

**Primary Requirement**: Créer un système multi-agents d'analyse éditoriale et concurrentielle utilisant l'IA pour automatiser l'analyse du style éditorial de sites web, identifier automatiquement les concurrents, scraper leurs articles, et détecter les tendances thématiques avec BERTopic.

**Technical Approach**: 
- Architecture multi-agents avec LangChain/LangGraph pour orchestration
- Stack Python asynchrone (FastAPI, SQLAlchemy 2.0 async, Crawl4AI)
- Base de données PostgreSQL pour métadonnées et traçabilité
- Vectorstore Qdrant pour embeddings et recherche sémantique
- LLMs locaux via Ollama (llama3, mistral, phi3) pour analyses spécialisées
- BERTopic pour topic modeling et détection de tendances
- API REST avec background tasks pour workflows longs
- Single-tenant MVP avec purge automatique données (90 jours)

## Technical Context

**Language/Version**: Python 3.12 (minimum 3.10+)  
**Primary Dependencies**: 
- FastAPI 0.115+ (API REST)
- SQLAlchemy 2.0+ (ORM async)
- LangChain 0.2+ / LangGraph (orchestration agents)
- Ollama (LLMs locaux)
- Crawl4AI 0.7+ (scraping)
- BERTopic 0.16+ (topic modeling)
- Qdrant (vectorstore)
- Pydantic V2 (validation)
- Uvicorn (serveur ASGI)

**Storage**: 
- PostgreSQL 15+ (données relationnelles, traçabilité, cache)
- Qdrant (embeddings et recherche sémantique)

**Testing**: 
- pytest (framework de tests)
- pytest-cov (couverture de code, target 80%)
- testcontainers (tests d'intégration avec DB réelle)
- httpx (tests E2E API)

**Target Platform**: Linux server (production), développement multi-plateforme (Windows/Mac/Linux)

**Project Type**: Web application (backend API avec orchestration multi-agents)

**Performance Goals**: 
- Analyse éditoriale complète : < 10 minutes pour 50 pages
- Recherche concurrents : < 2 minutes
- Scraping 100 articles : < 15 minutes
- Analyse BERTopic 300 articles : < 5 minutes
- API response time : < 500ms (endpoints non-background)

**Constraints**: 
- Single-tenant MVP (pas de multi-tenancy initial)
- Pas d'authentification pour MVP (rate limiting par IP uniquement : 100 req/min)
- Conservation données limitée à 90 jours (purge automatique)
- Respect strict robots.txt et crawl-delay
- Tout I/O asynchrone (pas de code synchrone bloquant)
- Type hints obligatoires (mypy strict mode)
- Couverture tests ≥ 80%

**Scale/Scope**: 
- Support jusqu'à 1000 domaines analysés simultanément
- PostgreSQL optimisé pour 10M+ articles indexés (avec purge 90j)
- Qdrant scaling horizontal si > 100M embeddings
- Max 200 pages analysées par domaine
- Max 100 articles scrapés par concurrent

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

### ✅ Article I: Architecture & Stack Technique

**Stack Fondamental:**
- ✅ Python 3.12 conforme (minimum 3.10+)
- ✅ uv pour gestion dépendances
- ✅ FastAPI 0.115+ pour API REST
- ✅ PostgreSQL 15+ avec SQLAlchemy 2.0+ async
- ✅ Qdrant pour vectorstore
- ✅ LangChain/LangGraph pour orchestration
- ✅ Ollama pour LLMs locaux
- ✅ Crawl4AI (module Python, pas conteneur)
- ✅ BERTopic 0.16+ pour topic modeling
- ✅ Pydantic V2 pour validation

**Architecture Multi-Agents:**
- ✅ DDD avec bounded contexts par agent
- ✅ Event-Driven Architecture pour communication
- ✅ Repository Pattern pour accès données
- ✅ CQRS léger (read/write separation)
- ✅ 5 agents identifiés (analysis, competitor, scraping, topic_modeling, orchestrator)

**Modèle de Données:**
- ✅ 10 tables PostgreSQL définies dans spec
- ✅ Soft delete avec flag is_valid
- ✅ Index sur domain, execution_id, status, created_at
- ✅ Types JSONB avec schemas Pydantic

**GATE STATUS: ✅ PASS** - Stack et architecture conformes à la constitution

### ✅ Article II: Standards de Code Python

**Type Hints & Validation:**
- ✅ Type hints obligatoires spécifiés dans constraints
- ✅ Pydantic V2 pour tous inputs/outputs API
- ✅ Pydantic Settings pour configuration

**Async/Await:**
- ✅ Tout I/O asynchrone (constraint explicite)
- ✅ SQLAlchemy 2.0 async
- ✅ Crawl4AI async

**Structure des Modules:**
- ✅ Structure définie dans spec (agents/, analysis/, api/, database/, etc.)

**GATE STATUS: ✅ PASS** - Standards de code conformes

### ✅ Article III: Tests (NON-NÉGOCIABLE)

**Stratégie de Tests:**
- ✅ Couverture minimale 80% spécifiée
- ✅ pytest pour framework
- ✅ testcontainers pour intégration
- ✅ httpx pour E2E
- ✅ Organisation tests/ (unit/, integration/, e2e/)

**GATE STATUS: ✅ PASS** - Stratégie de tests conforme

### ✅ Article IV: Agents IA - Standards

**Structure Agents:**
- ✅ BaseAgent class pattern défini dans spec
- ✅ Prompts centralisés dans agents/prompts.py
- ✅ LLMs spécialisés par tâche (llama3, mistral, phi3)
- ✅ State management via PostgreSQL (pas de state RAM)

**GATE STATUS: ✅ PASS** - Architecture agents conforme

### ✅ Article V: API FastAPI - Standards

**Structure Endpoints:**
- ✅ Versioning /api/v1/
- ✅ Status codes standardisés
- ✅ Pydantic models pour requests/responses
- ✅ Background tasks pour workflows longs
- ✅ WebSocket pour progression (optionnel)

**GATE STATUS: ✅ PASS** - Design API conforme

### ✅ Article VI: Base de Données - Standards

**SQLAlchemy Models:**
- ✅ Conventions snake_case pluriel
- ✅ Timestamps auto-managed
- ✅ Soft delete avec is_valid
- ✅ JSONB avec schemas Pydantic
- ✅ Migrations Alembic

**GATE STATUS: ✅ PASS** - Standards DB conformes

### ✅ Article VII: Scraping & Éthique

**Respect robots.txt:**
- ✅ Obligatoire spécifié dans constraints
- ✅ User-Agent déclaré
- ✅ Rate limiting par domaine (1 req/2s par défaut)

**GATE STATUS: ✅ PASS** - Standards scraping conformes

### Overall Constitution Gate Status: ✅ ALL GATES PASS

Aucune violation de la constitution détectée. Le plan est conforme à tous les principes définis.

## Project Structure

### Documentation (this feature)

```text
AgentEditorial/.specify/specs/000-project-foundation/
├── spec.md              # Feature specification (complete)
├── plan.md              # This file (/speckit.plan command output)
├── research.md          # Phase 0 output (to be generated)
├── data-model.md        # Phase 1 output (to be generated)
├── quickstart.md        # Phase 1 output (to be generated)
├── contracts/           # Phase 1 output (to be generated)
│   └── api.yaml         # OpenAPI 3.0 specification
└── checklists/
    └── requirements.md  # Specification quality checklist (complete)
```

### Source Code (repository root)

```text
python_scripts/
├── agents/              # Agents IA
│   ├── __init__.py
│   ├── base_agent.py    # BaseAgent abstract class
│   ├── agent_analysis.py
│   ├── agent_competitor.py
│   ├── agent_scraping.py
│   ├── agent_topic_modeling.py
│   ├── agent_orchestrator.py
│   ├── prompts.py       # Tous les prompts LLM centralisés
│   └── utils/
│       └── llm_factory.py  # Factory pour créer LLMs Ollama
│
├── analysis/            # Topic modeling & NLP
│   ├── __init__.py
│   ├── topic_modeling.py    # BERTopic pipeline
│   ├── ngram_extraction.py
│   ├── entity_extraction.py # spaCy
│   └── trend_synthesizer.py
│
├── api/                 # FastAPI
│   ├── __init__.py
│   ├── main.py          # FastAPI app + routes registration
│   ├── dependencies.py  # DB sessions, auth (future), rate limiting
│   ├── routers/
│   │   ├── __init__.py
│   │   ├── sites.py     # /api/v1/sites endpoints
│   │   ├── competitors.py
│   │   ├── trends.py
│   │   ├── executions.py  # Workflow status tracking
│   │   └── health.py
│   ├── schemas/         # Pydantic models API
│   │   ├── __init__.py
│   │   ├── requests.py
│   │   └── responses.py
│   └── middleware/
│       └── rate_limit.py  # Rate limiting by IP
│
├── database/
│   ├── __init__.py
│   ├── models.py        # SQLAlchemy models (10 tables)
│   ├── db_session.py    # Async session factory
│   ├── crud_profiles.py
│   ├── crud_executions.py
│   ├── crud_articles.py
│   ├── crud_topics.py
│   └── migrations/      # Alembic
│       └── versions/
│
├── ingestion/
│   ├── __init__.py
│   ├── crawl_pages.py   # Crawl4AI wrapper avec robots.txt
│   ├── detect_sitemaps.py
│   ├── text_cleaner.py
│   └── robots_txt.py    # Parser robots.txt
│
├── vectorstore/
│   ├── __init__.py
│   ├── qdrant_client.py
│   └── embeddings_utils.py  # Sentence-Transformers wrapper
│
├── config/
│   ├── __init__.py
│   └── settings.py      # Pydantic Settings
│
├── utils/
│   ├── __init__.py
│   ├── logging.py       # Structured logging setup
│   └── exceptions.py    # Custom exceptions hierarchy
│
└── jobs/
    ├── __init__.py
    └── purge_old_data.py  # Job de purge 90 jours (scheduler)

tests/
├── __init__.py
├── conftest.py          # Pytest fixtures (DB, mocks)
├── unit/
│   ├── test_crud_profiles.py
│   ├── test_text_cleaner.py
│   ├── test_ngram_extraction.py
│   └── test_robots_txt.py
├── integration/
│   ├── test_agent_analysis.py
│   ├── test_bertopic_pipeline.py
│   ├── test_qdrant_integration.py
│   └── conftest.py      # Fixtures DB testcontainers
└── e2e/
    ├── test_api_sites.py
    ├── test_api_competitors.py
    └── test_full_workflow.py

docker/
├── docker-compose.yml   # PostgreSQL, Qdrant, Ollama
└── Dockerfile           # Optional: containerize API (future)

docs/
├── architecture.md      # Diagrammes architecture
├── api.md              # Documentation endpoints (auto-générée)
├── agents.md           # Description agents et workflows
└── database.md         # Schéma DB + explications tables
```

**Structure Decision**: 
- Structure **single project** (backend API uniquement, pas de frontend pour MVP)
- Organisation par domaine fonctionnel (agents, analysis, api, database)
- Tests organisés par type (unit, integration, e2e)
- Infrastructure Docker Compose pour services externes uniquement (PostgreSQL, Qdrant, Ollama)

## Complexity Tracking

> **No Constitution Violations Detected** - All choices align with constitutional principles.

No violations to justify.

---

## Phase 0: Outline & Research

### Research Tasks

Based on Technical Context, the following research and clarification tasks are identified:

1. **LangChain 0.2+ / LangGraph Integration Patterns**
   - Best practices for multi-agent orchestration
   - State machine patterns with LangGraph
   - Integration with FastAPI background tasks

2. **Crawl4AI Async Best Practices**
   - Async patterns for Crawl4AI 0.7+
   - Robots.txt parsing and respect
   - Rate limiting and crawl-delay implementation
   - JavaScript rendering with Playwright in async context

3. **BERTopic 0.16+ Configuration & Performance**
   - Optimal hyperparameters for editorial content analysis
   - Integration with Qdrant embeddings
   - Temporal topic evolution patterns
   - Visualization generation and storage

4. **Qdrant Integration Patterns**
   - Collection management (single-tenant MVP)
   - Embedding generation pipeline (Sentence-Transformers)
   - Similarity search and deduplication strategies
   - Performance optimization for large-scale indexing

5. **FastAPI Background Tasks & WebSocket**
   - Background task patterns for long-running workflows
   - WebSocket streaming for progress updates
   - State management between tasks and WebSocket connections

6. **PostgreSQL Async Patterns (SQLAlchemy 2.0)**
   - Async session management best practices
   - Transaction handling in async context
   - Connection pooling configuration
   - Migration strategies with Alembic async

7. **Data Purge Strategy (90-day retention)**
   - Scheduled job implementation (APScheduler or similar)
   - Cascade deletion patterns (Qdrant + PostgreSQL)
   - Audit logging for purge operations
   - Performance optimization for bulk deletions

8. **Rate Limiting Implementation (IP-based)**
   - FastAPI middleware for rate limiting
   - In-memory vs Redis-based rate limiting
   - Configuration per endpoint
   - Testing strategies for rate limiting

### Research Output

**File**: `research.md` (to be generated in Phase 0)

The research.md will consolidate findings from all research tasks above, providing:
- Decision: What was chosen
- Rationale: Why it was chosen
- Alternatives considered: What else was evaluated
- Implementation patterns: Code examples and best practices

---

## Phase 1: Design & Contracts

### Data Model

**File**: `data-model.md` (to be generated)

Will include:
- Entity definitions for all 10 PostgreSQL tables
- Field specifications with types and constraints
- Relationships between entities
- Validation rules from requirements
- JSONB schemas (Pydantic models)
- Indexes and performance considerations
- Soft delete patterns

### API Contracts

**File**: `contracts/api.yaml` (to be generated)

OpenAPI 3.0 specification including:
- All endpoints from spec (US-009)
- Request/Response schemas (Pydantic models)
- Status codes and error responses
- Authentication (none for MVP, but rate limiting documented)
- WebSocket endpoints for progress streaming
- Examples and descriptions

**Endpoints to document:**
- `POST /api/v1/sites/analyze` - Launch editorial analysis
- `GET /api/v1/sites/{domain}` - Get site profile
- `GET /api/v1/sites` - List analyzed sites
- `POST /api/v1/competitors/search` - Find competitors
- `GET /api/v1/competitors/{domain}` - Get competitor list
- `POST /api/v1/scraping/competitors` - Scrape competitor articles
- `GET /api/v1/scraping/articles` - List scraped articles
- `POST /api/v1/trends/analyze` - Run BERTopic analysis
- `GET /api/v1/trends/topics` - Get discovered topics
- `GET /api/v1/trends/gaps` - Compare client vs competitors
- `GET /api/v1/executions/{execution_id}` - Get workflow status
- `WS /api/v1/executions/{execution_id}/stream` - Real-time progress
- `GET /api/v1/health` - Health check

### Quickstart Guide

**File**: `quickstart.md` (to be generated)

Will include:
- Prerequisites installation (uv, Ollama, Docker)
- Environment setup (.env configuration)
- Database initialization (Alembic migrations)
- Starting services (Docker Compose)
- Running the API server
- Example API calls
- Running tests
- Common troubleshooting

### Agent Context Update

After Phase 1, run:
```powershell
.specify/scripts/powershell/update-agent-context.ps1 -AgentType cursor-agent
```

This will update Cursor's agent context with new technologies from the plan.

---

## Phase 0 & 1 Status

### ✅ Phase 0: Research (COMPLETE)

**Generated**: `research.md`

All technical decisions documented:
- LangChain/LangGraph integration patterns
- Crawl4AI async best practices
- BERTopic configuration
- Qdrant integration patterns
- FastAPI background tasks & WebSocket
- PostgreSQL async patterns
- Data purge strategy (90-day retention)
- Rate limiting implementation

### ✅ Phase 1: Design & Contracts (COMPLETE)

**Generated Artifacts:**
- `data-model.md` - Complete database schema with 10 tables, relationships, Pydantic schemas
- `contracts/api.yaml` - OpenAPI 3.0 specification with all endpoints
- `quickstart.md` - Setup and usage guide

**Next**: Update agent context and proceed to `/speckit.tasks`

---

## Re-evaluation: Constitution Check (Post-Design)

### ✅ All Gates Still Pass

After Phase 0 and Phase 1 design decisions:
- ✅ Stack choices align with constitution
- ✅ Architecture patterns conform (DDD, Repository, CQRS léger)
- ✅ Database schema follows Article VI standards
- ✅ API design follows Article V standards
- ✅ All I/O operations remain async
- ✅ Type safety maintained with Pydantic schemas

**GATE STATUS: ✅ ALL GATES PASS** (Post-Design)

---

## Next Steps

1. **Generate research.md** (Phase 0) - COMPLETE
2. **Generate data-model.md** (Phase 1) - COMPLETE
3. **Generate contracts/api.yaml** (Phase 1) - COMPLETE
4. **Generate quickstart.md** (Phase 1) - COMPLETE
5. **Update agent context** (Phase 1) - Run update-agent-context.ps1
6. **Re-evaluate Constitution Check** - COMPLETE (All gates pass)

**Ready for**: `/speckit.tasks` to generate detailed implementation tasks.

---

**Status**: ✅ **PHASE 0 & 1 COMPLETE - READY FOR TASKS**  
**Last Updated**: 2025-01-25