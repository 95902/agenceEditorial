# Project Specification: Agent √âditorial & Concurrentiel

**Feature ID:** 000-project-foundation  
**Feature Branch:** main  
**Status:** Ready for Planning  
**Version:** 1.2.0  
**Last Updated:** 2025-01-25  
**Owner:** Development Team  
**Priority:** Critical

---

## Overview

### Problem Statement

Les entreprises et professionnels du marketing de contenu manquent d'outils automatis√©s pour :

- Comprendre leur propre style √©ditorial de mani√®re objective
- Identifier leurs concurrents r√©els sur le march√© digital
- Analyser les tendances √©ditoriales de leur secteur
- Obtenir des recommandations data-driven pour leur strat√©gie de contenu

L'analyse manuelle de ces √©l√©ments prend des semaines et reste subjective. Les outils existants (SEMrush, Ahrefs) se focalisent sur le SEO technique mais n√©gligent l'analyse √©ditoriale profonde.

### Solution

**Agent √âditorial & Concurrentiel** est un syst√®me multi-agents utilisant l'IA pour automatiser l'analyse √©ditoriale et concurrentielle compl√®te. Le syst√®me :

1. **Crawle et analyse** le style √©ditorial d'un site (ton, structure, vocabulaire)
2. **Identifie automatiquement** les concurrents via recherche multi-sources
3. **Scrape et indexe** les articles de blog concurrents
4. **D√©tecte les tendances** th√©matiques avec topic modeling (BERTopic)
5. **G√©n√®re des recommandations** strat√©giques bas√©es sur les gaps d√©tect√©s

### Key Benefits

**Pour les utilisateurs :**

- ‚è±Ô∏è Temps d'analyse r√©duit de **3 semaines √† 2 heures**
- üìä **Objectivit√©** via analyse IA multi-mod√®les
- üéØ **Recommandations actionnables** bas√©es sur donn√©es r√©elles
- üîÑ **Monitoring continu** des tendances concurrentielles

**Pour le business :**

- üí∞ R√©duction co√ªts consulting (‚Ç¨5K-15K par analyse ‚Üí ‚Ç¨0)
- üìà Am√©lioration performance √©ditoriale mesurable
- üöÄ Acc√©l√©ration time-to-market strat√©gie contenu

### Target Users

**Primary Users:**

- Responsables marketing de contenu (PME, ETI)
- Consultants SEO / Content Strategy
- Agences digitales

**Secondary Users:**

- Data analysts marketing
- Product managers SaaS B2B
- √âquipes communication corporate

### Success Metrics

| M√©trique | Baseline | Target (6 mois) |
|----------|----------|-----------------|
| Temps analyse compl√®te | 2-3 semaines | < 3 heures |
| Pr√©cision identification concurrents | N/A | > 85% |
| Topics d√©couverts pertinents | N/A | > 80% |
| Satisfaction utilisateur | N/A | > 4.5/5 |
| Co√ªt par analyse | ‚Ç¨8,000 | < ‚Ç¨50 |

---

## User Stories

### Epic 1: Analyse √âditoriale Automatis√©e

#### US-001: Analyser le style √©ditorial d'un site (Priority: Critical)

**As a** responsable marketing de contenu  
**I want** analyser automatiquement le style √©ditorial de mon site web  
**So that** je comprends objectivement mon positionnement √©ditorial actuel

**Acceptance Scenarios:**

**Scenario 1: Analyse r√©ussie d'un site standard**
- **Given** un domaine valide "example.com" avec 50+ pages de contenu
- **And** le site est accessible publiquement
- **When** je lance l'analyse √©ditoriale
- **Then** le syst√®me crawle max 50 pages en respectant robots.txt
- **And** g√©n√®re un profil √©ditorial complet en < 10 minutes
- **And** le profil contient : niveau de langage, ton, structure, mots-cl√©s, audience cible
- **And** les r√©sultats sont sauvegard√©s dans site_profiles

**Scenario 2: Site avec contenu limit√©**
- **Given** un domaine avec < 10 pages de contenu
- **When** je lance l'analyse
- **Then** le syst√®me retourne un avertissement "Contenu insuffisant"
- **And** propose d'analyser avec un seuil r√©duit
- **And** g√©n√®re un profil partiel si accept√©

**Scenario 3: Domaine inaccessible**
- **Given** un domaine qui retourne 403 ou robots.txt interdit crawling
- **When** je tente l'analyse
- **Then** le syst√®me retourne une erreur explicite
- **And** propose d'analyser via URL unique fournie manuellement

**Business Rules:**

- Maximum 200 pages analys√©es par domaine (protection co√ªts)
- Respect obligatoire robots.txt et crawl-delay
- Analyse multi-LLM : 4 mod√®les sp√©cialis√©s (llama3, mistral, phi3)
- Cache de 30 jours : r√©utilisation si domaine d√©j√† analys√©

**Dependencies:**

- Crawl4AI install√© et configur√©
- Ollama avec mod√®les t√©l√©charg√©s (llama3:8b, mistral:7b, phi3:medium)
- Qdrant collection cr√©√©e pour le domaine
- PostgreSQL tables: site_profiles, workflow_executions

---

#### US-002: Consulter l'historique d'analyses (Priority: High)

**As a** utilisateur existant  
**I want** acc√©der √† l'historique de mes analyses pr√©c√©dentes  
**So that** je peux comparer l'√©volution de mon style √©ditorial

**Acceptance Scenarios:**

**Scenario 1: Liste des analyses**
- **Given** j'ai analys√© 3 domaines dans le pass√©
- **When** j'acc√®de √† "/api/v1/sites"
- **Then** je vois la liste des 3 domaines avec date derni√®re analyse
- **And** statut de chaque analyse (completed, pending, failed)

**Scenario 2: D√©tail d'une analyse**
- **Given** une analyse compl√©t√©e pour "example.com"
- **When** je requ√™te "/api/v1/sites/example.com"
- **Then** je re√ßois le profil √©ditorial complet
- **And** m√©tadonn√©es : date, nb pages analys√©es, dur√©e, mod√®les utilis√©s

**Scenario 3: Comparaison temporelle**
- **Given** 2+ analyses du m√™me domaine √† dates diff√©rentes
- **When** je demande "/api/v1/sites/example.com/history"
- **Then** je vois l'√©volution des m√©triques cl√©s dans le temps

---

### Epic 2: Recherche Concurrentielle Automatis√©e

#### US-003: Identifier les concurrents automatiquement (Priority: Critical)

**As a** responsable marketing  
**I want** que le syst√®me identifie automatiquement mes concurrents  
**So that** je n'ai pas √† les lister manuellement et d√©couvre des acteurs ignor√©s

**Acceptance Scenarios:**

**Scenario 1: Recherche multi-sources avec strat√©gies optimis√©es**
- **Given** un site analys√© "mon-site.com" avec profil √©ditorial
- **When** je lance la recherche concurrentielle
- **Then** le syst√®me g√©n√®re 60 requ√™tes organis√©es en 6 strat√©gies (direct, services, combo, geo, competitive, alternatives)
- **And** ex√©cute maximum 30 requ√™tes sur les 60 g√©n√©r√©es (s√©lection optimis√©e)
- **And** interroge 3 sources : Tavily, DuckDuckGo, Crawl4AI pour chaque requ√™te
- **And** fusionne les r√©sultats en liste unique d√©dupliqu√©e
- **And** filtre par domaines .fr (TLD par d√©faut, configurable via param√®tre si besoin)
- **And** track la performance de chaque strat√©gie (queries, results, valid_results, efficiency)
- **And** retourne top 10 concurrents class√©s par pertinence

**Scenario 2: Pipeline de validation avanc√©**
- **Given** une liste brute de 50+ domaines trouv√©s via recherche multi-sources (apr√®s g√©n√©ration et ex√©cution requ√™tes)
- **When** le syst√®me applique le pipeline de validation complet
- **Then** √©tape 2 : d√©duplication par domaine (fusion r√©sultats multi-sources, exclusion domaine analys√©)
- **And** √©tape 3 : pr√©-filtrage automatique (exclusion PDFs, domaines interdits, listing platforms, outils SEO)
- **And** √©tape 4 : enrichissement homepage des top 50 candidats (description, services, keywords via crawl)
- **And** √©tape 5 : validation cross-source (boost si candidat trouv√© dans plusieurs sources)
- **And** √©tape 6 : filtrage LLM avec phi3:medium √©value la pertinence avec contexte enrichi (seuil >= 0.6)
- **And** √©limine les faux positifs (annuaires, marketplaces, m√©dias g√©n√©ralistes)
- **And** √©tape 7 : calcul similarit√© s√©mantique avec embeddings (all-MiniLM-L6-v2)
- **And** √©tape 8 : validation analyse de contenu (mots-cl√©s business, sections services actives)
- **And** √©tape 9 : ranking multi-crit√®res (LLM score + cross-validation + g√©ographie + s√©mantique)
- **And** √©tape 10 : assurance diversit√© (limites par cat√©gorie, g√©ographie, taille)
- **And** √©tape 11 : calcul score de confiance final pour chaque concurrent
- **And** √©tape 12 : filtrage final avec seuils ajust√©s (confidence >= 0.35, relevance >= 0.45)
- **And** garantit minimum 10 r√©sultats si disponibles
- **And** conserve uniquement les vrais concurrents √©ditoriaux (directs 0.8-1.0 et indirects 0.6-0.79)

**Scenario 3: Aucun concurrent trouv√©**
- **Given** un site de niche tr√®s sp√©cifique
- **When** la recherche ne trouve aucun concurrent pertinent apr√®s filtrage
- **Then** le syst√®me retourne une liste vide avec explication
- **And** propose d'√©largir les crit√®res de recherche (baisser seuils, √©largir strat√©gies)
- **And** log les m√©triques de performance des strat√©gies pour diagnostic

**Scenario 4: Garantie minimum de r√©sultats**
- **Given** une recherche qui trouve au moins 10 candidats pertinents apr√®s validation
- **When** le filtrage final par score de confiance √©limine trop de r√©sultats
- **Then** le syst√®me garantit minimum 10 r√©sultats si disponibles (rel√¢chement intelligent des seuils)
- **And** priorise les meilleurs r√©sultats m√™me si score l√©g√®rement sous les seuils stricts

**Business Rules:**

- Minimum 3 concurrents, maximum 20 (minimum 10 garantis si disponibles)
- Exclusion automatique du domaine analys√©
- Score de pertinence >= 0.6 pour √™tre retenu (concurrents directs 0.8-1.0, indirects 0.6-0.79)
- Score de confiance >= 0.35 et pertinence >= 0.45 pour filtrage final (seuils ajustables)
- Cache des r√©sultats : 7 jours
- TLD par d√©faut : .fr (configurable via param√®tre si besoin)
- Tracking performance des strat√©gies de requ√™tes (queries, results, valid_results, efficiency) pour optimisation future
- Support concurrents directs (m√™me produits/services, m√™me march√©) et indirects (m√™me industrie, services compl√©mentaires)

**Dependencies:**

- API Tavily configur√©e (optionnel)
- DuckDuckGo via package ddgs (recherche directe)
- LLM phi3:medium pour classification et filtrage
- Module query_generator pour g√©n√©ration requ√™tes multi-strat√©gies (6 types de strat√©gies)
- Embeddings utils pour calcul similarit√© s√©mantique (all-MiniLM-L6-v2)
- Crawl4AI pour enrichissement homepage des candidats (top 50)

---

#### US-004: Valider/ajuster la liste des concurrents (Priority: Medium)

**As a** utilisateur  
**I want** pouvoir valider ou ajuster la liste de concurrents propos√©e  
**So that** l'analyse porte sur les bons acteurs

**Acceptance Scenarios:**

**Scenario 1: Validation simple**
- **Given** une liste de 10 concurrents propos√©s
- **When** je valide la liste sans modification
- **Then** le syst√®me marque les 10 comme "validated"
- **And** lance automatiquement l'analyse de ces concurrents

**Scenario 2: Ajout manuel de concurrents**
- **Given** je connais 2 concurrents non d√©tect√©s
- **When** j'ajoute manuellement "concurrent-1.fr" et "concurrent-2.fr"
- **Then** le syst√®me v√©rifie que les domaines existent
- **And** les ajoute √† la liste avec flag "manual" (stockage dans workflow_executions.output_data avec metadata validation)
- **And** les inclut dans les analyses suivantes

**Scenario 3: Suppression de faux positifs**
- **Given** la liste contient "media-generaliste.fr" (faux positif)
- **When** je supprime ce domaine
- **Then** il est marqu√© "excluded" (stockage dans workflow_executions.output_data avec flags validation)
- **And** n'appara√Æt plus dans les analyses futures

**Business Rules:**

- Liste de concurrents stock√©e dans workflow_executions.output_data (JSONB) pour chaque recherche
- Flags de validation: "validated", "manual", "excluded" stock√©s dans metadata
- Liste valid√©e utilis√©e comme source de v√©rit√© pour analyses suivantes

---

#### D√©tails Techniques: Strat√©gies de G√©n√©ration de Requ√™tes

Le syst√®me g√©n√®re 60 requ√™tes optimis√©es organis√©es en 6 strat√©gies distinctes pour maximiser la couverture et la pertinence :

**1. Strat√©gie Direct (20 requ√™tes)**
- Requ√™tes simples avec keywords primaires : `{keyword} site:.fr`
- Variations avec terme "services" : `{keyword} services site:.fr`
- Bas√©e sur les 10 premiers keywords extraits du profil client
- Objectif : Trouver directement les acteurs mentionnant les mots-cl√©s principaux

**2. Strat√©gie Combo (12 requ√™tes)**
- Combinaisons de paires de keywords : `{keyword1} {keyword2} site:.fr`
- Limite aux 4-5 premiers keywords pour √©viter explosion combinatoire
- Objectif : Cibler les entreprises positionn√©es sur plusieurs domaines d'activit√©

**3. Strat√©gie G√©ographique (10 requ√™tes)**
- Keywords combin√©s avec r√©gions : `{keyword} {region} site:.fr`
- R√©gions cibl√©es : Paris, Ile-de-France, r√©gion parisienne, Lyon, Nantes, France
- Bas√©e sur les 2 premiers keywords
- Objectif : D√©couvrir les concurrents locaux/r√©gionaux souvent ignor√©s

**4. Strat√©gie Competitive (12 requ√™tes)**
- Termes concurrentiels combin√©s avec keywords : `{term} {keyword} site:.fr`
- Termes utilis√©s : prestataire, partenaire, int√©grateur, expert, sp√©cialiste, soci√©t√©
- Bas√©e sur les 2 premiers keywords
- Objectif : Identifier les entreprises positionn√©es comme experts/prestataires

**5. Strat√©gie Type ESN (6 requ√™tes)**
- Termes sectoriels combin√©s avec keywords : `{term} {keyword} site:.fr`
- Termes utilis√©s : ESN, SSII, soci√©t√© services num√©riques, agence digitale
- Objectif : Cibler sp√©cifiquement les acteurs du secteur IT/services num√©riques

**6. Strat√©gie Alternatives (10 requ√™tes)**
- Requ√™tes bas√©es sur le domaine analys√© :
  - `alternatives {domain} site:.fr`
  - `concurrent {domain} site:.fr`
  - `similaire {domain} site:.fr`
  - `{domain} concurrents site:.fr`
- Combinaisons domain + keywords pour contextualiser
- Objectif : D√©couvrir les alternatives mentionn√©es dans les recherches comparatives

**Optimisation d'ex√©cution :**

- Seulement 30 requ√™tes sur les 60 g√©n√©r√©es sont ex√©cut√©es (s√©lection optimis√©e)
- Tracking de performance par strat√©gie pour identifier les plus efficaces
- Logging structur√© pour optimisation future bas√©e sur donn√©es r√©elles

---

#### D√©tails Techniques: Pipeline de Validation en 12 √âtapes

Le pipeline de validation assure la qualit√© et la pertinence des concurrents identifi√©s :

**√âtape 1 : G√©n√©ration et Ex√©cution Multi-Strat√©gies**
- G√©n√©ration des 60 requ√™tes selon 6 strat√©gies
- Ex√©cution de 30 requ√™tes maximum (optimisation performance)
- Recherche simultan√©e sur Tavily (si disponible) et DuckDuckGo pour chaque requ√™te
- Tracking initial : nombre de requ√™tes par strat√©gie, results obtenus

**√âtape 2 : D√©duplication par Domaine**
- Fusion des r√©sultats de toutes les sources par domaine unique
- Exclusion automatique du domaine analys√©
- Conservation de toutes les m√©tadonn√©es (sources multiples, scores, URLs)

**√âtape 3 : Pr√©-filtrage Automatique**
- Exclusion des PDFs (URLs se terminant par .pdf)
- Exclusion des domaines interdits : .gouv.fr, .gov.fr, .edu.fr, .ac.fr, hal.*, archives-ouvertes
- Exclusion des outils d'analyse SEO : SimilarWeb, SitePrice, NicheProwler, SEMrush, Ahrefs, Moz
- Exclusion des plateformes de listing/agr√©gation : SortList, Digitiz, Clutch, GoodFirms, DesignRush
- Exclusion des sites m√©dias/g√©n√©ralistes : latribune.fr, lemonde.fr, lesechos.fr, franceinfo.fr
- D√©tection de patterns "listing" dans titres/contenus (liste, classement, meilleur, top)

**√âtape 4 : Enrichissement Homepage (Top 50 Candidats)**
- Crawl de la homepage des 50 meilleurs candidats apr√®s pr√©-filtre
- Extraction meta description ou premier paragraphe comme description
- Extraction section Services via patterns regex
- Extraction keywords d'activit√© (conseil, d√©veloppement, web, digital, marketing, etc.)
- Skip automatique des PDFs et sites non-business (gouvernement, acad√©mique)
- Limitation : 3 services max, 5 keywords max pour √©viter surcharge

**√âtape 5 : Validation Cross-Source**
- Identification des candidats trouv√©s dans plusieurs sources (Tavily + DuckDuckGo)
- Boost de score pour ces candidats (+0.15 au score de base)
- Flag `cross_validated: true` pour tra√ßabilit√©
- Objectif : Prioriser les concurrents confirm√©s par plusieurs sources

**√âtape 6 : Filtrage LLM avec Contexte Enrichi**
- Utilisation de phi3:medium pour √©valuation de pertinence
- Contexte fourni : domaine, description enrichie, services, keywords d'activit√©
- Seuil de pertinence >= 0.6 pour √™tre retenu :
  - **Concurrents directs** (0.8-1.0) : M√™me produits/services, m√™me march√©
  - **Concurrents indirects** (0.6-0.79) : M√™me industrie, services compl√©mentaires
- Raison obligatoire pour chaque concurrent retenu (explication de la pertinence)
- Fallback si LLM filtre tout : retour des top candidats avec score par d√©faut

**√âtape 7 : Calcul Similarit√© S√©mantique**
- G√©n√©ration embedding du profil cible (keywords ou domaine)
- G√©n√©ration embeddings batch des candidats (descriptions enrichies, limit√© √† 30 pour performance)
- Calcul cosine similarity entre embedding cible et embeddings candidats
- Ajout du score `semantic_similarity` (0.0-1.0) √† chaque candidat
- Utilisation all-MiniLM-L6-v2 (384 dimensions, mod√®le local)

**√âtape 8 : Validation Analyse de Contenu**
- V√©rification pr√©sence de mots-cl√©s business dans titre/description/contenu
- D√©tection de sections Services actives (pr√©sence termes : services, prestations, offres, solutions)
- V√©rification d'indicateurs de site actif (contact, devis, portfolio, actualit√©s r√©centes)
- Exclusion des sites m√©dias/news (d√©tection via keywords m√©dias dans domaine/contenu)
- Exclusion si aucun indicateur business (ni mots-cl√©s, ni section services)

**√âtape 9 : Ranking Multi-Crit√®res**
- Calcul score de pertinence combin√© :
  - LLM score : 50% du poids
  - Cross-validation bonus : +15% si trouv√© dans plusieurs sources
  - Bonus g√©ographique : +10% si m√™me r√©gion/city d√©tect√©e
  - Similarit√© s√©mantique : 25% du poids
- Tri par score calcul√© d√©croissant
- Priorit√© suppl√©mentaire par source (Tavily > DuckDuckGo > Crawl4AI)

**√âtape 10 : Assurance Diversit√©**
- Cat√©gorisation des candidats : ESN, agence web, agence marketing, freelancer, autre
- Limitation par cat√©gorie : max 5-10 par cat√©gorie selon max_results et nombre de cat√©gories
- Conservation de diversit√© g√©ographique et de taille (PME vs ETI)
- Re-tri par score de pertinence apr√®s application des limites

**√âtape 11 : Calcul Score de Confiance**
- Score combinant tous les crit√®res : pertinence LLM, cross-validation, similarit√© s√©mantique, validation contenu
- Pond√©ration selon fiabilit√© de chaque signal
- Score final 0.0-1.0 pour chaque candidat

**√âtape 12 : Filtrage Final avec Seuils Ajust√©s**
- Filtrage par seuils minimums :
  - Score de confiance >= 0.35
  - Score de pertinence >= 0.45
- Garantie minimum 10 r√©sultats si disponibles (rel√¢chement intelligent si trop filtr√©)
- Limitation √† max_results (d√©faut 10, max 20)
- Logging des m√©triques finales : total trouv√©, sources utilis√©es, strat√©gies efficaces

**Tracking de Performance par Strat√©gie :**

- Pour chaque strat√©gie : nombre de requ√™tes ex√©cut√©es, r√©sultats obtenus, r√©sultats valides apr√®s filtrage
- Calcul efficacit√© : valid_results / queries
- Logging structur√© pour identification strat√©gies les plus performantes
- Donn√©es utilisables pour optimisation future (prioriser strat√©gies efficaces, ajuster distribution)

---

### Epic 3: Scraping & Analyse des Articles Concurrents

#### US-005: Scraper les articles des concurrents (Priority: Critical)

**As a** data analyst marketing  
**I want** collecter automatiquement les articles de blog des concurrents  
**So that** j'ai une base de donn√©es √† jour pour l'analyse des tendances

**Acceptance Scenarios:**

**Scenario 1: D√©couverte et scraping r√©ussi**
- **Given** un concurrent valid√© "concurrent.fr"
- **When** je lance le scraping
- **Then** le syst√®me d√©tecte automatiquement le sitemap XML
- **And** identifie les URLs de type article/blog (pattern /blog/, /actualites/)
- **And** scrape jusqu'√† 100 articles par domaine
- **And** extrait : titre, auteur, date, contenu nettoy√©, mots-cl√©s, image
- **And** sauvegarde dans competitor_articles avec toutes m√©tadonn√©es

**Scenario 2: Respect des r√®gles de scraping**
- **Given** robots.txt sp√©cifie crawl-delay: 5
- **When** le scraping s'ex√©cute
- **Then** le syst√®me attend 5 secondes entre chaque requ√™te
- **And** respecte les paths disallowed
- **And** utilise le User-Agent d√©clar√©
- **And** enregistre les permissions dans scraping_permissions

**Scenario 3: Site sans sitemap**
- **Given** un concurrent sans sitemap.xml
- **When** je lance le scraping
- **Then** le syst√®me cherche flux RSS alternatif
- **And** sinon, crawle les pages principales pour d√©tecter liens articles
- **And** extrait max 50 articles via heuristiques HTML

**Business Rules:**

- Max 100 articles par concurrent
- Articles minimum 250 mots pour √™tre conserv√©s
- Date publication < 2 ans (articles r√©cents uniquement)
- D√©duplication par URL hash

**Dependencies:**

- Crawl4AI avec support async
- Playwright install√© pour JS rendering
- Table competitor_articles cr√©√©e
- Cache crawl_cache actif

---

#### US-006: Indexer s√©mantiquement les articles (Priority: High)

**As a** system  
**I want** indexer les articles dans un vectorstore  
**So that** je peux effectuer des recherches s√©mantiques et du clustering

**Acceptance Scenarios:**

**Scenario 1: G√©n√©ration embeddings et indexation**
- **Given** 100 articles scrap√©s pour un concurrent
- **When** le pipeline d'indexation s'ex√©cute
- **Then** g√©n√®re embeddings pour chaque article (all-MiniLM-L6-v2)
- **And** indexe dans Qdrant collection "competitor_articles"
- **And** payload contient : article_id, domain, date, keywords, titre
- **And** stocke qdrant_point_id dans competitor_articles.qdrant_point_id

**Scenario 2: D√©tection de doublons**
- **Given** 2 articles avec similarit√© cosine > 0.92
- **When** l'indexation d√©tecte cette similarit√©
- **Then** marque le 2√®me article comme doublon
- **And** ne l'indexe pas dans Qdrant
- **And** log l'√©v√©nement dans audit_log

**Scenario 3: Recherche s√©mantique**
- **Given** articles index√©s dans Qdrant
- **When** je cherche "intelligence artificielle g√©n√©rative"
- **Then** retourne top 10 articles pertinents m√™me sans mot-cl√© exact
- **And** inclut score de similarit√© pour chaque r√©sultat

---

### Epic 4: Topic Modeling & D√©tection de Tendances

#### US-007: Analyser les tendances avec BERTopic (Priority: Critical)

**As a** strat√®ge contenu  
**I want** identifier automatiquement les th√®mes dominants chez mes concurrents  
**So that** je d√©tecte les tendances du march√© et les gaps de contenu

**Acceptance Scenarios:**

**Scenario 1: Analyse BERTopic sur 30 jours**
- **Given** 300+ articles concurrents des 30 derniers jours
- **When** je lance l'analyse des tendances
- **Then** BERTopic d√©couvre automatiquement N topics (min 5, max 50)
- **And** chaque topic a : keywords principaux, coh√©rence score, nb articles
- **And** g√©n√®re visualisations : carte 2D topics, barchart, √©volution temporelle
- **And** sauvegarde r√©sultats dans bertopic_analysis

**Scenario 2: D√©tection topics √©mergents**
- **Given** analyse sur 7 jours + analyse sur 30 jours
- **When** le syst√®me compare les deux p√©riodes
- **Then** identifie les topics apparus dans les 7 derniers jours
- **And** marque comme "emerging" avec v√©locit√© calcul√©e
- **And** envoie alerte si topic √©mergent √† forte croissance

**Scenario 3: Clustering hi√©rarchique**
- **Given** 20 topics d√©couverts
- **When** je demande la hi√©rarchie
- **Then** BERTopic regroupe topics similaires en clusters parents
- **And** g√©n√®re arbre hi√©rarchique visualisable
- **And** permet exploration drill-down topic ‚Üí sous-topics

**Business Rules:**

- Minimum 50 articles pour analyse BERTopic valide
- Fen√™tres temporelles : 7j, 30j, 90j
- Topics avec < 10 articles marqu√©s comme "outliers"
- R√©g√©n√©ration automatique tous les lundis

**Dependencies:**

- BERTopic 0.16+ install√©
- UMAP + HDBSCAN pour clustering
- Embeddings pr√©-calcul√©s dans Qdrant
- Table bertopic_analysis cr√©√©e

---

#### US-008: Identifier les gaps de contenu (Priority: High)

**As a** responsable marketing  
**I want** comparer mes topics aux topics concurrents  
**So that** j'identifie les sujets que je ne couvre pas (gaps)

**Acceptance Scenarios:**

**Scenario 1: Comparaison client vs concurrents**
- **Given** analyse BERTopic de mon site + 5 concurrents
- **When** je demande l'analyse des gaps
- **Then** le syst√®me compare les ensembles de topics
- **And** identifie topics pr√©sents chez ‚â•3 concurrents mais absents chez moi
- **And** calcule "gap score" bas√© sur fr√©quence + importance topic

**Scenario 2: Recommandations de contenu**
- **Given** 5 gaps identifi√©s
- **When** je demande des recommandations
- **Then** pour chaque gap, sugg√®re : titre article, mots-cl√©s cibles, angle √©ditorial
- **And** priorise par impact estim√© (fr√©quence √ó engagement concurrent)
- **And** g√©n√®re calendrier √©ditorial sugg√©r√©

**Scenario 3: Suivi des gaps combl√©s**
- **Given** j'ai publi√© du contenu sur 2 gaps identifi√©s
- **When** je relance l'analyse apr√®s 30 jours
- **Then** le syst√®me d√©tecte la couverture de ces topics
- **And** met √† jour le gap score
- **And** marque comme "addressed" avec date

---

### Epic 5: API FastAPI & Orchestration

#### US-009: Exposer tous les workflows via API REST (Priority: Critical)

**As a** d√©veloppeur  
**I want** acc√©der √† toutes les fonctionnalit√©s via API REST  
**So that** je peux int√©grer le syst√®me dans d'autres applications

**Acceptance Scenarios:**

**Scenario 1: Lancement analyse √©ditoriale async**
- **Given** je fais une requ√™te API vers le syst√®me
- **When** je POST /api/v1/sites/analyze avec {"domain": "example.com", "max_pages": 50}
- **Then** retourne 202 Accepted avec execution_id
- **And** lance l'analyse en background task
- **And** je peux suivre la progression via WebSocket

**Scenario 2: Suivi d'ex√©cution en temps r√©el**
- **Given** une analyse en cours avec execution_id "abc-123"
- **When** je me connecte au WebSocket /api/v1/executions/abc-123/stream
- **Then** re√ßois messages JSON de progression
- **And** {"type": "progress", "current": 10, "total": 50, "message": "Crawling page 10"}
- **And** {"type": "completed", "result": {...}} √† la fin

**Scenario 3: Documentation OpenAPI automatique**
- **Given** l'API FastAPI d√©ploy√©e
- **When** j'acc√®de √† /docs
- **Then** vois documentation Swagger UI interactive
- **And** tous les endpoints document√©s avec sch√©mas Pydantic
- **And** possibilit√© de tester directement dans l'interface

**API Endpoints Required:**

```
POST   /api/v1/sites/analyze                    # Launch editorial analysis
GET    /api/v1/sites/{domain}                   # Get site profile
GET    /api/v1/sites                            # List analyzed sites

POST   /api/v1/competitors/search               # Find competitors
GET    /api/v1/competitors/{domain}             # Get competitor list

POST   /api/v1/scraping/competitors             # Scrape competitor articles
GET    /api/v1/scraping/articles                # List scraped articles

POST   /api/v1/trends/analyze                   # Run BERTopic analysis
GET    /api/v1/trends/topics                    # Get discovered topics
GET    /api/v1/trends/gaps                      # Compare client vs competitors

GET    /api/v1/executions/{execution_id}        # Get workflow status
WS     /api/v1/executions/{execution_id}/stream # Real-time progress

GET    /api/v1/health                           # Health check
```

**Dependencies:**

- FastAPI 0.115+ avec Uvicorn
- Pydantic V2 pour tous les schemas
- Background tasks pour workflows longs
- WebSocket support pour streaming

---

#### US-010: G√©rer les workflows avec tra√ßabilit√© compl√®te (Priority: High)

**As a** system administrator  
**I want** tracer toutes les ex√©cutions de workflows  
**So that** je peux d√©bugger, auditer et optimiser le syst√®me

**Acceptance Scenarios:**

**Scenario 1: Cr√©ation et tracking workflow**
- **Given** un workflow "editorial_analysis" lanc√©
- **When** le syst√®me d√©marre l'ex√©cution
- **Then** cr√©e entr√©e dans workflow_executions avec status "pending"
- **And** g√©n√®re execution_id unique (UUID)
- **And** enregistre : start_time, input_data, workflow_type

**Scenario 2: Mise √† jour statuts interm√©diaires**
- **Given** un workflow en cours
- **When** chaque √©tape se compl√®te
- **Then** log dans audit_log : step_name, status, input/output, timestamp
- **And** enregistre dans performance_metrics : dur√©e √©tape, tokens LLM, pages crawl√©es

**Scenario 3: Finalisation avec r√©sultats**
- **Given** un workflow qui se termine avec succ√®s
- **When** le syst√®me finalise
- **Then** met √† jour workflow_executions : status="completed", end_time, output_data, was_success=true
- **And** calcule duration totale
- **And** enregistre agr√©gations dans performance_metrics (avg_duration, success_rate calcul√©es via requ√™tes SQL si besoin)

**Scenario 4: Gestion des erreurs**
- **Given** une erreur survient pendant l'ex√©cution
- **When** l'exception est catch√©e
- **Then** met √† jour workflow_executions : status="failed", error_message, was_success=false
- **And** log complet dans audit_log avec stack trace
- **And** notifie l'utilisateur via API/WebSocket

---

## Functional Requirements

### FR-001: Crawling & Ingestion (MUST)

Le syst√®me DOIT pouvoir crawler et extraire le contenu de sites web en respectant :

- robots.txt et crawl-delay sp√©cifi√©
- Limitation configurable du nombre de pages (default: 50, max: 200)
- Extraction de contenu nettoy√© (sans HTML/CSS/JS)
- D√©tection automatique de sitemaps et flux RSS

### FR-002: Analyse √âditoriale Multi-LLM (MUST)

Le syst√®me DOIT analyser le style √©ditorial via 4 LLMs sp√©cialis√©s :

- **llama3:8b** : Extraction domaines d'activit√© + analyse ton/style
- **mistral:7b** : Analyse structure de contenu
- **phi3:medium** : Extraction mots-cl√©s strat√©giques
- Synth√®se finale fusionnant les 4 analyses

### FR-003: Recherche Concurrentielle Multi-Sources (MUST)

Le syst√®me DOIT identifier concurrents via un pipeline avanc√© multi-√©tapes :

**G√©n√©ration de requ√™tes optimis√©es :**

- G√©n√©ration de 60 requ√™tes organis√©es en 6 strat√©gies distinctes :
  - **Direct** : 20 requ√™tes - keywords simples avec site:.fr
  - **Services** : variations avec terme "services"
  - **Combo** : 12 requ√™tes - paires de keywords combin√©s
  - **Geo** : 10 requ√™tes - keywords + r√©gions g√©ographiques (Paris, Lyon, etc.)
  - **Competitive** : 12 requ√™tes - termes concurrentiels (prestataire, expert, sp√©cialiste)
  - **Alternatives** : 10 requ√™tes - variations (alternatives, concurrent, similaire + domain)
- Extraction intelligente de keywords depuis profil client (activity_domains, keywords primaires/secondaires)
- Limitation d'ex√©cution √† 30 requ√™tes maximum sur les 60 g√©n√©r√©es (optimisation performance)

**Recherche multi-sources :**

- Tavily Search API (si disponible, max 100 r√©sultats, recherche avanc√©e)
- DuckDuckGo via package ddgs (recherche directe, r√©gion fr-fr, filtre site:.fr)
- Crawl4AI pour exploration manuelle (optionnel, extraction depuis r√©sultats de recherche)

**Pipeline de validation en 12 √©tapes :**

1. **G√©n√©ration et ex√©cution** : Requ√™tes multi-strat√©gies avec tracking performance par strat√©gie
2. **D√©duplication** : Fusion r√©sultats par domaine, exclusion domaine analys√©
3. **Pr√©-filtrage** : Exclusion PDFs, domaines interdits (.gouv.fr, .edu.fr, outils SEO, listing platforms)
4. **Enrichissement** : Crawl homepage top 50 candidats (description, services, keywords d'activit√©)
5. **Validation cross-source** : Boost si candidat trouv√© dans plusieurs sources
6. **Filtrage LLM** : phi3:medium avec contexte enrichi, seuil >= 0.6 (directs 0.8-1.0, indirects 0.6-0.79)
7. **Similarit√© s√©mantique** : Calcul embeddings (all-MiniLM-L6-v2), cosine similarity avec profil cible
8. **Validation contenu** : Analyse pr√©sence mots-cl√©s business, sections services actives
9. **Ranking multi-crit√®res** : Score combin√© (LLM 50% + cross-validation 15% + g√©ographie 10% + s√©mantique 25%)
10. **Assurance diversit√©** : Limites par cat√©gorie (ESN, agence web, etc.), g√©ographie, taille
11. **Score de confiance** : Calcul final combinant tous les crit√®res
12. **Filtrage final** : Seuils ajust√©s (confidence >= 0.35, relevance >= 0.45), garantie minimum 10 r√©sultats si disponibles

**Tracking et optimisation :**

- M√©triques par strat√©gie : queries ex√©cut√©es, r√©sultats obtenus, r√©sultats valides, efficacit√©
- Logging structur√© pour identification strat√©gies les plus efficaces
- Donn√©es utilisables pour optimisation future des strat√©gies de recherche

### FR-004: Scraping √âthique (MUST)

Le syst√®me DOIT respecter les r√®gles de scraping :

- Lecture obligatoire de robots.txt avant tout crawl
- Respect du crawl-delay sp√©cifi√© (default: 2s)
- User-Agent identifiable : "EditorialBot/1.0 (+URL)"
- Cache de 24h des permissions pour √©viter requ√™tes r√©p√©t√©es
- Limitation √† 100 articles maximum par domaine

### FR-005: Indexation Vectorielle (MUST)

Le syst√®me DOIT indexer tous les contenus dans Qdrant :

- G√©n√©ration embeddings avec mod√®le local (all-MiniLM-L6-v2 pour MVP)
- Collection unique "competitor_articles" pour MVP (single-tenant, separation par source post-MVP si besoin)
- Payload riche : metadata + texte + embeddings
- D√©duplication automatique (similarit√© cosine > 0.92)
- Stockage du qdrant_point_id dans competitor_articles.qdrant_point_id pour tra√ßabilit√©

### FR-006: Topic Modeling BERTopic (MUST)

Le syst√®me DOIT appliquer BERTopic pour d√©tecter tendances :

- D√©couverte automatique du nombre de topics (min: 5, max: 50)
- Analyse temporelle sur fen√™tres : 7j, 30j, 90j
- G√©n√©ration visualisations interactives (HTML)
- D√©tection topics √©mergents par comparaison p√©riodes

### FR-007: API REST Compl√®te (MUST)

Le syst√®me DOIT exposer API REST avec :

- Tous les workflows accessibles via endpoints
- Validation Pydantic de tous les inputs
- Responses structur√©es avec status codes standards
- Documentation OpenAPI auto-g√©n√©r√©e (Swagger UI)
- Rate limiting configurable par endpoint

### FR-008: Background Tasks (MUST)

Le syst√®me DOIT g√©rer workflows longs en asynchrone :

- FastAPI BackgroundTasks pour analyses > 30s
- Retour imm√©diat avec execution_id
- Suivi progression via WebSocket (optionnel) ou polling
- Notifications fin d'ex√©cution (webhook ou email)

### FR-009: Tra√ßabilit√© Compl√®te (MUST)

Le syst√®me DOIT logger toutes les ex√©cutions :

- Table workflow_executions : id, type, status, timestamps, input/output
- Table audit_log : logs d√©taill√©s par √©tape
- Table performance_metrics : dur√©e, tokens LLM, pages crawl√©es, m√©triques par √©tape
- Agr√©gations calcul√©es : avg_duration, success_rate via requ√™tes SQL sur performance_metrics et workflow_executions

### FR-010: Base de Donn√©es PostgreSQL (MUST)

Le syst√®me DOIT utiliser PostgreSQL avec :

- SQLAlchemy 2.0+ async
- 10 tables principales (voir Constitution Article VI)
- Migrations Alembic versionn√©es
- Index sur : domain, execution_id, status, created_at
- Types JSONB pour donn√©es flexibles avec schemas Pydantic

### FR-011: Cache Intelligent (SHOULD)

Le syst√®me DEVRAIT impl√©menter cache multi-niveaux :

- crawl_cache : Hash URL + contenu (√©viter re-crawl)
- scraping_permissions : robots.txt cached 24h
- popular_domains : Stats domaines fr√©quemment analys√©s
- Invalidation automatique apr√®s X jours (configurable)

### FR-012: Monitoring & Health Checks (SHOULD)

Le syst√®me DEVRAIT exposer m√©triques de sant√© :

- Endpoint /api/v1/health v√©rifiant : PostgreSQL, Qdrant, Ollama
- M√©triques Prometheus-compatible (optionnel)
- Logs structur√©s JSON (structlog)
- Alertes automatiques sur erreurs critiques

### FR-013: Export & Reporting (COULD)

Le syst√®me POURRAIT permettre exports :

- Rapports PDF g√©n√©r√©s depuis r√©sultats d'analyse
- Export CSV des articles scrap√©s
- Export JSON des topics BERTopic
- Int√©gration Google Sheets/Excel (optionnel)

### FR-014: Data Retention & Purge (MUST)

Le syst√®me DOIT impl√©menter purge automatique des donn√©es :

- Conservation des articles scrap√©s : 90 jours maximum
- Job automatique de purge quotidien supprimant articles > 90 jours
- Purge √©galement des donn√©es associ√©es : embeddings Qdrant, m√©triques, cache
- Logs de purge dans audit_log pour tra√ßabilit√© RGPD
- R√©analyse n√©cessaire pour obtenir historique au-del√† de 90 jours

### FR-015: Rate Limiting API (MUST)

Le syst√®me DOIT impl√©menter rate limiting pour prot√©ger l'API publique :

- Rate limiting par IP : 100 requ√™tes/minute par d√©faut
- Configuration flexible par endpoint (analyses plus restrictives)
- Retour HTTP 429 Too Many Requests avec headers Retry-After
- Pas d'authentification requise pour MVP (API publique)

### FR-016: Authentification (COULD - Post-MVP)

Le syst√®me POURRAIT impl√©menter authentification post-MVP :

- JWT tokens ou API keys pour s√©curisation renforc√©e
- Multi-tenancy (isolation donn√©es par tenant) si besoin SaaS
- Rate limiting par utilisateur (remplace ou compl√®te rate limiting par IP)
- Gestion quotas (X analyses/mois par utilisateur)

---

## Non-Functional Requirements

### NFR-001: Performance

- Analyse √©ditoriale compl√®te : < 10 minutes pour 50 pages
- Recherche concurrents : < 2 minutes
- Scraping 100 articles : < 15 minutes (d√©pend crawl-delay)
- Analyse BERTopic 300 articles : < 5 minutes
- API response time : < 500ms (endpoints non-background)

### NFR-002: Scalabilit√©

- Support jusqu'√† 1000 domaines analys√©s simultan√©ment (single-tenant MVP)
- PostgreSQL optimis√© pour 10M+ articles index√©s (avec purge automatique 90j)
- Qdrant scaling horizontal si > 100M embeddings
- FastAPI workers configurables (2-8 selon load)
- Architecture single-tenant : pas de complexit√© multi-client initiale

### NFR-003: Fiabilit√©

- Uptime target : 99.5%
- Retry logic sur toutes op√©rations I/O (max 3 tentatives)
- Graceful degradation si service externe down (Tavily, Ollama)
- Backups PostgreSQL quotidiens + point-in-time recovery

### NFR-004: Maintenabilit√©

- Code coverage tests : ‚â• 80%
- Documentation inline (docstrings) : 100% des fonctions publiques
- Type hints obligatoires (mypy strict mode)
- CI/CD : linting + tests automatiques sur chaque PR

### NFR-005: S√©curit√©

- Variables sensibles en .env (jamais hardcod√©es)
- SQL injection protection (SQLAlchemy ORM)
- Rate limiting API : 100 req/min par IP (MVP sans authentification)
- Validation stricte inputs (Pydantic)
- Purge automatique donn√©es apr√®s 90 jours (compliance RGPD)

### NFR-006: Observabilit√©

- Logs structur√©s JSON avec contexte (execution_id, agent_name)
- M√©triques d√©taill√©es par agent (dur√©e, tokens, erreurs)
- Tracing distribu√© (LangSmith pour LLM calls)
- Dashboard monitoring (Grafana recommand√©)

---

## Success Criteria

### Definition of Done (Feature Complete)

Le projet est consid√©r√© complet quand :

**‚úÖ Core Functionality:**

- Analyse √©ditoriale fonctionne sur 10+ sites test vari√©s
- Recherche concurrentielle retourne ‚â•5 concurrents pertinents
- Scraping respecte 100% des robots.txt test√©s
- BERTopic d√©couvre topics coh√©rents sur dataset test 300 articles
- API expose tous endpoints avec documentation Swagger

**‚úÖ Quality Assurance:**

- Tests automatis√©s : coverage ‚â• 80%
- Tous tests passent (unit + integration + e2e)
- Linting : 0 erreurs (ruff, black, mypy)
- Performance : tous benchmarks NFR respect√©s
- Documentation compl√®te : README + Architecture + API

**‚úÖ Operations:**

- Docker Compose d√©marre tous services (PostgreSQL, Qdrant, Ollama)
- Migrations Alembic appliqu√©es automatiquement
- Health checks retournent "healthy"
- CI/CD pipeline ex√©cute en < 10 minutes
- Logs accessibles et structur√©s

**‚úÖ User Acceptance:**

- 3 utilisateurs beta testent avec succ√®s
- Satisfaction moyenne ‚â• 4/5
- 0 bug bloquant report√©
- Temps d'onboarding < 30 minutes

### Acceptance Testing

**Test 1: End-to-End Workflow Complet**

```
1. POST /api/v1/sites/analyze avec domain="test-site.fr"
   ‚Üí Expected: 202 + execution_id
2. Poll GET /api/v1/executions/{id} jusqu'√† status="completed"
   ‚Üí Expected: completion en < 10 min
3. GET /api/v1/sites/test-site.fr
   ‚Üí Expected: profil √©ditorial complet avec tous champs
4. POST /api/v1/competitors/search avec domain="test-site.fr"
   ‚Üí Expected: ‚â•5 concurrents retourn√©s
5. POST /api/v1/scraping/competitors avec competitors list
   ‚Üí Expected: ‚â•50 articles scrap√©s
6. POST /api/v1/trends/analyze
   ‚Üí Expected: ‚â•10 topics d√©couverts + visualisations g√©n√©r√©es
```

**Test 2: Performance sous Charge**

```
- 10 analyses √©ditoriales lanc√©es simultan√©ment
- Expected: toutes compl√®tent en < 15 min
- Expected: 0 erreur, 0 timeout
- Expected: PostgreSQL latency < 100ms
```

**Test 3: Resilience aux Erreurs**

```
- Domaine inexistant ‚Üí erreur claire retourn√©e
- robots.txt interdit crawl ‚Üí erreur avec suggestion alternative
- Ollama down ‚Üí retry puis fallback graceful
- PostgreSQL down ‚Üí retry puis 503 Service Unavailable
```

---

## Technical Constraints

### Mandatory Technologies

- **Python:** 3.10+ (3.12 recommand√©)
- **Frame
work API:** FastAPI 0.115+
- **Database:** PostgreSQL 15+
- **Vectorstore:** Qdrant
- **LLMs:** Ollama local (llama3, mistral, phi3)
- **ORM:** SQLAlchemy 2.0 async
- **Scraping:** Crawl4AI module (PAS conteneur)
- **Topic Modeling:** BERTopic 0.16+

### Prohibited

- ‚ùå Synchronous code for I/O operations
- ‚ùå Direct SQL queries (use SQLAlchemy)
- ‚ùå Hardcoded secrets in code
- ‚ùå Missing type hints on functions
- ‚ùå Missing tests for new features

### Preferred Patterns

- ‚úÖ Domain-Driven Design
- ‚úÖ Repository Pattern for data access
- ‚úÖ Dependency Injection (FastAPI Depends)
- ‚úÖ CQRS l√©ger (read/write separation)
- ‚úÖ Event-driven communication entre agents

---

## Architecture Decisions & Clarifications

### Authentication Strategy (RESOLVED)

**Decision:** Pas d'authentification pour MVP (API publique avec rate limiting par IP)  
**Rationale:** MVP plus rapide √† d√©velopper, adapt√© pour tests internes et validation conceptuelle  
**Impact:** Architecture API simplifi√©e, rate limiting par IP uniquement (pas de JWT/API keys pour MVP)  
**Future:** Migration vers authentification (API keys ou JWT) possible post-MVP si n√©cessaire  
**Status:** ‚úÖ Resolved 2025-01-25

### Multi-Tenancy (RESOLVED)

**Decision:** Single-tenant MVP uniquement  
**Rationale:** Architecture simplifi√©e pour MVP, pas de besoin multi-client initial  
**Impact:** Sch√©ma DB sans tenant_id, une seule collection Qdrant, pas d'isolation requise  
**Future:** Architecture peut √©voluer vers multi-tenant post-MVP si besoin (ajout tenant_id possible)  
**Status:** ‚úÖ Resolved 2025-01-25

### [NEEDS CLARIFICATION: LLM Providers]

**Question:** Supporter OpenAI/Anthropic en plus d'Ollama local ?  
**Impact:** Abstraction LLM provider, gestion co√ªts, fallback strategy  
**Stakeholder:** Tech Lead  
**Priority:** Low (peut √™tre ajout√© post-MVP)

### Data Retention / RGPD (RESOLVED)

**Decision:** Conservation 90 jours puis purge automatique  
**Rationale:** Minimisation risques RGPD, r√©duction stockage, politique claire et simple  
**Impact:** Job de purge automatique √† impl√©menter, donn√©es supprim√©es apr√®s 90 jours, r√©analyse n√©cessaire pour historique  
**RGPD Compliance:** Politique claire de r√©tention, droit √† l'oubli impl√©ment√© via purge automatique  
**Status:** ‚úÖ Resolved 2025-01-25

### [NEEDS CLARIFICATION: Internationalization]

**Question:** Support multi-langues (analyse sites EN, ES, DE) ?  
**Impact:** Mod√®les spaCy par langue, prompts LLM traduits  
**Stakeholder:** Product Owner  
**Priority:** Low (focus FR d'abord)

---

## Dependencies & Prerequisites

### External Services

- **Tavily API** (optionnel) : Cl√© API pour recherche premium
- **OpenAI API** (optionnel) : Fallback si Ollama insufficient
- **Qdrant Cloud** (optionnel) : Alternative √† instance locale

### Infrastructure Requirements

- **Docker & Docker Compose** : Orchestration services (PostgreSQL, Qdrant, Ollama)
- **Min 16GB RAM** : Ollama + BERTopic + Qdrant in-memory
- **Min 50GB disk** : Mod√®les Ollama + DB + embeddings
- **Python 3.10+** : Runtime application
- **uv** : Gestionnaire d√©pendances moderne

### Pre-Installation

```bash
# Install uv
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install Playwright (for Crawl4AI)
playwright install

# Download Ollama models
ollama pull llama3:8b
ollama pull mistral:7b
ollama pull phi3:medium

# Note: Embeddings generated via Sentence-Transformers (all-MiniLM-L6-v2)
# Model downloaded automatically on first use, no manual pull needed

# Install spaCy language model
python -m spacy download fr_core_news_md
```

---

## Related Documents

- **Constitution:** `.specify/memory/constitution.md` - Principes architecturaux non-n√©gociables
- **Database Schema:** `docs/db_schema.sql` - Sch√©ma PostgreSQL complet
- **Issues GitHub:** `docs/issues_github.md` + `docs/issues_github_etape2.md` - Backlog d√©taill√©
- **Architecture:** `docs/architecture.md` - Diagrammes architecture syst√®me
- **Prompts:** `python_scripts/agents/prompts.py` - Tous les prompts LLM

---

## Glossary

| Terme | D√©finition |
|-------|------------|
| **Agent** | Module autonome avec r√¥le sp√©cifique (analysis, competitor, scraping, topic modeling) |
| **Workflow** | S√©quence d'√©tapes orchestr√©es (ex: editorial_analysis = crawl ‚Üí LLM ‚Üí synthesis ‚Üí save) |
| **Embedding** | Vecteur num√©rique repr√©sentant s√©mantiquement un texte (384 dimensions pour all-MiniLM-L6-v2, g√©n√©r√© via Sentence-Transformers) |
| **Topic** | Th√®me d√©couvert par BERTopic, repr√©sent√© par cluster + keywords |
| **Gap** | Sujet pr√©sent chez concurrents mais absent dans contenu client |
| **Crawl-delay** | D√©lai impos√© par robots.txt entre requ√™tes (secondes) |
| **Execution ID** | UUID unique identifiant une ex√©cution de workflow |
| **Constitutional Compliance** | Respect strict des principes d√©finis dans constitution.md |

---

## Revision History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.2.0 | 2025-01-25 | Dev Team | Fixed inconsistencies: Removed workflow_stats table reference (use performance_metrics aggregations), fixed competitor_article_embeddings reference (use competitor_articles.qdrant_point_id), removed authentication mentions from US-009, harmonized embedding model (all-MiniLM-L6-v2), clarified FR-005 single collection MVP, added POST /competitors/{domain}/validate endpoint to contracts, clarified competitor storage structure. |
| 1.1.0 | 2025-01-25 | Dev Team | Resolved critical clarifications: Single-tenant MVP, 90-day data retention with auto-purge, no authentication for MVP (rate limiting by IP). Added FR-014 (Data Retention), FR-015 (Rate Limiting), updated NFR-005 and NFR-002. |
| 1.0.0 | 2025-01-25 | Dev Team | Initial comprehensive specification |

---

**Status:** ‚úÖ READY FOR PLANNING  
**Next Step:** Use `/speckit.plan` to generate technical architecture plan

---

**Constitutional Compliance Declaration:**

‚úÖ This specification adheres to all principles defined in `.specify/memory/constitution.md`  
‚úÖ All technical choices align with Article I (Architecture & Stack)  
‚úÖ All requirements respect Article II (Code Standards)  
‚úÖ Testing strategy follows Article III (Tests mandatory)  
‚úÖ Agent architecture matches Article IV (Agents IA)  
‚úÖ API design conforms to Article V (FastAPI Standards)
